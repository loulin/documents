#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Agent 2: è¡€ç³–è„†æ€§ä¸´åºŠé¡¾é—®
ä¸“æ³¨äºè¡€ç³–è„†æ€§åˆ†å‹å’Œä¸ªæ€§åŒ–ä¸´åºŠæ²»ç–—å»ºè®®
åŸºäºæ··æ²Œåˆ†æå’Œä¸´åºŠå†³ç­–æ”¯æŒ
"""

import pandas as pd
import numpy as np
from datetime import datetime
from enum import Enum
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import warnings
warnings.filterwarnings('ignore')

class BrittlenessType(Enum):
    """è¡€ç³–è„†æ€§åˆ†å‹"""
    CHAOTIC = "Iå‹æ··æ²Œè„†æ€§"
    QUASI_PERIODIC = "IIå‹å‡†å‘¨æœŸè„†æ€§"  
    STOCHASTIC = "IIIå‹éšæœºè„†æ€§"
    MEMORY_LOSS = "IVå‹è®°å¿†ç¼ºå¤±è„†æ€§"
    FREQUENCY_DOMAIN = "Vå‹é¢‘åŸŸè„†æ€§"
    STABLE = "ç¨³å®šå‹"

class RiskLevel(Enum):
    """é£é™©ç­‰çº§"""
    LOW = "ä½é£é™©"
    MODERATE = "ä¸­ç­‰é£é™©"
    HIGH = "é«˜é£é™©"
    CRITICAL = "æé«˜é£é™©"

@dataclass
class BrittlenessProfile:
    """è„†æ€§æ¡£æ¡ˆ"""
    type: BrittlenessType
    severity_score: float
    chaos_indicators: dict
    risk_level: RiskLevel
    clinical_features: list
    treatment_strategy: str

@dataclass  
class ClinicalRecommendation:
    """ä¸´åºŠå»ºè®®"""
    category: str
    priority: str
    action: str
    rationale: str
    expected_outcome: str
    monitoring_plan: str
    contraindications: list = None

class BrittlenessClinicalAdvisor:
    """
    è¡€ç³–è„†æ€§ä¸´åºŠé¡¾é—® - Agent 2
    ä¸“æ³¨äºè¡€ç³–è„†æ€§åˆ†å±‚å’Œä¸ªæ€§åŒ–æ²»ç–—å»ºè®®
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è„†æ€§ä¸´åºŠé¡¾é—®"""
        self.agent_name = "Brittleness Clinical Advisor"
        self.version = "1.0.0"
        self.description = "è¡€ç³–è„†æ€§åˆ†å‹å’Œä¸ªæ€§åŒ–ä¸´åºŠæ²»ç–—å»ºè®®ç³»ç»Ÿ"
        
        # è„†æ€§åˆ†å‹é˜ˆå€¼
        self.brittleness_thresholds = {
            'lyapunov_chaotic': 0.02,      # æ··æ²Œé˜ˆå€¼
            'lyapunov_stable': -0.01,      # ç¨³å®šé˜ˆå€¼
            'cv_high': 50,                 # é«˜å˜å¼‚é˜ˆå€¼
            'cv_unstable': 36,             # ä¸ç¨³å®šé˜ˆå€¼
            'entropy_threshold': 0.6,      # ç†µé˜ˆå€¼
            'hurst_memory': 0.45,          # è®°å¿†é˜ˆå€¼ (è°ƒæ•´è‡³æ›´åˆç†çš„èŒƒå›´)
            'hurst_persistent': 0.55       # æŒç»­æ€§é˜ˆå€¼
        }
        
        # æ²»ç–—ç­–ç•¥åº“
        self.treatment_strategies = {
            BrittlenessType.CHAOTIC: {
                "primary_strategy": "æ··æ²Œç¨³å®šåŒ–æ²»ç–—",
                "insulin_approach": "ä¿å®ˆå‡é‡",
                "target_hba1c": "8.0-8.5%",
                "monitoring": "24å°æ—¶ä¸¥å¯†ç›‘æ§",
                "key_principles": ["é¿å…å¼ºåŒ–æ²»ç–—", "å‡å°‘æ‰°åŠ¨", "é¢„é˜²æç«¯äº‹ä»¶"]
            },
            BrittlenessType.QUASI_PERIODIC: {
                "primary_strategy": "èŠ‚å¾‹é‡å»ºæ²»ç–—",
                "insulin_approach": "æ—¶é—´ä¼˜åŒ–ç»™è¯",
                "target_hba1c": "7.5-8.0%",
                "monitoring": "é‡ç‚¹ç›‘æµ‹Dawnç°è±¡",
                "key_principles": ["æ—¶é—´æ²»ç–—å­¦", "ç”Ÿæ´»è§„å¾‹åŒ–", "èŠ‚å¾‹åŒæ­¥"]
            },
            BrittlenessType.STOCHASTIC: {
                "primary_strategy": "æ™ºèƒ½åŒ–ç²¾å‡†æ²»ç–—",
                "insulin_approach": "è€ƒè™‘èƒ°å²›ç´ æ³µ",
                "target_hba1c": "7.0-7.5%",
                "monitoring": "è¿ç»­CGM+ç®—æ³•",
                "key_principles": ["é—­ç¯ç³»ç»Ÿ", "å®æ—¶è°ƒæ•´", "AIè¾…åŠ©"]
            },
            BrittlenessType.MEMORY_LOSS: {
                "primary_strategy": "è®°å¿†é‡å»ºæ²»ç–—",
                "insulin_approach": "é•¿æ•ˆåˆ¶å‰‚ä¼˜å…ˆ",
                "target_hba1c": "7.0-7.5%", 
                "monitoring": "è¯„ä¼°è®¤çŸ¥åŠŸèƒ½",
                "key_principles": ["GLP-1æ¿€åŠ¨å‰‚", "è‚ç³–è°ƒèŠ‚", "ç¥ç»ä¿æŠ¤"]
            },
            BrittlenessType.FREQUENCY_DOMAIN: {
                "primary_strategy": "é¢‘åŸŸè°ƒåˆ¶æ²»ç–—",
                "insulin_approach": "æ˜¼å¤œèŠ‚å¾‹è€ƒè™‘",
                "target_hba1c": "7.0-7.5%",
                "monitoring": "ç”Ÿç‰©èŠ‚å¾‹è¯„ä¼°",
                "key_principles": ["å…‰ç…§æ²»ç–—", "è¤ªé»‘ç´ ", "æ—¶ç›¸è°ƒæ•´"]
            },
            BrittlenessType.STABLE: {
                "primary_strategy": "ç»´æŒä¼˜åŒ–æ²»ç–—",
                "insulin_approach": "æ¸è¿›ç²¾ç»†è°ƒæ•´",
                "target_hba1c": "6.5-7.0%",
                "monitoring": "å¸¸è§„ç›‘æµ‹",
                "key_principles": ["æŒç»­ä¼˜åŒ–", "é¢„é˜²æ¶åŒ–", "ç”Ÿæ´»è´¨é‡"]
            }
        }
    
    def analyze_brittleness_profile(self, glucose_data: np.ndarray, 
                                  chaos_indicators: dict = None,
                                  patient_info: dict = None) -> BrittlenessProfile:
        """
        åˆ†æè¡€ç³–è„†æ€§æ¡£æ¡ˆ
        """
        print(f"ğŸ§¬ {self.agent_name} å¼€å§‹è„†æ€§åˆ†æ...")
        
        # 1. è®¡ç®—æ··æ²ŒæŒ‡æ ‡
        if chaos_indicators is None:
            chaos_indicators = self._calculate_chaos_indicators(glucose_data)
        
        # 2. è„†æ€§åˆ†å‹
        brittleness_type = self._classify_brittleness_type(chaos_indicators, glucose_data)
        
        # 3. ä¸¥é‡ç¨‹åº¦è¯„åˆ†
        severity_score = self._calculate_severity_score(chaos_indicators, glucose_data)
        
        # 4. é£é™©ç­‰çº§è¯„ä¼°
        risk_level = self._assess_risk_level(severity_score, chaos_indicators)
        
        # 5. ä¸´åºŠç‰¹å¾è¯†åˆ«
        clinical_features = self._identify_clinical_features(brittleness_type, chaos_indicators)
        
        # 6. æ²»ç–—ç­–ç•¥
        treatment_strategy = self._determine_treatment_strategy(brittleness_type)
        
        profile = BrittlenessProfile(
            type=brittleness_type,
            severity_score=severity_score,
            chaos_indicators=chaos_indicators,
            risk_level=risk_level,
            clinical_features=clinical_features,
            treatment_strategy=treatment_strategy
        )
        
        print(f"âœ… è„†æ€§åˆ†æå®Œæˆ: {brittleness_type.value}")
        return profile
    
    def _calculate_chaos_indicators(self, glucose_data: np.ndarray) -> dict:
        """è®¡ç®—æ··æ²Œåˆ†ææŒ‡æ ‡"""
        indicators = {}
        
        # LyapunovæŒ‡æ•°
        indicators['lyapunov_exponent'] = self._calculate_lyapunov(glucose_data)
        
        # è¿‘ä¼¼ç†µ
        indicators['approximate_entropy'] = self._calculate_approximate_entropy(glucose_data)
        
        # Shannonç†µ
        indicators['shannon_entropy'] = self._calculate_shannon_entropy(glucose_data)
        
        # HurstæŒ‡æ•°
        indicators['hurst_exponent'] = self._calculate_hurst_exponent(glucose_data)
        
        # åˆ†å½¢ç»´åº¦
        indicators['fractal_dimension'] = self._calculate_fractal_dimension(glucose_data)
        
        # å…³è”ç»´æ•°
        indicators['correlation_dimension'] = self._calculate_correlation_dimension(glucose_data)
        
        # æœ€å¤§LyapunovæŒ‡æ•°ç¨³å®šæ€§
        indicators['lyapunov_stability'] = "stable" if indicators['lyapunov_exponent'] < 0 else "chaotic"
        
        return indicators
    
    def _classify_brittleness_type(self, chaos_indicators: dict, glucose_data: np.ndarray) -> BrittlenessType:
        """
        è¡€ç³–è„†æ€§åˆ†å‹ - æ”¹è¿›ç‰ˆæœ¬
        åŸºäºå¤šç»´æ··æ²ŒæŒ‡æ ‡çš„ç¨³å¥åˆ†ç±»ç³»ç»Ÿ
        """
        lyapunov = chaos_indicators.get('lyapunov_exponent', 0)
        entropy = chaos_indicators.get('approximate_entropy', 0)
        hurst = chaos_indicators.get('hurst_exponent', 0.5)
        
        # è®¡ç®—å˜å¼‚ç³»æ•°
        cv = (np.std(glucose_data) / np.mean(glucose_data)) * 100
        
        # å†³ç­–æƒé‡ç³»ç»Ÿ
        chaos_score = 0
        memory_score = 0
        variability_score = 0
        
        # æ··æ²Œç‰¹å¾è¯„åˆ†
        if lyapunov > self.brittleness_thresholds['lyapunov_chaotic']:
            chaos_score += 2
        elif lyapunov > 0:
            chaos_score += 1
            
        if entropy > 0.8:
            chaos_score += 2
        elif entropy > self.brittleness_thresholds['entropy_threshold']:
            chaos_score += 1
            
        # è®°å¿†ç‰¹å¾è¯„åˆ† 
        if hurst < self.brittleness_thresholds['hurst_memory']:
            memory_score = -2  # å¼ºåæŒç»­æ€§ï¼ˆè®°å¿†ç¼ºå¤±ï¼‰
        elif hurst > self.brittleness_thresholds['hurst_persistent']:
            memory_score = 2   # å¼ºæŒç»­æ€§ï¼ˆé•¿ç¨‹è®°å¿†ï¼‰
        else:
            memory_score = 0   # éšæœºæ¸¸èµ°ç‰¹æ€§
            
        # å˜å¼‚æ€§è¯„åˆ†
        if cv > 60:
            variability_score = 3  # æé«˜å˜å¼‚
        elif cv > self.brittleness_thresholds['cv_high']:
            variability_score = 2  # é«˜å˜å¼‚
        elif cv > self.brittleness_thresholds['cv_unstable']:
            variability_score = 1  # ä¸­ç­‰å˜å¼‚
        else:
            variability_score = 0  # ä½å˜å¼‚
        
        # å¤šç»´åˆ†ç±»å†³ç­–
        # Iå‹æ··æ²Œè„†æ€§ï¼šé«˜æ··æ²Œ + æé«˜å˜å¼‚
        if chaos_score >= 3 and variability_score >= 3:
            return BrittlenessType.CHAOTIC
            
        # IIIå‹éšæœºè„†æ€§ï¼šé«˜æ··æ²Œ + é«˜å˜å¼‚ + éšæœºæ¸¸èµ°
        if chaos_score >= 2 and variability_score >= 2 and abs(memory_score) <= 1:
            return BrittlenessType.STOCHASTIC
            
        # IVå‹è®°å¿†ç¼ºå¤±è„†æ€§ï¼šè®°å¿†ç¼ºå¤± + ä¸­ç­‰ä»¥ä¸Šå˜å¼‚
        if memory_score <= -1 and variability_score >= 1:
            return BrittlenessType.MEMORY_LOSS
            
        # Vå‹é¢‘åŸŸè„†æ€§ï¼šä½æ··æ²Œä½†é«˜å˜å¼‚ + å¼ºæŒç»­æ€§
        if lyapunov < self.brittleness_thresholds['lyapunov_stable'] and variability_score >= 1 and memory_score >= 1:
            return BrittlenessType.FREQUENCY_DOMAIN
            
        # ç¨³å®šå‹ï¼šä½å˜å¼‚ + ç¨³å®šLyapunov
        if variability_score == 0 and lyapunov < self.brittleness_thresholds['lyapunov_chaotic']:
            return BrittlenessType.STABLE
            
        # IIå‹å‡†å‘¨æœŸè„†æ€§ï¼šå…¶ä»–æƒ…å†µï¼ˆä¸­ç­‰æ··æ²Œç‰¹å¾ï¼‰
        return BrittlenessType.QUASI_PERIODIC
    
    def _calculate_severity_score(self, chaos_indicators: dict, glucose_data: np.ndarray) -> float:
        """è®¡ç®—è„†æ€§ä¸¥é‡ç¨‹åº¦è¯„åˆ† (0-100)"""
        lyapunov = abs(chaos_indicators.get('lyapunov_exponent', 0))
        entropy = chaos_indicators.get('approximate_entropy', 0)
        
        # å˜å¼‚ç³»æ•°
        cv = (np.std(glucose_data) / np.mean(glucose_data)) * 100
        
        # ç»¼åˆè¯„åˆ†
        lyapunov_score = min(50, lyapunov * 1000)  # Lyapunovè´¡çŒ®æœ€å¤š50åˆ†
        entropy_score = entropy * 30  # ç†µè´¡çŒ®æœ€å¤š30åˆ†
        cv_score = min(20, cv / 5)  # CVè´¡çŒ®æœ€å¤š20åˆ†
        
        total_score = lyapunov_score + entropy_score + cv_score
        
        return min(100, total_score)
    
    def _assess_risk_level(self, severity_score: float, chaos_indicators: dict) -> RiskLevel:
        """è¯„ä¼°é£é™©ç­‰çº§"""
        if severity_score >= 80:
            return RiskLevel.CRITICAL
        elif severity_score >= 60:
            return RiskLevel.HIGH
        elif severity_score >= 40:
            return RiskLevel.MODERATE
        else:
            return RiskLevel.LOW
    
    def _identify_clinical_features(self, brittleness_type: BrittlenessType, 
                                  chaos_indicators: dict) -> list:
        """è¯†åˆ«ä¸´åºŠç‰¹å¾"""
        features = []
        
        if brittleness_type == BrittlenessType.CHAOTIC:
            features.extend([
                "è¡€ç³–ç³»ç»Ÿå‘ˆç°æ··æ²Œè¡Œä¸º",
                "å¯¹æ²»ç–—è°ƒæ•´æåº¦æ•æ„Ÿ",
                "å­˜åœ¨ä¸¥é‡ä½è¡€ç³–é£é™©",
                "è¡€ç³–æ¨¡å¼ä¸å¯é¢„æµ‹"
            ])
        
        elif brittleness_type == BrittlenessType.QUASI_PERIODIC:
            features.extend([
                "å­˜åœ¨ç—…ç†æ€§è¡€ç³–å‘¨æœŸ",
                "Dawnç°è±¡æ˜¾è‘—",
                "æ˜¼å¤œèŠ‚å¾‹ç´Šä¹±",
                "å¯è¯†åˆ«çš„å‘¨æœŸæ¨¡å¼"
            ])
        
        elif brittleness_type == BrittlenessType.STOCHASTIC:
            features.extend([
                "è¡€ç³–å˜åŒ–éšæœºæ€§å¼º",
                "éœ€è¦æ™ºèƒ½åŒ–ç®¡ç†",
                "å¯èƒ½å­˜åœ¨ç¥ç»ç—…å˜",
                "ä¼ ç»Ÿæ²»ç–—æ•ˆæœæœ‰é™"
            ])
        
        elif brittleness_type == BrittlenessType.MEMORY_LOSS:
            features.extend([
                "è¡€ç³–ç³»ç»Ÿè®°å¿†åŠŸèƒ½ç¼ºå¤±",
                "è‚ç³–è°ƒèŠ‚èƒ½åŠ›ä¸‹é™",
                "å¯èƒ½å­˜åœ¨è®¤çŸ¥åŠŸèƒ½å½±å“",
                "éœ€è¦é•¿æ•ˆæ²»ç–—"
            ])
        
        elif brittleness_type == BrittlenessType.FREQUENCY_DOMAIN:
            features.extend([
                "æ˜¼å¤œèŠ‚å¾‹å®Œå…¨ç´Šä¹±",
                "ç”Ÿç‰©é’Ÿè°ƒèŠ‚æœºåˆ¶å¤±æ•ˆ",
                "éœ€è¦èŠ‚å¾‹é‡å»º",
                "å˜å¼‚æ€§è™½é«˜ä½†ç³»ç»Ÿç›¸å¯¹ç¨³å®š"
            ])
        
        else:  # STABLE
            features.extend([
                "è¡€ç³–è°ƒèŠ‚ç³»ç»Ÿç¨³å®š",
                "æ²»ç–—ååº”å¯é¢„æµ‹",
                "é€‚åˆç²¾ç»†åŒ–ç®¡ç†",
                "é¢„åç›¸å¯¹è‰¯å¥½"
            ])
        
        return features
    
    def _determine_treatment_strategy(self, brittleness_type: BrittlenessType) -> str:
        """ç¡®å®šæ²»ç–—ç­–ç•¥"""
        strategy = self.treatment_strategies.get(brittleness_type, {})
        return strategy.get("primary_strategy", "ä¸ªæ€§åŒ–æ²»ç–—")
    
    def generate_clinical_recommendations(self, profile: BrittlenessProfile,
                                        patient_info: dict = None) -> List[ClinicalRecommendation]:
        """
        ç”Ÿæˆä¸ªæ€§åŒ–ä¸´åºŠå»ºè®®
        """
        recommendations = []
        strategy = self.treatment_strategies[profile.type]
        
        # 1. èƒ°å²›ç´ è°ƒæ•´å»ºè®®
        recommendations.append(ClinicalRecommendation(
            category="èƒ°å²›ç´ æ²»ç–—",
            priority="HIGH",
            action=f"é‡‡ç”¨{strategy['insulin_approach']}ç­–ç•¥",
            rationale=f"{profile.type.value}éœ€è¦ç‰¹å®šçš„èƒ°å²›ç´ æ²»ç–—æ–¹å¼",
            expected_outcome="é™ä½è„†æ€§ç›¸å…³é£é™©ï¼Œæ”¹å–„è¡€ç³–ç¨³å®šæ€§",
            monitoring_plan=strategy['monitoring']
        ))
        
        # 2. è¡€ç³–ç›®æ ‡è®¾å®š
        recommendations.append(ClinicalRecommendation(
            category="è¡€ç³–ç›®æ ‡",
            priority="HIGH", 
            action=f"è®¾å®šHbA1cç›®æ ‡ä¸º{strategy['target_hba1c']}",
            rationale=f"{profile.type.value}éœ€è¦ä¸ªæ€§åŒ–çš„è¡€ç³–æ§åˆ¶ç›®æ ‡",
            expected_outcome="å¹³è¡¡è¡€ç³–æ§åˆ¶ä¸å®‰å…¨æ€§",
            monitoring_plan="æ¯3ä¸ªæœˆè¯„ä¼°HbA1cå’ŒCGMæ•°æ®"
        ))
        
        # 3. ç›‘æµ‹è®¡åˆ’
        recommendations.append(ClinicalRecommendation(
            category="ç›‘æµ‹ç®¡ç†",
            priority="MEDIUM",
            action=strategy['monitoring'],
            rationale="è„†æ€§è¡€ç³–éœ€è¦åŠ å¼ºç›‘æµ‹",
            expected_outcome="åŠæ—¶å‘ç°è¡€ç³–å¼‚å¸¸ï¼Œé¢„é˜²ä¸¥é‡äº‹ä»¶",
            monitoring_plan="æ ¹æ®è„†æ€§ç±»å‹è°ƒæ•´ç›‘æµ‹é¢‘ç‡"
        ))
        
        # 4. åŸºäºè„†æ€§ç±»å‹çš„ç‰¹æ®Šå»ºè®®
        if profile.type == BrittlenessType.CHAOTIC:
            recommendations.append(ClinicalRecommendation(
                category="å®‰å…¨æªæ–½",
                priority="CRITICAL",
                action="å»ºç«‹ä¸¥æ ¼çš„ä½è¡€ç³–é¢„é˜²åè®®",
                rationale="æ··æ²Œç³»ç»Ÿå­˜åœ¨æé«˜çš„ä½è¡€ç³–é£é™©",
                expected_outcome="é˜²æ­¢ä¸¥é‡ä½è¡€ç³–äº‹ä»¶",
                monitoring_plan="24å°æ—¶CGMç›‘æ§ï¼Œè®¾ç½®ä¿å®ˆæŠ¥è­¦é˜ˆå€¼",
                contraindications=["å¼ºåŒ–æ²»ç–—", "å¿«é€Ÿå‰‚é‡è°ƒæ•´", "ä¸¥æ ¼è¡€ç³–ç›®æ ‡"]
            ))
        
        elif profile.type == BrittlenessType.FREQUENCY_DOMAIN:
            recommendations.append(ClinicalRecommendation(
                category="èŠ‚å¾‹æ²»ç–—",
                priority="HIGH",
                action="å®æ–½å…‰ç…§æ²»ç–—å’Œç”Ÿæ´»èŠ‚å¾‹å¹²é¢„",
                rationale="é¢‘åŸŸè„†æ€§éœ€è¦é‡å»ºç”Ÿç‰©èŠ‚å¾‹",
                expected_outcome="æ¢å¤æ­£å¸¸æ˜¼å¤œè¡€ç³–èŠ‚å¾‹",
                monitoring_plan="ç›‘æµ‹ç”Ÿç‰©èŠ‚å¾‹æŒ‡æ ‡å’Œè¡€ç³–æ¨¡å¼"
            ))
        
        elif profile.type == BrittlenessType.STOCHASTIC:
            recommendations.append(ClinicalRecommendation(
                category="æŠ€æœ¯æ”¯æŒ",
                priority="HIGH",
                action="è€ƒè™‘èƒ°å²›ç´ æ³µæˆ–é—­ç¯ç³»ç»Ÿ",
                rationale="éšæœºè„†æ€§éœ€è¦æ™ºèƒ½åŒ–æ²»ç–—",
                expected_outcome="é€šè¿‡ç®—æ³•è‡ªåŠ¨è°ƒæ•´åº”å¯¹éšæœºå˜åŒ–",
                monitoring_plan="è¿ç»­CGMé…åˆæ™ºèƒ½ç®—æ³•ç›‘æµ‹"
            ))
        
        # 5. é£é™©ç®¡ç†å»ºè®®
        if profile.risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]:
            recommendations.append(ClinicalRecommendation(
                category="é£é™©ç®¡ç†",
                priority="CRITICAL",
                action="åˆ¶å®šä¸ªæ€§åŒ–ç´§æ€¥é¢„æ¡ˆ",
                rationale=f"{profile.risk_level.value}éœ€è¦ç‰¹æ®Šé£é™©ç®¡ç†",
                expected_outcome="é™ä½è¡€ç³–ç›¸å…³ä¸è‰¯äº‹ä»¶é£é™©",
                monitoring_plan="åŠ å¼ºæ‚£è€…æ•™è‚²å’Œå®¶å±åŸ¹è®­"
            ))
        
        return recommendations
    
    def generate_brittleness_report(self, glucose_data: np.ndarray,
                                  patient_id: str = "Unknown",
                                  patient_info: dict = None) -> dict:
        """
        ç”Ÿæˆè¡€ç³–è„†æ€§åˆ†ææŠ¥å‘Š
        """
        print(f"ğŸ©º {self.agent_name} å¼€å§‹ç”Ÿæˆè„†æ€§æŠ¥å‘Š...")
        
        # 1. åˆ†æè„†æ€§æ¡£æ¡ˆ
        profile = self.analyze_brittleness_profile(glucose_data, patient_info=patient_info)
        
        # 2. ç”Ÿæˆä¸´åºŠå»ºè®®
        recommendations = self.generate_clinical_recommendations(profile, patient_info)
        
        # 3. é¢„åè¯„ä¼°
        prognosis = self._assess_prognosis(profile)
        
        # 4. æ„å»ºæŠ¥å‘Š
        report = {
            'agent_info': {
                'name': self.agent_name,
                'version': self.version,
                'analysis_time': datetime.now().isoformat(),
                'patient_id': patient_id
            },
            'brittleness_profile': {
                'type': profile.type.value,
                'severity_score': profile.severity_score,
                'risk_level': profile.risk_level.value,
                'clinical_features': profile.clinical_features,
                'treatment_strategy': profile.treatment_strategy
            },
            'chaos_analysis': profile.chaos_indicators,
            'clinical_recommendations': [
                {
                    'category': rec.category,
                    'priority': rec.priority,
                    'action': rec.action,
                    'rationale': rec.rationale,
                    'expected_outcome': rec.expected_outcome,
                    'monitoring_plan': rec.monitoring_plan,
                    'contraindications': rec.contraindications or []
                }
                for rec in recommendations
            ],
            'prognosis_assessment': prognosis,
            'follow_up_plan': self._create_follow_up_plan(profile)
        }
        
        print(f"âœ… è„†æ€§æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        return report
    
    def _assess_prognosis(self, profile: BrittlenessProfile) -> dict:
        """è¯„ä¼°é¢„å"""
        prognosis_map = {
            BrittlenessType.STABLE: {
                'short_term': 'Excellent',
                'long_term': 'Good',
                'key_concerns': ['é¢„é˜²æ¶åŒ–', 'ç»´æŒç°çŠ¶']
            },
            BrittlenessType.QUASI_PERIODIC: {
                'short_term': 'Good',
                'long_term': 'Fair',
                'key_concerns': ['èŠ‚å¾‹ç¨³å®š', 'é¢„é˜²æ··æ²ŒåŒ–']
            },
            BrittlenessType.STOCHASTIC: {
                'short_term': 'Fair',
                'long_term': 'Guarded',
                'key_concerns': ['å¹¶å‘ç—‡é£é™©', 'æ²»ç–—å¤æ‚æ€§']
            },
            BrittlenessType.CHAOTIC: {
                'short_term': 'Guarded',
                'long_term': 'Poor',
                'key_concerns': ['ä¸¥é‡ä½è¡€ç³–', 'ç³»ç»Ÿä¸ç¨³å®š']
            },
            BrittlenessType.MEMORY_LOSS: {
                'short_term': 'Fair',
                'long_term': 'Guarded',
                'key_concerns': ['è®¤çŸ¥åŠŸèƒ½', 'æ²»ç–—ä¾ä»æ€§']
            },
            BrittlenessType.FREQUENCY_DOMAIN: {
                'short_term': 'Good',
                'long_term': 'Fair',
                'key_concerns': ['èŠ‚å¾‹é‡å»º', 'ç”Ÿæ´»è´¨é‡']
            }
        }
        
        return prognosis_map.get(profile.type, {
            'short_term': 'Unknown',
            'long_term': 'Unknown',
            'key_concerns': ['éœ€è¦è¿›ä¸€æ­¥è¯„ä¼°']
        })
    
    def _create_follow_up_plan(self, profile: BrittlenessProfile) -> dict:
        """åˆ¶å®šéšè®¿è®¡åˆ’"""
        base_intervals = {
            BrittlenessType.CHAOTIC: {'clinic': '2-4å‘¨', 'cgm_review': 'æ¯å‘¨'},
            BrittlenessType.STOCHASTIC: {'clinic': '4-6å‘¨', 'cgm_review': '2å‘¨'},
            BrittlenessType.QUASI_PERIODIC: {'clinic': '6-8å‘¨', 'cgm_review': '2-4å‘¨'},
            BrittlenessType.MEMORY_LOSS: {'clinic': '4-6å‘¨', 'cgm_review': '2å‘¨'},
            BrittlenessType.FREQUENCY_DOMAIN: {'clinic': '6-8å‘¨', 'cgm_review': '2-4å‘¨'},
            BrittlenessType.STABLE: {'clinic': '3-6ä¸ªæœˆ', 'cgm_review': 'æœˆåº¦'}
        }
        
        intervals = base_intervals.get(profile.type, {'clinic': '6-8å‘¨', 'cgm_review': 'æœˆåº¦'})
        
        return {
            'clinic_visit_interval': intervals['clinic'],
            'cgm_data_review': intervals['cgm_review'],
            'key_monitoring_points': [
                'è„†æ€§æŒ‡æ ‡å˜åŒ–',
                'æ²»ç–—ååº”è¯„ä¼°',
                'ä¸è‰¯äº‹ä»¶ç›‘æµ‹',
                'ç”Ÿæ´»è´¨é‡è¯„ä¼°'
            ],
            'adjustment_triggers': [
                'è„†æ€§ç±»å‹æ”¹å˜',
                'ä¸¥é‡ç¨‹åº¦æ¶åŒ–',
                'æ–°å‡ºç°å®‰å…¨äº‹ä»¶'
            ]
        }
    
    # æ··æ²Œåˆ†æç®—æ³•å®ç°
    def _calculate_lyapunov(self, data: np.ndarray) -> float:
        """è®¡ç®—LyapunovæŒ‡æ•°"""
        if len(data) < 10:
            return 0
        
        # ç®€åŒ–çš„LyapunovæŒ‡æ•°è®¡ç®—
        diff_data = np.diff(data)
        if len(diff_data) < 2:
            return 0
        
        # è®¡ç®—ç›¸é‚»å·®å€¼çš„å‘æ•£ç‡
        divergences = []
        for i in range(1, len(diff_data)):
            if abs(diff_data[i-1]) > 1e-10:
                divergence = abs(diff_data[i] / diff_data[i-1])
                if divergence > 0:
                    divergences.append(np.log(divergence))
        
        if not divergences:
            return 0
        
        return np.mean(divergences)
    
    def _calculate_approximate_entropy(self, data: np.ndarray, m: int = 2, r: float = 0.2) -> float:
        """è®¡ç®—è¿‘ä¼¼ç†µ"""
        N = len(data)
        if N < m + 1:
            return 0
        
        def _maxdist(xi, xj):
            return max([abs(ua - va) for ua, va in zip(xi, xj)])
        
        def _phi(m):
            patterns = np.array([data[i:i+m] for i in range(N-m+1)])
            C = np.zeros(N-m+1)
            
            for i in range(N-m+1):
                template = patterns[i]
                matches = sum(1 for j in range(N-m+1) 
                            if _maxdist(template, patterns[j]) <= r * np.std(data))
                C[i] = matches / float(N-m+1)
            
            phi = np.mean([np.log(c) for c in C if c > 0])
            return phi
        
        return _phi(m) - _phi(m+1)
    
    def _calculate_shannon_entropy(self, data: np.ndarray, bins: int = 50) -> float:
        """è®¡ç®—Shannonç†µ"""
        hist, _ = np.histogram(data, bins=bins)
        hist = hist[hist > 0]
        prob = hist / np.sum(hist)
        return -np.sum(prob * np.log2(prob))
    
    def _calculate_hurst_exponent(self, data: np.ndarray) -> float:
        """
        è®¡ç®—HurstæŒ‡æ•° - ç¨³å®šç‰ˆæœ¬
        ä½¿ç”¨å¤šçª—å£R/Såˆ†æï¼Œæä¾›æ›´ç¨³å®šçš„é•¿ç¨‹è®°å¿†ç‰¹æ€§åº¦é‡
        """
        if len(data) < 20:
            return 0.5
        
        # æ•°æ®é¢„å¤„ç†ï¼šå»è¶‹åŠ¿å’Œæ ‡å‡†åŒ–
        from scipy import signal
        detrended = signal.detrend(data)
        
        # å¤šæ—¶é—´çª—å£è®¾è®¡
        n = len(data)
        min_window = 10
        max_window = min(n // 4, 200)  # é™åˆ¶æœ€å¤§çª—å£
        
        if max_window <= min_window:
            return 0.5
        
        # å¯¹æ•°ç­‰é—´è·çª—å£å¤§å°
        window_sizes = np.unique(np.logspace(
            np.log10(min_window), 
            np.log10(max_window), 
            12
        ).astype(int))
        
        rs_values = []
        valid_windows = []
        
        for window_size in window_sizes:
            if window_size >= n or window_size < min_window:
                continue
                
            # æ»‘åŠ¨çª—å£R/Såˆ†æ
            rs_list = []
            num_windows = n - window_size + 1
            step = max(1, num_windows // 10)  # æœ€å¤šå–10ä¸ªçª—å£
            
            for i in range(0, num_windows, step):
                segment = detrended[i:i + window_size]
                
                if len(segment) != window_size:
                    continue
                
                # ç´¯ç§¯åå·®åºåˆ—
                mean_segment = np.mean(segment)
                cumulative_deviate = np.cumsum(segment - mean_segment)
                
                # R: ç´¯ç§¯åå·®çš„èŒƒå›´
                R = np.max(cumulative_deviate) - np.min(cumulative_deviate)
                
                # S: æ ‡å‡†å·®
                S = np.std(segment, ddof=1)  # ä½¿ç”¨æ— åæ ‡å‡†å·®
                
                # R/Sæ¯”å€¼
                if S > 1e-10 and R > 1e-10:  # é¿å…æ•°å€¼é—®é¢˜
                    rs_list.append(R / S)
            
            if len(rs_list) >= 3:  # è‡³å°‘éœ€è¦3ä¸ªæœ‰æ•ˆæ ·æœ¬
                rs_mean = np.mean(rs_list)
                if rs_mean > 0:
                    rs_values.append(rs_mean)
                    valid_windows.append(window_size)
        
        # æ£€æŸ¥æœ‰æ•ˆæ€§
        if len(rs_values) < 3:
            return 0.5
        
        # çº¿æ€§å›å½’ log(R/S) vs log(n)
        log_windows = np.log(valid_windows)
        log_rs = np.log(rs_values)
        
        # è¿‡æ»¤æ— ç©·å€¼å’ŒNaN
        valid_mask = np.isfinite(log_windows) & np.isfinite(log_rs)
        
        if np.sum(valid_mask) < 3:
            return 0.5
        
        # ç¨³å¥çš„çº¿æ€§æ‹Ÿåˆ
        try:
            coeffs = np.polyfit(log_windows[valid_mask], log_rs[valid_mask], 1)
            hurst = coeffs[0]
            
            # HurstæŒ‡æ•°åˆç†æ€§æ£€æŸ¥
            # ç†è®ºèŒƒå›´: 0 < H < 1
            # H = 0.5: éšæœºæ¸¸èµ°ï¼ˆæ— è®°å¿†ï¼‰
            # H > 0.5: é•¿ç¨‹æ­£ç›¸å…³ï¼ˆè¶‹åŠ¿æŒç»­ï¼‰
            # H < 0.5: é•¿ç¨‹è´Ÿç›¸å…³ï¼ˆåè¶‹åŠ¿ï¼‰
            hurst = max(0.05, min(0.95, hurst))
            
            return float(hurst)
            
        except (np.linalg.LinAlgError, ValueError):
            return 0.5
    
    def _calculate_fractal_dimension(self, data: np.ndarray) -> float:
        """è®¡ç®—åˆ†å½¢ç»´åº¦"""
        # ç®€åŒ–çš„åˆ†å½¢ç»´åº¦è®¡ç®—
        if len(data) < 4:
            return 1.5
        
        # ä½¿ç”¨Higuchiæ–¹æ³•çš„ç®€åŒ–ç‰ˆæœ¬
        k_max = min(10, len(data) // 4)
        lk = []
        
        for k in range(1, k_max + 1):
            lm = []
            for m in range(k):
                indices = np.arange(m, len(data), k)
                if len(indices) < 2:
                    continue
                subset = data[indices]
                length = np.sum(np.abs(np.diff(subset))) * (len(data) - 1) / (len(indices) - 1) / k
                lm.append(length)
            
            if lm:
                lk.append(np.mean(lm))
        
        if len(lk) < 2:
            return 1.5
        
        # æ‹Ÿåˆç›´çº¿æ±‚æ–œç‡
        x = np.log(range(1, len(lk) + 1))
        y = np.log(lk)
        
        try:
            slope = np.polyfit(x, y, 1)[0]
            return 2 - slope
        except:
            return 1.5
    
    def _calculate_correlation_dimension(self, data: np.ndarray) -> float:
        """è®¡ç®—å…³è”ç»´æ•°"""
        # ç®€åŒ–çš„å…³è”ç»´æ•°è®¡ç®—
        if len(data) < 10:
            return 2.0
        
        # ä½¿ç”¨ç®€åŒ–çš„Grassberger-Procacciaç®—æ³•
        m = 3  # åµŒå…¥ç»´æ•°
        embedded = np.array([data[i:i+m] for i in range(len(data)-m+1)])
        
        if len(embedded) < 2:
            return 2.0
        
        # è®¡ç®—è·ç¦»çŸ©é˜µ
        distances = []
        for i in range(len(embedded)):
            for j in range(i+1, len(embedded)):
                dist = np.linalg.norm(embedded[i] - embedded[j])
                distances.append(dist)
        
        if not distances:
            return 2.0
        
        # ç®€åŒ–çš„å…³è”ç»´æ•°ä¼°ç®—
        distances = np.array(distances)
        median_dist = np.median(distances)
        
        if median_dist == 0:
            return 2.0
        
        correlation_sum = np.sum(distances < median_dist) / len(distances)
        
        if correlation_sum <= 0:
            return 2.0
        
        return np.log(correlation_sum) / np.log(median_dist / np.max(distances))

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    advisor = BrittlenessClinicalAdvisor()
    print(f"âœ… {advisor.agent_name} åˆå§‹åŒ–å®Œæˆ")
    print(f"ğŸ§¬ æ”¯æŒ6ç§è¡€ç³–è„†æ€§ç±»å‹åˆ†æ")
    print(f"ğŸ’Š æä¾›ä¸ªæ€§åŒ–ä¸´åºŠæ²»ç–—å»ºè®®")