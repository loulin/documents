#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AGPAIæ‰¹é‡åˆ†æè„šæœ¬
æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªæ‚£è€…çš„CGMæ•°æ®
"""

import os
import json
from datetime import datetime
from AGPAI_Agent_V2 import AGPAI_Agent_V2

def batch_analyze_patients(data_directory, output_directory="./reports"):
    """
    æ‰¹é‡åˆ†ææ‚£è€…æ•°æ®
    
    Args:
        data_directory: CGMæ•°æ®æ–‡ä»¶ç›®å½•
        output_directory: è¾“å‡ºæŠ¥å‘Šç›®å½•
    """
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_directory, exist_ok=True)
    
    # åˆå§‹åŒ–Agent
    agent = AGPAI_Agent_V2()
    
    # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
    supported_extensions = ['.txt', '.csv']
    
    # æ‰«ææ•°æ®æ–‡ä»¶
    data_files = []
    for file in os.listdir(data_directory):
        if any(file.lower().endswith(ext) for ext in supported_extensions):
            data_files.append(file)
    
    print(f"ğŸ” å‘ç° {len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    
    results_summary = []
    
    for i, filename in enumerate(data_files, 1):
        try:
            print(f"\nğŸ“Š æ­£åœ¨åˆ†æ {i}/{len(data_files)}: {filename}")
            
            # æå–æ‚£è€…IDï¼ˆä»æ–‡ä»¶åï¼‰
            patient_id = os.path.splitext(filename)[0]
            file_path = os.path.join(data_directory, filename)
            
            # æ‰§è¡Œåˆ†æ
            report = agent.generate_comprehensive_report(
                patient_id=patient_id,
                cgm_file_path=file_path,
                include_historical=True
            )
            
            # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
            report_file = os.path.join(output_directory, f"{patient_id}_report.md")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            # è·å–åˆ†ææ•°æ®
            analysis_data = agent._get_last_analysis_data()  # éœ€è¦æ·»åŠ è¿™ä¸ªæ–¹æ³•
            
            # ä¿å­˜JSONæ•°æ®
            json_file = os.path.join(output_directory, f"{patient_id}_data.json")
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=2)
            
            # è®°å½•æˆåŠŸ
            results_summary.append({
                'patient_id': patient_id,
                'status': 'success',
                'report_file': report_file,
                'json_file': json_file,
                'timestamp': datetime.now().isoformat()
            })
            
            print(f"âœ… å®Œæˆ: {patient_id}")
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {filename} - {str(e)}")
            results_summary.append({
                'patient_id': patient_id,
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })
    
    # ä¿å­˜æ±‡æ€»ç»“æœ
    summary_file = os.path.join(output_directory, "batch_analysis_summary.json")
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°æ±‡æ€»
    success_count = sum(1 for r in results_summary if r['status'] == 'success')
    error_count = len(results_summary) - success_count
    
    print(f"\nğŸ“‹ æ‰¹é‡åˆ†æå®Œæˆ:")
    print(f"   âœ… æˆåŠŸ: {success_count} ä¸ª")
    print(f"   âŒ å¤±è´¥: {error_count} ä¸ª")
    print(f"   ğŸ“‚ è¾“å‡ºç›®å½•: {output_directory}")
    print(f"   ğŸ“„ æ±‡æ€»æ–‡ä»¶: {summary_file}")

def analyze_single_patient(file_path, patient_id=None, output_dir="./reports"):
    """
    åˆ†æå•ä¸ªæ‚£è€…
    
    Args:
        file_path: CGMæ•°æ®æ–‡ä»¶è·¯å¾„
        patient_id: æ‚£è€…IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»æ–‡ä»¶åæå–ï¼‰
        output_dir: è¾“å‡ºç›®å½•
    """
    
    if patient_id is None:
        patient_id = os.path.splitext(os.path.basename(file_path))[0]
    
    print(f"ğŸ©º åˆ†ææ‚£è€…: {patient_id}")
    print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {file_path}")
    
    try:
        # åˆå§‹åŒ–Agent
        agent = AGPAI_Agent_V2()
        
        # æ‰§è¡Œåˆ†æ
        report = agent.generate_comprehensive_report(
            patient_id=patient_id,
            cgm_file_path=file_path,
            include_historical=True
        )
        
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        print("\n" + "="*60)
        print(report)
        print("="*60)
        
        # ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
            report_file = os.path.join(output_dir, f"{patient_id}_report.md")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return report
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
        return None

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  å•ä¸ªæ–‡ä»¶åˆ†æ: python3 batch_analysis.py single /path/to/file.txt")
        print("  æ‰¹é‡åˆ†æ:     python3 batch_analysis.py batch /path/to/directory")
        print("  ç¤ºä¾‹:")
        print("    python3 batch_analysis.py single './R002 v11.txt'")
        print("    python3 batch_analysis.py batch '/path/to/cgm/data/folder'")
        sys.exit(1)
    
    mode = sys.argv[1]
    
    if mode == "single":
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾›æ–‡ä»¶è·¯å¾„")
            sys.exit(1)
        
        file_path = sys.argv[2]
        patient_id = sys.argv[3] if len(sys.argv) > 3 else None
        
        analyze_single_patient(file_path, patient_id)
        
    elif mode == "batch":
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾›æ•°æ®ç›®å½•è·¯å¾„")
            sys.exit(1)
        
        data_dir = sys.argv[2]
        output_dir = sys.argv[3] if len(sys.argv) > 3 else "./reports"
        
        batch_analyze_patients(data_dir, output_dir)
        
    else:
        print(f"âŒ æœªçŸ¥æ¨¡å¼: {mode}")
        print("æ”¯æŒçš„æ¨¡å¼: single, batch")
        sys.exit(1)