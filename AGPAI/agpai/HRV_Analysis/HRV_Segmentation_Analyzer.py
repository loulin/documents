#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
HRV_Segmentation_Analyzer.py

HRVæ™ºèƒ½åˆ†æ®µåˆ†æå™¨ - åŸºäºAgent2 v5.0æ™ºèƒ½åˆ†æ®µæ¶æ„
ä¸“é—¨ç”¨äºHRVæ•°æ®çš„è®­ç»ƒé˜¶æ®µè¯†åˆ«ã€æ¢å¤çŠ¶æ€åˆ†æ®µå’Œè‡ªä¸»ç¥ç»åŠŸèƒ½æ¼”å˜åˆ†æ

ä½œè€…: AGPAI Team
ç‰ˆæœ¬: v1.0
æ—¥æœŸ: 2025-08-28
"""

import numpy as np
import pandas as pd
from scipy import signal
from scipy.stats import chi2_contingency
import json
from datetime import datetime, timedelta
from enum import Enum

class HRVDataStatus(Enum):
    """HRVæ•°æ®çŠ¶æ€"""
    TRAINING = "training"          # è®­ç»ƒç›‘æµ‹æ•°æ®
    RECOVERY = "recovery"          # æ¢å¤ç›‘æµ‹æ•°æ®
    CLINICAL = "clinical"          # ä¸´åºŠç›‘æµ‹æ•°æ®
    RESEARCH = "research"          # ç§‘ç ”æ•°æ®
    REALTIME = "realtime"          # å®æ—¶ç›‘æµ‹

class HRVSegmentationAnalyzer:
    """HRVæ™ºèƒ½åˆ†æ®µåˆ†æå™¨"""
    
    def __init__(self):
        self.segmentation_modes = {
            'auto': 'æ™ºèƒ½è‡ªåŠ¨é€‰æ‹©',
            'training_phases': 'è®­ç»ƒé˜¶æ®µåˆ†æ®µ',
            'recovery_monitoring': 'æ¢å¤ç›‘æµ‹åˆ†æ®µ',
            'circadian_rhythm': 'æ˜¼å¤œèŠ‚å¾‹åˆ†æ®µ',
            'autonomic_balance': 'è‡ªä¸»ç¥ç»å¹³è¡¡åˆ†æ®µ',
            'dual': 'åŒæ¨¡å¼åˆ†æ'
        }
        
        # HRVå˜åŒ–æ˜¾è‘—æ€§é˜ˆå€¼
        self.change_thresholds = {
            'RMSSD': 15,      # ms
            'LF_HF_ratio': 0.5,
            'heart_rate': 10   # bpm
        }
    
    def detect_data_status(self, rr_intervals, timestamps=None, context_info=None):
        """æ™ºèƒ½æ£€æµ‹HRVæ•°æ®çŠ¶æ€"""
        try:
            duration_hours = len(rr_intervals) * np.mean(rr_intervals) / 1000 / 3600
            mean_hr = 60000 / np.mean(rr_intervals)
            
            # åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯åˆ¤æ–­
            if context_info:
                if 'training' in context_info.lower() or 'exercise' in context_info.lower():
                    data_status = HRVDataStatus.TRAINING
                elif 'recovery' in context_info.lower() or 'rest' in context_info.lower():
                    data_status = HRVDataStatus.RECOVERY
                elif 'clinical' in context_info.lower() or 'patient' in context_info.lower():
                    data_status = HRVDataStatus.CLINICAL
                else:
                    data_status = HRVDataStatus.RESEARCH
            else:
                # åŸºäºæ•°æ®ç‰¹å¾è‡ªåŠ¨åˆ¤æ–­
                if duration_hours < 2 and mean_hr > 90:
                    data_status = HRVDataStatus.TRAINING
                elif duration_hours < 8 and mean_hr < 70:
                    data_status = HRVDataStatus.RECOVERY
                elif duration_hours >= 20:
                    data_status = HRVDataStatus.CLINICAL
                else:
                    data_status = HRVDataStatus.RESEARCH
            
            return {
                "æ•°æ®çŠ¶æ€": data_status.value,
                "æ•°æ®æ—¶é•¿": f"{duration_hours:.1f}å°æ—¶",
                "æ•°æ®ç‚¹æ•°": len(rr_intervals),
                "å¹³å‡å¿ƒç‡": f"{mean_hr:.1f} bpm",
                "æ¨èåˆ†æ®µæ¨¡å¼": self.recommend_segmentation_mode(data_status)
            }
        except:
            return {
                "æ•°æ®çŠ¶æ€": HRVDataStatus.RESEARCH.value,
                "æ¨èåˆ†æ®µæ¨¡å¼": "autonomic_balance"
            }
    
    def recommend_segmentation_mode(self, data_status):
        """æ ¹æ®æ•°æ®çŠ¶æ€æ¨èåˆ†æ®µæ¨¡å¼"""
        recommendations = {
            HRVDataStatus.TRAINING: "training_phases",      # è®­ç»ƒæ•°æ®å…³æ³¨è®­ç»ƒé˜¶æ®µ
            HRVDataStatus.RECOVERY: "recovery_monitoring",  # æ¢å¤æ•°æ®å…³æ³¨æ¢å¤é˜¶æ®µ
            HRVDataStatus.CLINICAL: "circadian_rhythm",     # ä¸´åºŠæ•°æ®å…³æ³¨æ˜¼å¤œèŠ‚å¾‹
            HRVDataStatus.RESEARCH: "autonomic_balance",    # ç§‘ç ”æ•°æ®å…³æ³¨è‡ªä¸»ç¥ç»
            HRVDataStatus.REALTIME: "dual"                  # å®æ—¶æ•°æ®åŒæ¨¡å¼åˆ†æ
        }
        return recommendations.get(data_status, "autonomic_balance")
    
    def extract_hrv_features_windowed(self, rr_intervals, window_size_minutes=5):
        """æå–æ»‘åŠ¨çª—å£HRVç‰¹å¾"""
        window_size_beats = int(window_size_minutes * 60 / (np.mean(rr_intervals) / 1000))
        window_size_beats = max(50, min(window_size_beats, len(rr_intervals) // 10))
        
        features = []
        
        for i in range(0, len(rr_intervals) - window_size_beats, window_size_beats // 4):
            window_rr = rr_intervals[i:i + window_size_beats]
            
            if len(window_rr) < 20:
                continue
            
            # æ—¶åŸŸHRVæŒ‡æ ‡
            rmssd = np.sqrt(np.mean(np.diff(window_rr) ** 2))
            sdnn = np.std(window_rr)
            pnn50 = (np.sum(np.abs(np.diff(window_rr)) > 50) / (len(window_rr) - 1)) * 100
            mean_hr = 60000 / np.mean(window_rr)
            
            # é¢‘åŸŸHRVæŒ‡æ ‡ (ç®€åŒ–ç‰ˆæœ¬)
            try:
                # æ’å€¼åˆ°ç­‰é—´éš”æ—¶é—´åºåˆ—
                time_points = np.cumsum(window_rr) / 1000
                time_uniform = np.arange(0, time_points[-1], 0.25)  # 4Hzé‡‡æ ·
                rr_interpolated = np.interp(time_uniform, time_points[:-1], window_rr[:-1])
                
                # åŠŸç‡è°±å¯†åº¦
                f, psd = signal.welch(signal.detrend(rr_interpolated), fs=4, nperseg=min(64, len(rr_interpolated)))
                
                lf_mask = (f >= 0.04) & (f < 0.15)
                hf_mask = (f >= 0.15) & (f < 0.4)
                
                lf_power = np.sum(psd[lf_mask])
                hf_power = np.sum(psd[hf_mask])
                lf_hf_ratio = lf_power / hf_power if hf_power > 0 else 0
            except:
                lf_hf_ratio = 0
            
            # å¤æ‚æ€§æŒ‡æ ‡
            complexity = self.calculate_simple_complexity(window_rr)
            
            feature_dict = {
                'start_beat': i,
                'window_center_time_min': (i + window_size_beats // 2) * np.mean(rr_intervals) / 1000 / 60,
                'RMSSD': rmssd,
                'SDNN': sdnn,
                'pNN50': pnn50,
                'mean_HR': mean_hr,
                'LF_HF_ratio': lf_hf_ratio,
                'complexity': complexity
            }
            
            features.append(feature_dict)
        
        return features
    
    def calculate_simple_complexity(self, rr_intervals):
        """è®¡ç®—ç®€å•çš„å¤æ‚æ€§æŒ‡æ ‡"""
        try:
            if len(rr_intervals) < 10:
                return 0
            
            # åŸºäºç›¸é‚»RRé—´æœŸå·®å€¼çš„å˜å¼‚æ€§
            diff_rr = np.diff(rr_intervals)
            complexity = np.std(diff_rr) / np.mean(rr_intervals) if np.mean(rr_intervals) > 0 else 0
            return complexity
        except:
            return 0
    
    def detect_hrv_change_points(self, features, method='multi_parameter'):
        """HRVå˜åŒ–ç‚¹æ£€æµ‹"""
        change_points = []
        
        if len(features) < 6:
            return change_points
        
        if method == 'multi_parameter':
            change_points = self.multi_parameter_change_detection(features)
        elif method == 'autonomic_balance':
            change_points = self.autonomic_balance_change_detection(features)
        else:
            change_points = self.training_phase_detection(features)
        
        return change_points
    
    def multi_parameter_change_detection(self, features):
        """å¤šå‚æ•°HRVå˜åŒ–ç‚¹æ£€æµ‹"""
        change_points = []
        
        # æå–å…³é”®å‚æ•°åºåˆ—
        rmssd_series = [f['RMSSD'] for f in features]
        hr_series = [f['mean_HR'] for f in features]
        lf_hf_series = [f['LF_HF_ratio'] for f in features]
        
        # æ»‘åŠ¨çª—å£ç»Ÿè®¡æ£€éªŒ
        window_size = 5
        for i in range(window_size, len(features) - window_size):
            
            # RMSSDå˜åŒ–æ£€æµ‹
            before_rmssd = np.mean(rmssd_series[i-window_size:i])
            after_rmssd = np.mean(rmssd_series[i:i+window_size])
            rmssd_change = abs(after_rmssd - before_rmssd)
            
            # å¿ƒç‡å˜åŒ–æ£€æµ‹
            before_hr = np.mean(hr_series[i-window_size:i])
            after_hr = np.mean(hr_series[i:i+window_size])
            hr_change = abs(after_hr - before_hr)
            
            # LF/HFæ¯”å€¼å˜åŒ–æ£€æµ‹
            before_lf_hf = np.mean(lf_hf_series[i-window_size:i])
            after_lf_hf = np.mean(lf_hf_series[i:i+window_size])
            lf_hf_change = abs(after_lf_hf - before_lf_hf)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ˜¾è‘—å˜åŒ–ç‚¹
            significant_changes = 0
            change_details = []
            
            if rmssd_change > self.change_thresholds['RMSSD']:
                significant_changes += 1
                change_details.append(f"RMSSDå˜åŒ–{rmssd_change:.1f}ms")
            
            if hr_change > self.change_thresholds['heart_rate']:
                significant_changes += 1
                change_details.append(f"å¿ƒç‡å˜åŒ–{hr_change:.1f}bpm")
            
            if lf_hf_change > self.change_thresholds['LF_HF_ratio']:
                significant_changes += 1
                change_details.append(f"LF/HFå˜åŒ–{lf_hf_change:.2f}")
            
            if significant_changes >= 2:
                change_point = {
                    'feature_index': i,
                    'time_minutes': features[i]['window_center_time_min'],
                    'significance_score': significant_changes,
                    'change_type': self.classify_hrv_change_type(features[i-1], features[i]),
                    'change_details': change_details
                }
                change_points.append(change_point)
        
        return change_points
    
    def classify_hrv_change_type(self, before_features, after_features):
        """åˆ†ç±»HRVå˜åŒ–ç±»å‹"""
        hr_change = after_features['mean_HR'] - before_features['mean_HR']
        rmssd_change = after_features['RMSSD'] - before_features['RMSSD']
        lf_hf_change = after_features['LF_HF_ratio'] - before_features['LF_HF_ratio']
        
        if hr_change > 20:
            return "å¿ƒç‡ä¸Šå‡é˜¶æ®µ"
        elif hr_change < -20:
            return "å¿ƒç‡ä¸‹é™é˜¶æ®µ"
        elif rmssd_change > 15:
            return "å‰¯äº¤æ„Ÿæ¿€æ´»"
        elif rmssd_change < -15:
            return "å‰¯äº¤æ„ŸæŠ‘åˆ¶"
        elif lf_hf_change > 1.0:
            return "äº¤æ„Ÿç¥ç»æ¿€æ´»"
        elif lf_hf_change < -1.0:
            return "äº¤æ„Ÿç¥ç»æŠ‘åˆ¶"
        else:
            return "ç»¼åˆè°ƒèŠ‚å˜åŒ–"
    
    def analyze_training_phases(self, rr_intervals, change_points):
        """è®­ç»ƒé˜¶æ®µåˆ†æ®µåˆ†æ"""
        if not change_points:
            # é»˜è®¤è®­ç»ƒä¸‰é˜¶æ®µï¼šçƒ­èº«-ä¸»è®­ç»ƒ-æ¢å¤
            segments = self.create_training_default_segments(rr_intervals)
        else:
            segments = self.create_training_adaptive_segments(rr_intervals, change_points)
        
        return {
            "åˆ†æ®µæ¨¡å¼": "è®­ç»ƒé˜¶æ®µåˆ†æ®µ",
            "åˆ†æ®µæ•°é‡": len(segments),
            "åˆ†æ®µè¯¦æƒ…": segments,
            "ä¸´åºŠåº”ç”¨": "é€‚ç”¨äºè¿åŠ¨å‘˜è®­ç»ƒç›‘æµ‹å’Œè¿åŠ¨å¤„æ–¹åˆ¶å®š"
        }
    
    def create_training_default_segments(self, rr_intervals):
        """åˆ›å»ºé»˜è®¤è®­ç»ƒé˜¶æ®µåˆ†æ®µ"""
        total_duration_min = len(rr_intervals) * np.mean(rr_intervals) / 1000 / 60
        
        segments = []
        
        if total_duration_min <= 30:  # çŸ­æ—¶è®­ç»ƒ
            # çƒ­èº« (å‰20%)ï¼Œä¸»è®­ç»ƒ (ä¸­60%)ï¼Œæ¢å¤ (å20%)
            boundaries = [0, int(0.2 * len(rr_intervals)), 
                         int(0.8 * len(rr_intervals)), len(rr_intervals)]
            phase_names = ["çƒ­èº«é˜¶æ®µ", "ä¸»è®­ç»ƒé˜¶æ®µ", "å³æ—¶æ¢å¤"]
        elif total_duration_min <= 90:  # ä¸­ç­‰è®­ç»ƒ
            # çƒ­èº«ï¼Œä¸»è®­ç»ƒ1ï¼Œä¸»è®­ç»ƒ2ï¼Œæ¢å¤
            boundaries = [0, int(0.15 * len(rr_intervals)), int(0.5 * len(rr_intervals)),
                         int(0.8 * len(rr_intervals)), len(rr_intervals)]
            phase_names = ["çƒ­èº«é˜¶æ®µ", "ä¸»è®­ç»ƒé˜¶æ®µ1", "ä¸»è®­ç»ƒé˜¶æ®µ2", "æ¢å¤é˜¶æ®µ"]
        else:  # é•¿æ—¶è®­ç»ƒ
            # æ›´è¯¦ç»†çš„åˆ†æ®µ
            boundaries = [0, int(0.1 * len(rr_intervals)), int(0.3 * len(rr_intervals)),
                         int(0.7 * len(rr_intervals)), int(0.9 * len(rr_intervals)), len(rr_intervals)]
            phase_names = ["çƒ­èº«", "è®­ç»ƒå¼ºåŒ–1", "è®­ç»ƒå¼ºåŒ–2", "è®­ç»ƒç»´æŒ", "æ¢å¤"]
        
        for i in range(len(boundaries) - 1):
            start_idx = boundaries[i]
            end_idx = boundaries[i + 1]
            segment_rr = rr_intervals[start_idx:end_idx]
            
            segments.append({
                "é˜¶æ®µç¼–å·": i + 1,
                "é˜¶æ®µåç§°": phase_names[i] if i < len(phase_names) else f"é˜¶æ®µ{i+1}",
                "å¼€å§‹æ—¶é—´": f"{start_idx * np.mean(rr_intervals) / 1000 / 60:.1f}åˆ†é’Ÿ",
                "æŒç»­æ—¶é—´": f"{len(segment_rr) * np.mean(segment_rr) / 1000 / 60:.1f}åˆ†é’Ÿ",
                "è®­ç»ƒç‰¹å¾": self.analyze_training_segment(segment_rr)
            })
        
        return segments
    
    def analyze_training_segment(self, segment_rr):
        """åˆ†æè®­ç»ƒåˆ†æ®µç‰¹å¾"""
        try:
            mean_hr = 60000 / np.mean(segment_rr)
            rmssd = np.sqrt(np.mean(np.diff(segment_rr) ** 2))
            
            # è®­ç»ƒå¼ºåº¦è¯„ä¼°
            if mean_hr >= 150:
                intensity = "é«˜å¼ºåº¦"
                zone = "æ— æ°§é˜ˆä»¥ä¸Š"
            elif mean_hr >= 130:
                intensity = "ä¸­é«˜å¼ºåº¦"
                zone = "æœ‰æ°§-æ— æ°§æ··åˆåŒº"
            elif mean_hr >= 110:
                intensity = "ä¸­ç­‰å¼ºåº¦"
                zone = "æœ‰æ°§åŒº"
            elif mean_hr >= 90:
                intensity = "ä½ä¸­å¼ºåº¦"
                zone = "è„‚è‚ªç‡ƒçƒ§åŒº"
            else:
                intensity = "ä½å¼ºåº¦"
                zone = "æ¢å¤åŒº"
            
            # è‡ªä¸»ç¥ç»çŠ¶æ€
            if rmssd >= 40:
                autonomic_state = "å‰¯äº¤æ„Ÿä¸»å¯¼"
            elif rmssd >= 20:
                autonomic_state = "å¹³è¡¡çŠ¶æ€"
            else:
                autonomic_state = "äº¤æ„Ÿä¸»å¯¼"
            
            return {
                "å¹³å‡å¿ƒç‡": f"{mean_hr:.1f} bpm",
                "è®­ç»ƒå¼ºåº¦": intensity,
                "å¿ƒç‡åŒºé—´": zone,
                "HRV(RMSSD)": f"{rmssd:.1f} ms",
                "è‡ªä¸»ç¥ç»çŠ¶æ€": autonomic_state,
                "è®­ç»ƒé€‚åº”æ€§": self.assess_training_adaptation(mean_hr, rmssd)
            }
        except:
            return {"è¯„ä¼°": "æ•°æ®ä¸è¶³"}
    
    def assess_training_adaptation(self, mean_hr, rmssd):
        """è¯„ä¼°è®­ç»ƒé€‚åº”æ€§"""
        # åŸºäºå¿ƒç‡å’ŒHRVçš„ç®€åŒ–è¯„ä¼°
        if mean_hr < 70 and rmssd > 50:
            return "ä¼˜ç§€é€‚åº”æ€§"
        elif mean_hr < 80 and rmssd > 35:
            return "è‰¯å¥½é€‚åº”æ€§"
        elif mean_hr < 90 and rmssd > 25:
            return "ä¸€èˆ¬é€‚åº”æ€§"
        elif mean_hr > 100 and rmssd < 15:
            return "ç–²åŠ³çŠ¶æ€"
        else:
            return "éœ€è¦è¯„ä¼°"
    
    def analyze_recovery_monitoring(self, rr_intervals, change_points):
        """æ¢å¤ç›‘æµ‹åˆ†æ®µåˆ†æ"""
        segments = self.create_recovery_segments(rr_intervals, change_points)
        
        return {
            "åˆ†æ®µæ¨¡å¼": "æ¢å¤ç›‘æµ‹åˆ†æ®µ",
            "åˆ†æ®µæ•°é‡": len(segments),
            "åˆ†æ®µè¯¦æƒ…": segments,
            "ä¸´åºŠåº”ç”¨": "é€‚ç”¨äºè¿åŠ¨æ¢å¤ç›‘æµ‹å’Œç–²åŠ³è¯„ä¼°"
        }
    
    def create_recovery_segments(self, rr_intervals, change_points):
        """åˆ›å»ºæ¢å¤é˜¶æ®µåˆ†æ®µ"""
        total_duration_min = len(rr_intervals) * np.mean(rr_intervals) / 1000 / 60
        
        if not change_points or total_duration_min < 60:
            # é»˜è®¤æ¢å¤é˜¶æ®µï¼šå³æ—¶æ¢å¤-å¿«é€Ÿæ¢å¤-æ…¢é€Ÿæ¢å¤-ç¨³å®šæœŸ
            if total_duration_min <= 30:
                boundaries = [0, len(rr_intervals) // 3, 2 * len(rr_intervals) // 3, len(rr_intervals)]
                phase_names = ["å³æ—¶æ¢å¤", "å¿«é€Ÿæ¢å¤", "è¶‹å‘ç¨³å®š"]
            else:
                boundaries = [0, len(rr_intervals) // 4, len(rr_intervals) // 2, 
                             3 * len(rr_intervals) // 4, len(rr_intervals)]
                phase_names = ["å³æ—¶æ¢å¤", "å¿«é€Ÿæ¢å¤", "æ…¢é€Ÿæ¢å¤", "ç¨³å®šæœŸ"]
        else:
            # åŸºäºå˜åŒ–ç‚¹çš„è‡ªé€‚åº”åˆ†æ®µ
            boundaries = [0] + [cp['feature_index'] * 4 for cp in change_points if cp['feature_index'] * 4 < len(rr_intervals)] + [len(rr_intervals)]
            boundaries = sorted(list(set(boundaries)))
            phase_names = [f"æ¢å¤é˜¶æ®µ{i+1}" for i in range(len(boundaries)-1)]
        
        segments = []
        for i in range(len(boundaries) - 1):
            start_idx = boundaries[i]
            end_idx = boundaries[i + 1]
            segment_rr = rr_intervals[start_idx:end_idx]
            
            segments.append({
                "æ¢å¤é˜¶æ®µ": i + 1,
                "é˜¶æ®µåç§°": phase_names[i] if i < len(phase_names) else f"æ¢å¤{i+1}",
                "å¼€å§‹æ—¶é—´": f"{start_idx * np.mean(rr_intervals) / 1000 / 60:.1f}åˆ†é’Ÿ",
                "æŒç»­æ—¶é—´": f"{len(segment_rr) * np.mean(segment_rr) / 1000 / 60:.1f}åˆ†é’Ÿ",
                "æ¢å¤ç‰¹å¾": self.analyze_recovery_segment(segment_rr)
            })
        
        return segments
    
    def analyze_recovery_segment(self, segment_rr):
        """åˆ†ææ¢å¤åˆ†æ®µç‰¹å¾"""
        try:
            mean_hr = 60000 / np.mean(segment_rr)
            rmssd = np.sqrt(np.mean(np.diff(segment_rr) ** 2))
            hrv_trend = self.calculate_hrv_trend(segment_rr)
            
            # æ¢å¤è´¨é‡è¯„ä¼°
            if mean_hr <= 70 and rmssd >= 40:
                recovery_quality = "ä¼˜ç§€æ¢å¤"
            elif mean_hr <= 80 and rmssd >= 30:
                recovery_quality = "è‰¯å¥½æ¢å¤"
            elif mean_hr <= 90 and rmssd >= 20:
                recovery_quality = "ä¸€èˆ¬æ¢å¤"
            elif mean_hr > 100 or rmssd < 15:
                recovery_quality = "æ¢å¤ä¸è¶³"
            else:
                recovery_quality = "éœ€è¦è¯„ä¼°"
            
            return {
                "å¹³å‡å¿ƒç‡": f"{mean_hr:.1f} bpm",
                "HRV(RMSSD)": f"{rmssd:.1f} ms", 
                "HRVè¶‹åŠ¿": hrv_trend,
                "æ¢å¤è´¨é‡": recovery_quality,
                "å»ºè®®": self.generate_recovery_recommendation(mean_hr, rmssd, recovery_quality)
            }
        except:
            return {"è¯„ä¼°": "æ•°æ®ä¸è¶³"}
    
    def calculate_hrv_trend(self, segment_rr):
        """è®¡ç®—HRVè¶‹åŠ¿"""
        if len(segment_rr) < 100:
            return "æ•°æ®ä¸è¶³"
        
        # åˆ†ä¸ºå‰åŠæ®µå’ŒååŠæ®µæ¯”è¾ƒ
        mid_point = len(segment_rr) // 2
        first_half_rmssd = np.sqrt(np.mean(np.diff(segment_rr[:mid_point]) ** 2))
        second_half_rmssd = np.sqrt(np.mean(np.diff(segment_rr[mid_point:]) ** 2))
        
        rmssd_change = second_half_rmssd - first_half_rmssd
        
        if rmssd_change > 5:
            return "HRVä¸Šå‡"
        elif rmssd_change < -5:
            return "HRVä¸‹é™"
        else:
            return "HRVç¨³å®š"
    
    def generate_recovery_recommendation(self, mean_hr, rmssd, recovery_quality):
        """ç”Ÿæˆæ¢å¤å»ºè®®"""
        if recovery_quality == "ä¼˜ç§€æ¢å¤":
            return "æ¢å¤å……åˆ†ï¼Œå¯è¿›è¡Œä¸‹ä¸€é˜¶æ®µè®­ç»ƒ"
        elif recovery_quality == "è‰¯å¥½æ¢å¤":
            return "æ¢å¤è‰¯å¥½ï¼Œå»ºè®®é€‚åº¦è®­ç»ƒ"
        elif recovery_quality == "ä¸€èˆ¬æ¢å¤":
            return "æ¢å¤ä¸€èˆ¬ï¼Œå»ºè®®é™ä½è®­ç»ƒå¼ºåº¦"
        else:
            return "æ¢å¤ä¸è¶³ï¼Œå»ºè®®å»¶é•¿ä¼‘æ¯æ—¶é—´"

def analyze_hrv_segmentation(rr_intervals, patient_id="Unknown", mode="auto", context_info=None):
    """HRVæ™ºèƒ½åˆ†æ®µåˆ†æä¸»å‡½æ•°"""
    
    print(f"ğŸ’“ HRVæ™ºèƒ½åˆ†æ®µåˆ†æå¯åŠ¨ - æ‚£è€…ID: {patient_id}")
    print(f"ğŸ”§ åˆ†æ®µæ¨¡å¼: {mode}")
    if context_info:
        print(f"ğŸ“ ä¸Šä¸‹æ–‡ä¿¡æ¯: {context_info}")
    print("="*60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = HRVSegmentationAnalyzer()
    
    # æ£€æµ‹æ•°æ®çŠ¶æ€
    data_status = analyzer.detect_data_status(rr_intervals, context_info=context_info)
    print(f"ğŸ“Š æ•°æ®çŠ¶æ€: {data_status['æ•°æ®çŠ¶æ€']}")
    print(f"â±ï¸  æ•°æ®æ—¶é•¿: {data_status['æ•°æ®æ—¶é•¿']}")
    print(f"ğŸ’— å¹³å‡å¿ƒç‡: {data_status['å¹³å‡å¿ƒç‡']}")
    
    # æ™ºèƒ½æ¨¡å¼é€‰æ‹©
    if mode == "auto":
        mode = data_status['æ¨èåˆ†æ®µæ¨¡å¼']
        print(f"ğŸ§  æ™ºèƒ½æ¨èæ¨¡å¼: {mode}")
    
    # æå–HRVç‰¹å¾
    hrv_features = analyzer.extract_hrv_features_windowed(rr_intervals)
    print(f"ğŸ“ˆ æå–äº† {len(hrv_features)} ä¸ªHRVç‰¹å¾çª—å£")
    
    # æ£€æµ‹å˜åŒ–ç‚¹
    change_points = analyzer.detect_hrv_change_points(hrv_features)
    print(f"ğŸ¯ æ£€æµ‹åˆ°å˜åŒ–ç‚¹: {len(change_points)}ä¸ª")
    
    # æ‰§è¡Œåˆ†æ®µåˆ†æ
    if mode == "training_phases":
        segmentation_result = analyzer.analyze_training_phases(rr_intervals, change_points)
    elif mode == "recovery_monitoring":
        segmentation_result = analyzer.analyze_recovery_monitoring(rr_intervals, change_points)
    else:
        # é»˜è®¤ä½¿ç”¨è®­ç»ƒé˜¶æ®µåˆ†æ
        segmentation_result = analyzer.analyze_training_phases(rr_intervals, change_points)
    
    # ç”ŸæˆæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report = {
        "æŠ¥å‘Šå¤´ä¿¡æ¯": {
            "æŠ¥å‘Šç±»å‹": "HRVæ™ºèƒ½åˆ†æ®µåˆ†ææŠ¥å‘Š v1.0",
            "æ‚£è€…ID": patient_id,
            "åˆ†ææ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "åˆ†æ®µæ¨¡å¼": analyzer.segmentation_modes.get(mode, mode),
            "ä¸Šä¸‹æ–‡ä¿¡æ¯": context_info or "æ— "
        },
        "æ•°æ®çŠ¶æ€åˆ†æ": data_status,
        "HRVç‰¹å¾åˆ†æ": {
            "ç‰¹å¾çª—å£æ•°": len(hrv_features),
            "å¹³å‡RMSSD": f"{np.mean([f['RMSSD'] for f in hrv_features]):.1f} ms",
            "å¹³å‡å¿ƒç‡": f"{np.mean([f['mean_HR'] for f in hrv_features]):.1f} bpm"
        },
        "å˜åŒ–ç‚¹æ£€æµ‹": {
            "æ£€æµ‹åˆ°çš„å˜åŒ–ç‚¹": len(change_points),
            "å˜åŒ–ç‚¹è¯¦æƒ…": change_points
        },
        "æ™ºèƒ½åˆ†æ®µç»“æœ": segmentation_result
    }
    
    # ä¿å­˜æŠ¥å‘Š
    filename = f"HRV_Segmentation_Analysis_{patient_id}_{timestamp}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=str)
    
    print("ğŸ“Š HRVæ™ºèƒ½åˆ†æ®µåˆ†æå®Œæˆ")
    print(f"ğŸ“ åˆ†æ®µæ•°é‡: {segmentation_result['åˆ†æ®µæ•°é‡']}")
    print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {filename}")
    
    return report

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # ç”Ÿæˆç¤ºä¾‹è®­ç»ƒHRVæ•°æ®
    np.random.seed(42)
    
    # æ¨¡æ‹Ÿ60åˆ†é’Ÿè®­ç»ƒçš„RRé—´æœŸæ•°æ®
    # çƒ­èº«(0-10min) -> ä¸»è®­ç»ƒ(10-45min) -> æ¢å¤(45-60min)
    
    total_minutes = 60
    avg_beats_per_minute = 80  # å¹³å‡å¿ƒç‡çº¦80bpm
    total_beats = total_minutes * avg_beats_per_minute
    
    rr_intervals = []
    
    for minute in range(total_minutes):
        if minute < 10:  # çƒ­èº«é˜¶æ®µ
            target_hr = 70 + minute * 2  # 70-88 bpm
            base_rr = 60000 / target_hr
            # è¾ƒé«˜çš„HRV (å‰¯äº¤æ„Ÿç¥ç»è¿˜æœ‰æ´»æ€§)
            rr_variation = np.random.normal(0, 40, avg_beats_per_minute)
        elif minute < 45:  # ä¸»è®­ç»ƒé˜¶æ®µ
            progress = (minute - 10) / 35
            target_hr = 90 + progress * 40  # 90-130 bpm
            base_rr = 60000 / target_hr
            # ä½HRV (äº¤æ„Ÿç¥ç»ä¸»å¯¼)
            rr_variation = np.random.normal(0, 15, avg_beats_per_minute)
        else:  # æ¢å¤é˜¶æ®µ
            recovery_progress = (minute - 45) / 15
            target_hr = 130 - recovery_progress * 40  # 130é™åˆ°90 bpm
            base_rr = 60000 / target_hr
            # é€æ¸å¢åŠ çš„HRV (å‰¯äº¤æ„Ÿç¥ç»æ¢å¤)
            rr_var_std = 15 + recovery_progress * 25  # 15å¢åŠ åˆ°40
            rr_variation = np.random.normal(0, rr_var_std, avg_beats_per_minute)
        
        # ç”Ÿæˆè¯¥åˆ†é’Ÿçš„RRé—´æœŸ
        minute_rr = base_rr + rr_variation
        minute_rr = np.clip(minute_rr, 400, 1500)  # é™åˆ¶åœ¨åˆç†èŒƒå›´
        rr_intervals.extend(minute_rr)
    
    rr_intervals = np.array(rr_intervals[:total_beats])  # ç¡®ä¿æ€»æ•°æ®ç‚¹æ•°æ­£ç¡®
    
    print(f"ç”Ÿæˆäº† {len(rr_intervals)} ä¸ªè®­ç»ƒRRé—´æœŸæ•°æ®")
    print(f"è®­ç»ƒæ—¶é•¿: {len(rr_intervals) * np.mean(rr_intervals) / 1000 / 60:.1f} åˆ†é’Ÿ")
    print(f"å¹³å‡å¿ƒç‡: {60000 / np.mean(rr_intervals):.1f} bpm")
    print(f"å¿ƒç‡èŒƒå›´: {60000 / np.max(rr_intervals):.1f} - {60000 / np.min(rr_intervals):.1f} bpm")
    
    # æ‰§è¡Œåˆ†æ
    result = analyze_hrv_segmentation(
        rr_intervals, 
        "Demo_Athlete_001", 
        "auto",
        "è¿åŠ¨å‘˜é—´æ­‡è®­ç»ƒç›‘æµ‹"
    )
    
    print("\nğŸ¯ HRVè®­ç»ƒåˆ†æ®µæ¼”ç¤ºåˆ†æå®Œæˆï¼")