#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å­¦ä¹ åˆ†æå™¨ - åˆ†æåŒ»ç”Ÿä¿®æ”¹æ¨¡å¼ï¼Œä¼˜åŒ–AIå»ºè®®ç”Ÿæˆ
"""
import json
import re
from datetime import datetime
from collections import defaultdict, Counter
import difflib

class LearningAnalyzer:
    """å­¦ä¹ åˆ†æå™¨ - åˆ†æä¿®æ”¹åé¦ˆå¹¶æå–ä¼˜åŒ–å»ºè®®"""
    
    def __init__(self, feedback_db_path="feedback_database.json"):
        self.feedback_db_path = feedback_db_path
        self.feedback_data = self.load_feedback_data()
        self.learning_insights = {}
    
    def load_feedback_data(self):
        """åŠ è½½åé¦ˆæ•°æ®"""
        try:
            with open(self.feedback_db_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {"feedback_records": [], "learning_stats": {}}
    
    def analyze_all_feedback(self):
        """åˆ†ææ‰€æœ‰åé¦ˆæ•°æ®"""
        records = self.feedback_data.get("feedback_records", [])
        
        if not records:
            print("æ²¡æœ‰æ‰¾åˆ°åé¦ˆè®°å½•")
            return
        
        print(f"å¼€å§‹åˆ†æ {len(records)} æ¡åé¦ˆè®°å½•...")
        
        # åˆ†æå„ä¸ªç»´åº¦
        self.learning_insights = {
            "terminology_patterns": self.analyze_terminology_changes(records),
            "content_structure_patterns": self.analyze_structure_changes(records),
            "clinical_judgment_patterns": self.analyze_clinical_modifications(records),
            "doctor_preferences": self.analyze_doctor_preferences(records),
            "parameter_adjustments": self.analyze_parameter_trends(records),
            "summary": self.generate_learning_summary(records)
        }
        
        return self.learning_insights
    
    def analyze_terminology_changes(self, records):
        """åˆ†æç”¨è¯ä¿®æ”¹æ¨¡å¼"""
        print("åˆ†æç”¨è¯ä¿®æ”¹æ¨¡å¼...")
        
        word_replacements = defaultdict(list)
        phrase_replacements = defaultdict(list)
        
        for record in records:
            original = record.get("original_report", "")
            modified = record.get("modified_report", "")
            
            # ä½¿ç”¨difflibæ‰¾å‡ºå…·ä½“çš„ä¿®æ”¹
            diff = list(difflib.unified_diff(
                original.split(), modified.split(), lineterm=''
            ))
            
            # æå–æ›¿æ¢è¯æ±‡
            for i, line in enumerate(diff):
                if line.startswith('-') and i+1 < len(diff) and diff[i+1].startswith('+'):
                    original_word = line[1:].strip()
                    modified_word = diff[i+1][1:].strip()
                    if original_word != modified_word:
                        word_replacements[original_word].append(modified_word)
        
        # ç»Ÿè®¡æœ€å¸¸è§çš„æ›¿æ¢
        common_replacements = {}
        for original, replacements in word_replacements.items():
            if len(replacements) > 1:  # è‡³å°‘è¢«æ›¿æ¢è¿‡2æ¬¡
                most_common = Counter(replacements).most_common(1)[0]
                common_replacements[original] = {
                    "preferred_replacement": most_common[0],
                    "frequency": most_common[1],
                    "total_occurrences": len(replacements)
                }
        
        return {
            "common_replacements": common_replacements,
            "replacement_patterns": dict(word_replacements)
        }
    
    def analyze_structure_changes(self, records):
        """åˆ†æç»“æ„ä¿®æ”¹æ¨¡å¼"""
        print("åˆ†ææŠ¥å‘Šç»“æ„ä¿®æ”¹æ¨¡å¼...")
        
        structure_patterns = {
            "section_additions": [],
            "section_removals": [],
            "reordering_patterns": [],
            "formatting_preferences": []
        }
        
        for record in records:
            original = record.get("original_report", "")
            modified = record.get("modified_report", "")
            
            # åˆ†ææ ‡é¢˜ç»“æ„
            original_headers = re.findall(r'<h[1-6]>(.*?)</h[1-6]>', original)
            modified_headers = re.findall(r'<h[1-6]>(.*?)</h[1-6]>', modified)
            
            # æ£€æµ‹æ–°å¢æˆ–åˆ é™¤çš„ç« èŠ‚
            added_sections = set(modified_headers) - set(original_headers)
            removed_sections = set(original_headers) - set(modified_headers)
            
            if added_sections:
                structure_patterns["section_additions"].extend(list(added_sections))
            if removed_sections:
                structure_patterns["section_removals"].extend(list(removed_sections))
        
        return structure_patterns
    
    def analyze_clinical_modifications(self, records):
        """åˆ†æä¸´åºŠåˆ¤æ–­ä¿®æ”¹æ¨¡å¼"""
        print("åˆ†æä¸´åºŠåˆ¤æ–­ä¿®æ”¹æ¨¡å¼...")
        
        clinical_patterns = {
            "risk_assessment_adjustments": [],
            "recommendation_modifications": [],
            "threshold_adjustments": [],
            "safety_emphasis_patterns": []
        }
        
        # å…³é”®è¯åŒ¹é…æ¨¡å¼
        risk_keywords = ["é£é™©", "å®‰å…¨", "ä½è¡€ç³–", "é«˜è¡€ç³–", "TBR", "TAR"]
        recommendation_keywords = ["å»ºè®®", "æ¨è", "åº”å½“", "éœ€è¦", "è°ƒæ•´"]
        threshold_keywords = ["é˜ˆå€¼", "æ ‡å‡†", "ç›®æ ‡", "70%", "80%", "4%"]
        
        for record in records:
            original = record.get("original_report", "")
            modified = record.get("modified_report", "")
            
            # æ£€æŸ¥é£é™©è¯„ä¼°ä¿®æ”¹
            for keyword in risk_keywords:
                if keyword in original and keyword in modified:
                    original_context = self.extract_context(original, keyword)
                    modified_context = self.extract_context(modified, keyword)
                    if original_context != modified_context:
                        clinical_patterns["risk_assessment_adjustments"].append({
                            "keyword": keyword,
                            "original": original_context,
                            "modified": modified_context,
                            "doctor_id": record.get("doctor_id", "unknown")
                        })
        
        return clinical_patterns
    
    def analyze_doctor_preferences(self, records):
        """åˆ†æä¸åŒåŒ»ç”Ÿçš„åå¥½æ¨¡å¼"""
        print("åˆ†æåŒ»ç”Ÿä¸ªäººåå¥½...")
        
        doctor_patterns = defaultdict(lambda: {
            "modification_frequency": 0,
            "preferred_terminology": defaultdict(list),
            "common_additions": [],
            "modification_style": "unknown"
        })
        
        for record in records:
            doctor_id = record.get("doctor_id", "unknown")
            doctor_patterns[doctor_id]["modification_frequency"] += 1
            
            # åˆ†æä¿®æ”¹é£æ ¼
            change_summary = record.get("change_summary", {})
            mod_type = change_summary.get("modification_type", "unknown")
            if mod_type in ["major_revision", "moderate_edit"]:
                doctor_patterns[doctor_id]["modification_style"] = "detailed"
            elif mod_type == "minor_edit":
                doctor_patterns[doctor_id]["modification_style"] = "conservative"
        
        return dict(doctor_patterns)
    
    def analyze_parameter_trends(self, records):
        """åˆ†æå‚æ•°è°ƒæ•´è¶‹åŠ¿"""
        print("åˆ†æå‚æ•°è°ƒæ•´è¶‹åŠ¿...")
        
        parameter_trends = {
            "tir_threshold_adjustments": [],
            "risk_weight_changes": [],
            "assessment_criteria_modifications": []
        }
        
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æ•°å€¼å‚æ•°åˆ†æ
        # ç›®å‰å…ˆåšåŸºç¡€çš„æ–‡æœ¬åˆ†æ
        
        for record in records:
            original = record.get("original_report", "")
            modified = record.get("modified_report", "")
            
            # æå–æ•°å€¼å˜åŒ–
            original_numbers = re.findall(r'\d+\.?\d*%?', original)
            modified_numbers = re.findall(r'\d+\.?\d*%?', modified)
            
            if len(original_numbers) != len(modified_numbers):
                parameter_trends["assessment_criteria_modifications"].append({
                    "original_count": len(original_numbers),
                    "modified_count": len(modified_numbers),
                    "doctor_id": record.get("doctor_id", "unknown")
                })
        
        return parameter_trends
    
    def generate_learning_summary(self, records):
        """ç”Ÿæˆå­¦ä¹ æ€»ç»“"""
        total_records = len(records)
        
        # ç»Ÿè®¡ä¿®æ”¹ç±»å‹åˆ†å¸ƒ
        modification_types = defaultdict(int)
        for record in records:
            mod_type = record.get("change_summary", {}).get("modification_type", "unknown")
            modification_types[mod_type] += 1
        
        # æ‰¾å‡ºæœ€æ´»è·ƒçš„åŒ»ç”Ÿ
        doctor_activity = defaultdict(int)
        for record in records:
            doctor_id = record.get("doctor_id", "unknown")
            doctor_activity[doctor_id] += 1
        
        most_active_doctor = max(doctor_activity.items(), key=lambda x: x[1]) if doctor_activity else ("none", 0)
        
        return {
            "total_records_analyzed": total_records,
            "modification_type_distribution": dict(modification_types),
            "most_active_doctor": most_active_doctor[0],
            "most_active_doctor_count": most_active_doctor[1],
            "analysis_timestamp": datetime.now().isoformat(),
            "learning_recommendations": self.generate_optimization_recommendations()
        }
    
    def generate_optimization_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        if not self.learning_insights:
            return ["è¯·å…ˆè¿è¡Œanalyze_all_feedback()æ–¹æ³•"]
        
        recommendations = []
        
        # åŸºäºå¸¸è§æ›¿æ¢è¯æ±‡çš„å»ºè®®
        terminology = self.learning_insights.get("terminology_patterns", {})
        common_replacements = terminology.get("common_replacements", {})
        
        if common_replacements:
            recommendations.append(
                f"å‘ç°{len(common_replacements)}ä¸ªå¸¸è§ç”¨è¯æ›¿æ¢æ¨¡å¼ï¼Œå»ºè®®æ›´æ–°é»˜è®¤è¯æ±‡è¡¨"
            )
        
        # åŸºäºç»“æ„ä¿®æ”¹çš„å»ºè®®
        structure = self.learning_insights.get("content_structure_patterns", {})
        if structure.get("section_additions"):
            recommendations.append("åŒ»ç”Ÿç»å¸¸æ·»åŠ æ–°ç« èŠ‚ï¼Œå»ºè®®æ‰©å……æŠ¥å‘Šæ¨¡æ¿")
        
        # åŸºäºåŒ»ç”Ÿåå¥½çš„å»ºè®®
        doctor_prefs = self.learning_insights.get("doctor_preferences", {})
        if len(doctor_prefs) > 1:
            recommendations.append("æ£€æµ‹åˆ°å¤šä½åŒ»ç”Ÿçš„ä¸åŒåå¥½ï¼Œå»ºè®®å®ç°ä¸ªæ€§åŒ–é…ç½®")
        
        if not recommendations:
            recommendations.append("æš‚æœªå‘ç°æ˜æ˜¾çš„ä¼˜åŒ–æ¨¡å¼ï¼Œå»ºè®®æ”¶é›†æ›´å¤šåé¦ˆæ•°æ®")
        
        return recommendations
    
    def extract_context(self, text, keyword, window=50):
        """æå–å…³é”®è¯å‘¨å›´çš„ä¸Šä¸‹æ–‡"""
        pos = text.find(keyword)
        if pos == -1:
            return ""
        
        start = max(0, pos - window)
        end = min(len(text), pos + len(keyword) + window)
        
        return text[start:end]
    
    def export_learning_report(self, output_path="learning_analysis_report.json"):
        """å¯¼å‡ºå­¦ä¹ åˆ†ææŠ¥å‘Š"""
        if not self.learning_insights:
            self.analyze_all_feedback()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.learning_insights, f, ensure_ascii=False, indent=2)
        
        print(f"å­¦ä¹ åˆ†ææŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}")
        return output_path
    
    def print_summary(self):
        """æ‰“å°å­¦ä¹ æ€»ç»“"""
        if not self.learning_insights:
            self.analyze_all_feedback()
        
        summary = self.learning_insights.get("summary", {})
        
        print("\n" + "="*60)
        print("ğŸ“Š äº”æ­¥æ³•Plus å­¦ä¹ åˆ†ææ€»ç»“")
        print("="*60)
        print(f"ğŸ“ˆ åˆ†æè®°å½•æ€»æ•°: {summary.get('total_records_analyzed', 0)}")
        print(f"ğŸ‘¨â€âš•ï¸ æœ€æ´»è·ƒåŒ»ç”Ÿ: {summary.get('most_active_doctor', 'unknown')} ({summary.get('most_active_doctor_count', 0)} æ¬¡ä¿®æ”¹)")
        print(f"ğŸ• åˆ†ææ—¶é—´: {summary.get('analysis_timestamp', 'unknown')}")
        
        print("\nğŸ“‹ ä¿®æ”¹ç±»å‹åˆ†å¸ƒ:")
        mod_dist = summary.get('modification_type_distribution', {})
        for mod_type, count in mod_dist.items():
            print(f"  â€¢ {mod_type}: {count} æ¬¡")
        
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        recommendations = summary.get('learning_recommendations', [])
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec}")
        
        print("="*60)


def main():
    """ä¸»ç¨‹åº"""
    analyzer = LearningAnalyzer()
    
    # åˆ†ææ‰€æœ‰åé¦ˆ
    analyzer.analyze_all_feedback()
    
    # æ‰“å°æ€»ç»“
    analyzer.print_summary()
    
    # å¯¼å‡ºè¯¦ç»†æŠ¥å‘Š
    analyzer.export_learning_report()


if __name__ == "__main__":
    main()