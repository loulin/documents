#!/usr/bin/env python3
"""
ç”ŸæˆV4.0è¯Šæ–­ä¸å†…ç½®è¯Šæ–­çš„å¯¹æ¯”è¡¨æ ¼
åŸºäºé«˜æ ‡å‡†V4.0æ–¹æ³•çš„çœŸå®è¯Šæ–­å¯¹æ¯”åˆ†æ
"""

import pandas as pd
import numpy as np
import os
from collections import Counter

class V4DiagnosisComparator:
    """V4.0è¯Šæ–­å¯¹æ¯”åˆ†æå™¨"""
    
    def __init__(self):
        # SNOMED-CTä»£ç æ˜ å°„
        self.snomed_to_chinese = {
            '426627000': 'å¿ƒåŠ¨è¿‡é€Ÿ',
            '426177001': 'æŸæ”¯é˜»æ»', 
            '164889003': 'æˆ¿æ€§å¿ƒå¾‹å¤±å¸¸',
            '59118001': 'å³æŸæ”¯é˜»æ»',
            '164934002': 'å¿ƒæˆ¿é¢¤åŠ¨',
            '251146004': 'å·¦æŸæ”¯é˜»æ»',
            '428750005': 'å·¦æŸæ”¯é˜»æ»',
            '427393009': 'çª¦æ€§å¿ƒåŠ¨è¿‡ç¼“',
            '426783006': 'çª¦æ€§å¿ƒå¾‹',
            '164917005': 'å¿ƒå¾‹ä¸é½',
            '413444003': 'å¿ƒè‚Œç¼ºè¡€',
            '164884008': 'å¿ƒç”µå›¾å¼‚å¸¸',
            '164865005': 'äºŒåº¦æˆ¿å®¤é˜»æ»',
            '164890007': 'å®¤æ€§å¿ƒå¾‹å¤±å¸¸',
            '164909002': 'å·¦è½´åè½¬',
            '17338001': 'å®¤æ€§æœŸå‰æ”¶ç¼©',
            '39732003': 'å·¦å¿ƒå®¤è‚¥åš',
            '429622005': 'å·¦å‰åˆ†æ”¯é˜»æ»'
        }
        
        # åå‘æ˜ å°„
        self.chinese_to_snomed = {v: k for k, v in self.snomed_to_chinese.items()}
    
    def load_builtin_diagnoses(self, data_dir):
        """åŠ è½½å†…ç½®è¯Šæ–­"""
        builtin_data = []
        
        # è¯»å–RECORDSæ–‡ä»¶
        records_file = os.path.join(data_dir, 'RECORDS')
        if not os.path.exists(records_file):
            print("âŒ æœªæ‰¾åˆ°RECORDSæ–‡ä»¶")
            return None
        
        with open(records_file, 'r') as f:
            record_names = [line.strip() for line in f if line.strip()]
        
        print(f"ğŸ“‹ åŠ è½½ {len(record_names)} ä¸ªè®°å½•çš„å†…ç½®è¯Šæ–­...")
        
        for record_name in record_names:
            header_file = os.path.join(data_dir, f"{record_name}.hea")
            if not os.path.exists(header_file):
                continue
                
            # è§£æå¤´æ–‡ä»¶
            try:
                with open(header_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                # æå–æ‚£è€…ä¿¡æ¯å’Œè¯Šæ–­
                age, sex, diagnosis = None, None, None
                
                for line in lines:
                    line = line.strip()
                    if line.startswith('#Age:'):
                        age = line.split(':')[1].strip()
                    elif line.startswith('#Sex:'):
                        sex = line.split(':')[1].strip()
                    elif line.startswith('#Dx:'):
                        diagnosis = line.split(':')[1].strip()
                        break
                
                # å¤„ç†è¯Šæ–­ä»£ç 
                builtin_diagnoses = []
                if diagnosis:
                    codes = [code.strip() for code in diagnosis.split(',')]
                    for code in codes:
                        if code in self.snomed_to_chinese:
                            builtin_diagnoses.append(self.snomed_to_chinese[code])
                        else:
                            builtin_diagnoses.append(f"æœªçŸ¥è¯Šæ–­({code})")
                
                builtin_data.append({
                    'record_name': record_name,
                    'age': age,
                    'sex': sex,
                    'builtin_diagnosis_codes': diagnosis if diagnosis else '',
                    'builtin_diagnosis_names': ', '.join(builtin_diagnoses) if builtin_diagnoses else 'æ— è¯Šæ–­'
                })
                
            except Exception as e:
                print(f"âŒ è§£æ{record_name}.heaå¤±è´¥: {e}")
                continue
        
        return pd.DataFrame(builtin_data)
    
    def load_v4_results(self, v4_results_file):
        """åŠ è½½V4.0è¯Šæ–­ç»“æœ"""
        try:
            df = pd.read_csv(v4_results_file)
            print(f"ğŸ“Š åŠ è½½V4.0è¯Šæ–­ç»“æœ: {len(df)} æ¡è®°å½•")
            return df
        except Exception as e:
            print(f"âŒ åŠ è½½V4.0ç»“æœå¤±è´¥: {e}")
            return None
    
    def convert_algorithm_diagnosis(self, diagnosis_codes):
        """è½¬æ¢ç®—æ³•è¯Šæ–­ä»£ç ä¸ºä¸­æ–‡åç§°"""
        if not diagnosis_codes or pd.isna(diagnosis_codes):
            return 'æ— è¯Šæ–­'
        
        diagnoses = []
        codes = [code.strip() for code in str(diagnosis_codes).split(',')]
        
        for code in codes:
            if code in self.snomed_to_chinese:
                diagnoses.append(self.snomed_to_chinese[code])
            else:
                diagnoses.append(f"æœªçŸ¥({code})")
        
        return ', '.join(diagnoses)
    
    def calculate_similarity(self, builtin_str, algorithm_str):
        """è®¡ç®—è¯Šæ–­ç›¸ä¼¼æ€§"""
        if not builtin_str or not algorithm_str or builtin_str == 'æ— è¯Šæ–­' or algorithm_str == 'æ— è¯Šæ–­':
            return {
                'exact_match': False,
                'partial_match': 0,
                'jaccard': 0.0,
                'precision': 0.0,
                'recall': 0.0,
                'f1': 0.0,
                'match_details': 'æ— æœ‰æ•ˆè¯Šæ–­å¯¹æ¯”'
            }
        
        # åˆ†è¯å¤„ç†
        builtin_set = set([d.strip() for d in builtin_str.split(',')])
        algorithm_set = set([d.strip() for d in algorithm_str.split(',')])
        
        # è®¡ç®—äº¤é›†
        intersection = builtin_set & algorithm_set
        union = builtin_set | algorithm_set
        
        # è®¡ç®—æŒ‡æ ‡
        exact_match = builtin_set == algorithm_set
        partial_match = len(intersection)
        
        jaccard = len(intersection) / len(union) if len(union) > 0 else 0.0
        precision = len(intersection) / len(algorithm_set) if len(algorithm_set) > 0 else 0.0
        recall = len(intersection) / len(builtin_set) if len(builtin_set) > 0 else 0.0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
        
        # åŒ¹é…è¯¦æƒ…
        if exact_match:
            match_details = 'å®Œå…¨åŒ¹é…'
        elif partial_match > 0:
            matched = list(intersection)
            match_details = f'éƒ¨åˆ†åŒ¹é…: {", ".join(matched)}'
        else:
            match_details = 'æ— åŒ¹é…'
        
        return {
            'exact_match': exact_match,
            'partial_match': partial_match,
            'jaccard': jaccard,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'match_details': match_details
        }
    
    def generate_comparison_table(self, data_dir, v4_results_file, output_file):
        """ç”Ÿæˆå®Œæ•´å¯¹æ¯”è¡¨æ ¼"""
        print("ğŸ” ç”ŸæˆV4.0è¯Šæ–­ä¸å†…ç½®è¯Šæ–­å¯¹æ¯”è¡¨æ ¼")
        print("=" * 60)
        
        # åŠ è½½æ•°æ®
        builtin_df = self.load_builtin_diagnoses(data_dir)
        v4_df = self.load_v4_results(v4_results_file)
        
        if builtin_df is None or v4_df is None:
            print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        # åˆå¹¶æ•°æ®
        merged_df = pd.merge(builtin_df, v4_df, on='record_name', how='inner')
        print(f"ğŸ“Š æˆåŠŸåŒ¹é… {len(merged_df)} æ¡è®°å½•")
        
        # ç”Ÿæˆå¯¹æ¯”ç»“æœ
        comparison_results = []
        
        for _, row in merged_df.iterrows():
            # è½¬æ¢ç®—æ³•è¯Šæ–­
            algorithm_diagnosis_names = self.convert_algorithm_diagnosis(row['algorithm_diagnosis'])
            
            # è®¡ç®—ç›¸ä¼¼æ€§
            similarity = self.calculate_similarity(
                row['builtin_diagnosis_names'], 
                algorithm_diagnosis_names
            )
            
            # åˆ›å»ºå¯¹æ¯”è®°å½•
            result = {
                'record_name': row['record_name'],
                'age': row['age'],
                'sex': row['sex'],
                'builtin_diagnosis': row['builtin_diagnosis_names'],
                'builtin_codes': row['builtin_diagnosis_codes'],
                'v4_algorithm_diagnosis': algorithm_diagnosis_names,
                'v4_algorithm_codes': row['algorithm_diagnosis'],
                'v4_confidence': row.get('diagnosis_confidence', 0.0),
                'v4_features_total': row.get('features_used_total', 0),
                'v4_features_morphology': row.get('features_used_morphology', 0),
                **similarity
            }
            
            comparison_results.append(result)
        
        # åˆ›å»ºç»“æœDataFrame
        results_df = pd.DataFrame(comparison_results)
        
        # ä¿å­˜ç»“æœ
        results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_statistics_report(results_df)
        
        print(f"ğŸ’¾ å¯¹æ¯”è¡¨æ ¼å·²ä¿å­˜è‡³: {output_file}")
        return results_df
    
    def generate_statistics_report(self, df):
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        print(f"\\n" + "=" * 60)
        print("ğŸ“Š V4.0è¯Šæ–­å¯¹æ¯”ç»Ÿè®¡æŠ¥å‘Š")
        print("=" * 60)
        
        total_records = len(df)
        exact_matches = df['exact_match'].sum()
        partial_matches = (df['partial_match'] > 0).sum()
        no_matches = total_records - partial_matches
        
        print(f"\\nğŸ¯ æ€»ä½“ç»Ÿè®¡:")
        print(f"   - æ€»ç—…ä¾‹æ•°: {total_records}")
        print(f"   - å®Œå…¨åŒ¹é…: {exact_matches} ä¾‹ ({exact_matches/total_records*100:.1f}%)")
        print(f"   - éƒ¨åˆ†åŒ¹é…: {partial_matches - exact_matches} ä¾‹ ({(partial_matches - exact_matches)/total_records*100:.1f}%)")
        print(f"   - æ— åŒ¹é…: {no_matches} ä¾‹ ({no_matches/total_records*100:.1f}%)")
        print(f"   - æ€»ä½“æœ‰æ•ˆåŒ¹é…ç‡: {partial_matches/total_records*100:.1f}%")
        
        print(f"\\nğŸ“ˆ å¹³å‡æ€§èƒ½æŒ‡æ ‡:")
        print(f"   - Jaccardç›¸ä¼¼åº¦: {df['jaccard'].mean():.3f}")
        print(f"   - ç²¾ç¡®ç‡: {df['precision'].mean():.3f}")
        print(f"   - å¬å›ç‡: {df['recall'].mean():.3f}")
        print(f"   - F1åˆ†æ•°: {df['f1'].mean():.3f}")
        
        print(f"\\nğŸ”¬ V4.0ç³»ç»Ÿç‰¹å¾:")
        print(f"   - å¹³å‡ç½®ä¿¡åº¦: {df['v4_confidence'].mean():.3f}")
        print(f"   - å¹³å‡ç‰¹å¾ä½¿ç”¨æ•°: {df['v4_features_total'].mean():.1f}")
        print(f"   - å¹³å‡å½¢æ€å­¦ç‰¹å¾æ•°: {df['v4_features_morphology'].mean():.1f}")
        
        # è¯Šæ–­åˆ†å¸ƒåˆ†æ
        print(f"\\nğŸ” è¯Šæ–­åˆ†å¸ƒåˆ†æ:")
        
        # å†…ç½®è¯Šæ–­åˆ†å¸ƒ
        builtin_diagnoses = []
        for dx_str in df['builtin_diagnosis']:
            if pd.notna(dx_str) and dx_str != 'æ— è¯Šæ–­':
                for dx in dx_str.split(','):
                    builtin_diagnoses.append(dx.strip())
        
        # V4.0è¯Šæ–­åˆ†å¸ƒ
        v4_diagnoses = []
        for dx_str in df['v4_algorithm_diagnosis']:
            if pd.notna(dx_str) and dx_str != 'æ— è¯Šæ–­':
                for dx in dx_str.split(','):
                    v4_diagnoses.append(dx.strip())
        
        builtin_counts = Counter(builtin_diagnoses)
        v4_counts = Counter(v4_diagnoses)
        
        print(f"\\n{'è¯Šæ–­ç±»å‹':<20} {'å†…ç½®é¢‘æ¬¡':<10} {'V4.0é¢‘æ¬¡':<10} {'å·®å¼‚':<10}")
        print("-" * 50)
        
        all_diagnoses = set(builtin_counts.keys()) | set(v4_counts.keys())
        for diagnosis in sorted(all_diagnoses):
            builtin_count = builtin_counts.get(diagnosis, 0)
            v4_count = v4_counts.get(diagnosis, 0)
            diff = v4_count - builtin_count
            diff_str = f"{diff:+d}" if diff != 0 else "0"
            
            print(f"{diagnosis:<20} {builtin_count:<10} {v4_count:<10} {diff_str:<10}")

def main():
    """ä¸»å‡½æ•°"""
    # æ–‡ä»¶è·¯å¾„
    data_dir = '/Users/williamsun/Documents/gplus/docs/ECG/ECG_demodata/01/010'
    v4_results_file = '/Users/williamsun/Documents/gplus/docs/ECG/report/v4_diagnosis_results/integrated_algorithm_diagnosis_v4.csv'
    output_file = '/Users/williamsun/Documents/gplus/docs/ECG/report/v4_diagnosis_detailed_comparison.csv'
    
    # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
    comparator = V4DiagnosisComparator()
    results_df = comparator.generate_comparison_table(data_dir, v4_results_file, output_file)
    
    if results_df is not None:
        print(f"\\nâœ… V4.0è¯Šæ–­å¯¹æ¯”è¡¨æ ¼ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ” è¯¦ç»†å¯¹æ¯”æ•°æ®å·²ä¿å­˜è‡³CSVæ–‡ä»¶")
        
        # æ˜¾ç¤ºå‰å‡ è¡Œç¤ºä¾‹
        print(f"\\nğŸ“‹ å‰10ä¸ªè®°å½•é¢„è§ˆ:")
        print("=" * 120)
        for i, row in results_df.head(10).iterrows():
            print(f"è®°å½• {row['record_name']} ({row['age']}å² {row['sex']})")
            print(f"  ğŸ“‹ å†…ç½®è¯Šæ–­: {row['builtin_diagnosis']}")
            print(f"  ğŸ¤– V4.0è¯Šæ–­: {row['v4_algorithm_diagnosis']}")
            print(f"  ğŸ¯ åŒ¹é…æƒ…å†µ: {row['match_details']}")
            print(f"  ğŸ“Š ç›¸ä¼¼åº¦: Jaccard={row['jaccard']:.3f}, ç²¾ç¡®ç‡={row['precision']:.3f}, å¬å›ç‡={row['recall']:.3f}")
            print(f"  ğŸ”§ ç½®ä¿¡åº¦: {row['v4_confidence']:.3f}, ç‰¹å¾æ•°: {row['v4_features_total']}")
            print()
    
    return results_df

if __name__ == '__main__':
    main()