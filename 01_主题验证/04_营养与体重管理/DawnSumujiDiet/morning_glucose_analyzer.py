#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…æ™¨è¡€ç³–å‡é«˜ç°è±¡åˆ†æå·¥å…·
ç”¨äºåŒºåˆ†é»æ˜ç°è±¡ã€è‹æœ¨æ°æ•ˆåº”å’Œè¿›é£Ÿç›¸å…³è¡€ç³–å‡é«˜

æ”¯æŒçš„æ•°æ®æ ¼å¼ï¼š
1. HRS9531æ ‡å‡†æ ¼å¼ï¼šSTUDYID,SUBJID,ARM,SITEID,LBNAM,VISIT,LBREFID,LBDTC,LBORRES,LBORRESU
2. ç®€åŒ–æ ¼å¼ï¼šdatetime,glucose æˆ– timestamp,glucose
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡ç¼–ç 
import sys
import os
if sys.platform.startswith('win'):
    os.environ['PYTHONIOENCODING'] = 'utf-8'

class MorningGlucoseAnalyzer:
    def __init__(self):
        self.glucose_data = None
        self.analysis_results = []
        
    def load_data(self, file_path, format_type="auto"):
        """
        åŠ è½½è¡€ç³–æ•°æ®
        
        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            format_type: æ•°æ®æ ¼å¼ç±»å‹ ("auto", "hrs9531", "simple")
        """
        try:
            if file_path.endswith('.csv'):
                data = pd.read_csv(file_path)
            elif file_path.endswith('.xlsx'):
                data = pd.read_excel(file_path)
            else:
                raise ValueError("æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼šCSV, XLSX")
                
            # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
            if format_type == "auto":
                if "LBDTC" in data.columns and "LBORRES" in data.columns:
                    format_type = "hrs9531"
                elif "datetime" in data.columns or "timestamp" in data.columns:
                    format_type = "simple"
                else:
                    print("è­¦å‘Šï¼šæ— æ³•è‡ªåŠ¨è¯†åˆ«æ ¼å¼ï¼Œå°è¯•é€šç”¨è§£æ...")
                    format_type = "generic"
            
            self.glucose_data = self._parse_data(data, format_type)
            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼š{len(self.glucose_data)} æ¡è®°å½•")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼š{e}")
            return False
    
    def _parse_data(self, data, format_type):
        """è§£æä¸åŒæ ¼å¼çš„æ•°æ®"""
        
        if format_type == "hrs9531":
            # HRS9531æ ‡å‡†æ ¼å¼
            df = data[['SUBJID', 'LBDTC', 'LBORRES']].copy()
            df['datetime'] = pd.to_datetime(df['LBDTC'])
            df['glucose'] = pd.to_numeric(df['LBORRES'], errors='coerce')
            df['subject_id'] = df['SUBJID']
            
        elif format_type == "simple":
            # ç®€åŒ–æ ¼å¼
            df = data.copy()
            if 'datetime' in df.columns:
                df['datetime'] = pd.to_datetime(df['datetime'])
            elif 'timestamp' in df.columns:
                df['datetime'] = pd.to_datetime(df['timestamp'])
            
            # æŸ¥æ‰¾è¡€ç³–åˆ—
            glucose_cols = [col for col in df.columns if 'glucose' in col.lower() or 'bg' in col.lower() or 'value' in col.lower()]
            if glucose_cols:
                df['glucose'] = pd.to_numeric(df[glucose_cols[0]], errors='coerce')
            
            df['subject_id'] = 'Patient_1'  # é»˜è®¤å•æ‚£è€…
            
        else:
            # é€šç”¨æ ¼å¼å°è¯•
            df = data.copy()
            datetime_cols = [col for col in df.columns if any(x in col.lower() for x in ['time', 'date', 'datetime'])]
            if datetime_cols:
                df['datetime'] = pd.to_datetime(df[datetime_cols[0]])
            
            value_cols = [col for col in df.columns if any(x in col.lower() for x in ['glucose', 'value', 'bg', 'result'])]
            if value_cols:
                df['glucose'] = pd.to_numeric(df[value_cols[0]], errors='coerce')
            
            df['subject_id'] = 'Patient_1'
        
        # æ•°æ®æ¸…ç†
        df = df.dropna(subset=['datetime', 'glucose'])
        df = df[(df['glucose'] >= 1.0) & (df['glucose'] <= 30.0)]  # åˆç†è¡€ç³–èŒƒå›´
        df = df.sort_values(['subject_id', 'datetime'])
        
        return df[['subject_id', 'datetime', 'glucose']]
    
    def analyze_morning_patterns(self, subject_id=None, days_window=7):
        """
        åˆ†ææ¸…æ™¨è¡€ç³–å‡é«˜æ¨¡å¼
        
        Args:
            subject_id: æ‚£è€…IDï¼ŒNoneè¡¨ç¤ºåˆ†ææ‰€æœ‰æ‚£è€…
            days_window: åˆ†æå¤©æ•°çª—å£
        """
        if self.glucose_data is None:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®")
            return
        
        subjects = [subject_id] if subject_id else self.glucose_data['subject_id'].unique()
        
        for subj in subjects:
            print(f"\nğŸ” åˆ†ææ‚£è€…ï¼š{subj}")
            subject_data = self.glucose_data[self.glucose_data['subject_id'] == subj].copy()
            
            # æŒ‰æ—¥æœŸåˆ†ç»„åˆ†æ
            subject_data['date'] = subject_data['datetime'].dt.date
            daily_patterns = []
            
            for date in subject_data['date'].unique()[:days_window]:
                daily_data = subject_data[subject_data['date'] == date]
                if len(daily_data) < 20:  # æ•°æ®ç‚¹å¤ªå°‘è·³è¿‡
                    continue
                    
                pattern = self._analyze_single_day(daily_data, date)
                if pattern:
                    daily_patterns.append(pattern)
            
            # æ±‡æ€»åˆ†æç»“æœ
            if daily_patterns:
                summary = self._summarize_patterns(subj, daily_patterns)
                self.analysis_results.append(summary)
                self._print_analysis_results(summary)
    
    def _analyze_single_day(self, daily_data, date):
        """åˆ†æå•æ—¥è¡€ç³–æ¨¡å¼"""
        # æå–å…³é”®æ—¶é—´æ®µæ•°æ®
        morning_data = self._extract_morning_period(daily_data)
        night_data = self._extract_night_period(daily_data)
        
        if len(morning_data) < 5 or len(night_data) < 10:
            return None
        
        # æ£€æµ‹æ¸…æ™¨è¡€ç³–å‡é«˜
        morning_rise = self._detect_morning_rise(morning_data)
        if not morning_rise:
            return None
        
        # åˆ†æå¤œé—´æ¨¡å¼
        night_pattern = self._analyze_night_pattern(night_data)
        
        # åˆ†æä¸Šå‡ç‰¹å¾
        rise_characteristics = self._analyze_rise_characteristics(morning_data)
        
        # æ¨¡å¼åˆ†ç±»è¯„åˆ†
        scores = self._calculate_pattern_scores(night_pattern, rise_characteristics)
        
        return {
            'date': date,
            'morning_rise': morning_rise,
            'night_pattern': night_pattern,
            'rise_characteristics': rise_characteristics,
            'scores': scores,
            'classification': self._classify_pattern(scores)
        }
    
    def _extract_morning_period(self, daily_data):
        """æå–æ¸…æ™¨æ—¶æ®µæ•°æ® (3:00-9:00)"""
        return daily_data[
            (daily_data['datetime'].dt.hour >= 3) & 
            (daily_data['datetime'].dt.hour <= 9)
        ].copy()
    
    def _extract_night_period(self, daily_data):
        """æå–å¤œé—´æ—¶æ®µæ•°æ® (22:00-6:00)"""
        return daily_data[
            (daily_data['datetime'].dt.hour >= 22) | 
            (daily_data['datetime'].dt.hour <= 6)
        ].copy()
    
    def _detect_morning_rise(self, morning_data):
        """æ£€æµ‹æ¸…æ™¨è¡€ç³–å‡é«˜äº‹ä»¶"""
        if len(morning_data) < 5:
            return None
        
        glucose_values = morning_data['glucose'].values
        start_bg = np.mean(glucose_values[:3])  # å‰3ä¸ªç‚¹å¹³å‡
        peak_bg = np.max(glucose_values)
        end_bg = np.mean(glucose_values[-3:])  # å3ä¸ªç‚¹å¹³å‡
        
        rise_amount = peak_bg - start_bg
        
        if rise_amount >= 1.5:  # è¡€ç³–ä¸Šå‡â‰¥1.5 mmol/Læ‰è€ƒè™‘
            peak_time = morning_data.iloc[np.argmax(glucose_values)]['datetime']
            return {
                'start_glucose': start_bg,
                'peak_glucose': peak_bg,
                'end_glucose': end_bg,
                'rise_amount': rise_amount,
                'peak_time': peak_time,
                'rise_detected': True
            }
        
        return None
    
    def _analyze_night_pattern(self, night_data):
        """åˆ†æå¤œé—´è¡€ç³–æ¨¡å¼"""
        if len(night_data) < 10:
            return {}
        
        glucose_values = night_data['glucose'].values
        min_glucose = np.min(glucose_values)
        mean_glucose = np.mean(glucose_values)
        std_glucose = np.std(glucose_values)
        
        # æ£€æµ‹ä½è¡€ç³–
        hypoglycemia = min_glucose < 3.9
        severe_hypo = min_glucose < 3.0
        
        # æ£€æµ‹è¡€ç³–ä¸‹é™è¶‹åŠ¿
        if len(glucose_values) >= 6:
            early_night = np.mean(glucose_values[:len(glucose_values)//3])
            late_night = np.mean(glucose_values[-len(glucose_values)//3:])
            glucose_decline = early_night - late_night
        else:
            glucose_decline = 0
        
        return {
            'min_glucose': min_glucose,
            'mean_glucose': mean_glucose,
            'glucose_variability': std_glucose,
            'has_hypoglycemia': hypoglycemia,
            'has_severe_hypo': severe_hypo,
            'glucose_decline': glucose_decline,
            'stable_night': std_glucose < 1.0
        }
    
    def _analyze_rise_characteristics(self, morning_data):
        """åˆ†æè¡€ç³–ä¸Šå‡ç‰¹å¾"""
        if len(morning_data) < 5:
            return {}
        
        glucose_values = morning_data['glucose'].values
        time_values = morning_data['datetime'].values
        
        # è®¡ç®—ä¸Šå‡é€Ÿç‡
        time_diff = (time_values[-1] - time_values[0]) / np.timedelta64(1, 'h')  # å°æ—¶
        if time_diff > 0:
            rise_rate = (glucose_values[-1] - glucose_values[0]) / time_diff
        else:
            rise_rate = 0
        
        # åˆ†æä¸Šå‡æ¨¡å¼
        # è®¡ç®—30åˆ†é’Ÿçª—å£å†…çš„æœ€å¤§ä¸Šå‡é€Ÿç‡
        max_rise_rate = 0
        for i in range(len(glucose_values) - 2):
            window_time = (time_values[i+2] - time_values[i]) / np.timedelta64(1, 'h')
            if window_time > 0:
                window_rate = (glucose_values[i+2] - glucose_values[i]) / window_time
                max_rise_rate = max(max_rise_rate, window_rate)
        
        # åˆ¤æ–­ä¸Šå‡æ¨¡å¼
        gradual_rise = max_rise_rate < 2.0  # ç¼“æ…¢ä¸Šå‡
        rapid_rise = max_rise_rate > 4.0    # å¿«é€Ÿä¸Šå‡
        
        # æŒç»­æ—¶é—´
        rise_duration = time_diff
        
        return {
            'average_rise_rate': rise_rate,
            'max_rise_rate': max_rise_rate,
            'gradual_rise': gradual_rise,
            'rapid_rise': rapid_rise,
            'rise_duration': rise_duration,
            'consistent_pattern': np.std(np.diff(glucose_values)) < 0.8
        }
    
    def _calculate_pattern_scores(self, night_pattern, rise_characteristics):
        """è®¡ç®—å„ç§æ¨¡å¼çš„è¯„åˆ†"""
        dawn_score = 0
        somogyi_score = 0
        food_score = 0
        
        # é»æ˜ç°è±¡è¯„åˆ†
        if rise_characteristics.get('gradual_rise', False):
            dawn_score += 2
        if rise_characteristics.get('consistent_pattern', False):
            dawn_score += 2
        if night_pattern.get('stable_night', False):
            dawn_score += 2
        if not night_pattern.get('has_hypoglycemia', False):
            dawn_score += 2
        if 2.0 <= rise_characteristics.get('average_rise_rate', 0) <= 4.0:
            dawn_score += 1
        
        # è‹æœ¨æ°æ•ˆåº”è¯„åˆ†
        if night_pattern.get('has_hypoglycemia', False):
            somogyi_score += 3
        if night_pattern.get('has_severe_hypo', False):
            somogyi_score += 2
        if night_pattern.get('glucose_decline', 0) > 2.0:
            somogyi_score += 2
        if rise_characteristics.get('max_rise_rate', 0) > 4.0:
            somogyi_score += 2
        if not rise_characteristics.get('consistent_pattern', False):
            somogyi_score += 1
        
        # è¿›é£Ÿç›¸å…³è¯„åˆ†
        if rise_characteristics.get('rapid_rise', False):
            food_score += 3
        if rise_characteristics.get('max_rise_rate', 0) > 6.0:
            food_score += 2
        if rise_characteristics.get('rise_duration', 0) < 2.0:
            food_score += 2
        if not rise_characteristics.get('gradual_rise', False):
            food_score += 1
        
        return {
            'dawn_phenomenon': dawn_score,
            'somogyi_effect': somogyi_score,
            'food_related': food_score
        }
    
    def _classify_pattern(self, scores):
        """æ ¹æ®è¯„åˆ†åˆ†ç±»æ¨¡å¼"""
        max_score = max(scores.values())
        
        if max_score < 4:
            return "æœªåˆ†ç±»/æ··åˆå› ç´ "
        
        if scores['dawn_phenomenon'] == max_score:
            return "é»æ˜ç°è±¡"
        elif scores['somogyi_effect'] == max_score:
            return "è‹æœ¨æ°æ•ˆåº”"
        elif scores['food_related'] == max_score:
            return "è¿›é£Ÿç›¸å…³"
        else:
            return "æœªåˆ†ç±»/æ··åˆå› ç´ "
    
    def _summarize_patterns(self, subject_id, daily_patterns):
        """æ±‡æ€»åˆ†æç»“æœ"""
        classifications = [p['classification'] for p in daily_patterns]
        
        # ç»Ÿè®¡å„ç±»å‹å‡ºç°é¢‘ç‡
        from collections import Counter
        pattern_counts = Counter(classifications)
        
        # è®¡ç®—å¹³å‡è¯„åˆ†
        avg_scores = {
            'dawn_phenomenon': np.mean([p['scores']['dawn_phenomenon'] for p in daily_patterns]),
            'somogyi_effect': np.mean([p['scores']['somogyi_effect'] for p in daily_patterns]),
            'food_related': np.mean([p['scores']['food_related'] for p in daily_patterns])
        }
        
        # ä¸»è¦æ¨¡å¼åˆ¤æ–­å’Œç½®ä¿¡åº¦è®¡ç®—
        main_pattern = pattern_counts.most_common(1)[0][0]
        
        # æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•
        confidence = self._calculate_enhanced_confidence(daily_patterns, main_pattern, pattern_counts)
        
        return {
            'subject_id': subject_id,
            'analysis_days': len(daily_patterns),
            'pattern_distribution': dict(pattern_counts),
            'main_pattern': main_pattern,
            'confidence': confidence,
            'average_scores': avg_scores,
            'daily_details': daily_patterns
        }
    
    def _print_analysis_results(self, summary):
        """æ‰“å°åˆ†æç»“æœ"""
        print(f"\nğŸ“Š æ‚£è€… {summary['subject_id']} åˆ†æç»“æœï¼š")
        print(f"   åˆ†æå¤©æ•°: {summary['analysis_days']} å¤©")
        print(f"   ä¸»è¦æ¨¡å¼: {summary['main_pattern']} (ç½®ä¿¡åº¦: {summary['confidence']:.1%})")
        
        print("\n   æ¨¡å¼åˆ†å¸ƒ:")
        for pattern, count in summary['pattern_distribution'].items():
            percentage = count / summary['analysis_days'] * 100
            print(f"     {pattern}: {count}å¤© ({percentage:.1f}%)")
        
        print("\n   å¹³å‡è¯„åˆ†:")
        for pattern, score in summary['average_scores'].items():
            pattern_name = {'dawn_phenomenon': 'é»æ˜ç°è±¡', 
                          'somogyi_effect': 'è‹æœ¨æ°æ•ˆåº”', 
                          'food_related': 'è¿›é£Ÿç›¸å…³'}[pattern]
            print(f"     {pattern_name}: {score:.1f}åˆ†")
        
        # æ˜¾ç¤ºç½®ä¿¡åº¦è®¡ç®—è¯¦æƒ…
        if hasattr(self, '_last_confidence_details'):
            self._print_confidence_breakdown()
        
        # è¯¦ç»†çš„æ—¥æœŸæ¨¡å¼åˆ†æ
        self._print_detailed_daily_analysis(summary)
        
        # ç»™å‡ºä¸´åºŠå»ºè®®
        self._provide_clinical_recommendations(summary)
    
    def _print_detailed_daily_analysis(self, summary):
        """æ‰“å°è¯¦ç»†çš„æ¯æ—¥æ¨¡å¼åˆ†æ"""
        print("\nğŸ“… è¯¦ç»†æ—¥æœŸåˆ†æ:")
        
        daily_patterns = summary['daily_details']
        
        # æŒ‰æ¨¡å¼åˆ†ç»„æ˜¾ç¤º
        pattern_groups = {
            'é»æ˜ç°è±¡': [],
            'è‹æœ¨æ°æ•ˆåº”': [],
            'è¿›é£Ÿç›¸å…³': [],
            'æœªåˆ†ç±»/æ··åˆå› ç´ ': []
        }
        
        for pattern in daily_patterns:
            classification = pattern['classification']
            date_str = pattern['date'].strftime('%Y-%m-%d')
            
            # æå–å…³é”®ä¿¡æ¯
            morning_rise = pattern['morning_rise']
            night_pattern = pattern['night_pattern']
            scores = pattern['scores']
            
            detail_info = {
                'date': date_str,
                'rise_amount': morning_rise['rise_amount'] if morning_rise else 0,
                'peak_time': morning_rise['peak_time'].strftime('%H:%M') if morning_rise else 'N/A',
                'night_min': night_pattern.get('min_glucose', 'N/A'),
                'has_hypo': night_pattern.get('has_hypoglycemia', False),
                'scores': scores
            }
            
            pattern_groups[classification].append(detail_info)
        
        # æ˜¾ç¤ºæ¯ç§æ¨¡å¼çš„è¯¦ç»†ä¿¡æ¯
        for pattern_type, details in pattern_groups.items():
            if details:
                print(f"\n   ğŸ”¸ {pattern_type} ({len(details)}å¤©):")
                for detail in details:
                    print(f"     {detail['date']}: ", end="")
                    print(f"å‡é«˜{detail['rise_amount']:.1f}mmol/L (å³°å€¼{detail['peak_time']}), ", end="")
                    print(f"å¤œé—´æœ€ä½{detail['night_min']:.1f}mmol/L", end="")
                    if detail['has_hypo']:
                        print(" âš ï¸ä½è¡€ç³–", end="")
                    print(f" [è¯„åˆ†: é»æ˜{detail['scores']['dawn_phenomenon']:.1f}/è‹æœ¨æ°{detail['scores']['somogyi_effect']:.1f}/è¿›é£Ÿ{detail['scores']['food_related']:.1f}]")
        
        # æ··åˆæ¨¡å¼ç‰¹åˆ«æé†’
        mixed_patterns = len([p for p in daily_patterns if self._is_mixed_pattern(p['scores'])])
        if mixed_patterns > 0:
            print(f"\n   âš ï¸  å‘ç° {mixed_patterns} å¤©å­˜åœ¨æ¨¡å¼é‡å æˆ–éš¾ä»¥åŒºåˆ†çš„æƒ…å†µ")
            print("      è¿™äº›æ—¥æœŸéœ€è¦ç»“åˆä¸´åºŠæƒ…å†µè¿›ä¸€æ­¥åˆ†æ:")
            for pattern in daily_patterns:
                if self._is_mixed_pattern(pattern['scores']):
                    date_str = pattern['date'].strftime('%Y-%m-%d')
                    scores = pattern['scores']
                    max_score = max(scores.values())
                    if max_score < 5:  # è¯„åˆ†éƒ½ä¸é«˜
                        print(f"        {date_str}: å„æ¨¡å¼è¯„åˆ†æ¥è¿‘ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯åˆ¤æ–­")
                    else:
                        # æ‰¾åˆ°è¯„åˆ†æ¥è¿‘çš„æ¨¡å¼
                        high_score_patterns = [k for k, v in scores.items() if v >= max_score - 1]
                        if len(high_score_patterns) > 1:
                            pattern_names = [{'dawn_phenomenon': 'é»æ˜ç°è±¡', 'somogyi_effect': 'è‹æœ¨æ°æ•ˆåº”', 'food_related': 'è¿›é£Ÿç›¸å…³'}[p] for p in high_score_patterns]
                            print(f"        {date_str}: {'/'.join(pattern_names)} æ¨¡å¼é‡å ")
    
    def _is_mixed_pattern(self, scores):
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ··åˆæ¨¡å¼"""
        sorted_scores = sorted(scores.values(), reverse=True)
        # å¦‚æœæœ€é«˜åˆ†å’Œç¬¬äºŒé«˜åˆ†å·®è·å°äº2åˆ†ï¼Œæˆ–è€…æœ€é«˜åˆ†å°äº5åˆ†ï¼Œè®¤ä¸ºæ˜¯æ··åˆæ¨¡å¼
        return (sorted_scores[0] - sorted_scores[1] < 2) or (sorted_scores[0] < 5)
    
    def _calculate_enhanced_confidence(self, daily_patterns, main_pattern, pattern_counts):
        """è®¡ç®—å¢å¼ºç‰ˆç½®ä¿¡åº¦"""
        total_days = len(daily_patterns)
        main_pattern_days = pattern_counts[main_pattern]
        
        # 1. åŸºç¡€é¢‘ç‡ç½®ä¿¡åº¦
        frequency_confidence = main_pattern_days / total_days
        
        # 2. è¯„åˆ†å¼ºåº¦ç½®ä¿¡åº¦
        main_pattern_key = {
            'é»æ˜ç°è±¡': 'dawn_phenomenon',
            'è‹æœ¨æ°æ•ˆåº”': 'somogyi_effect', 
            'è¿›é£Ÿç›¸å…³': 'food_related',
            'æœªåˆ†ç±»/æ··åˆå› ç´ ': None
        }.get(main_pattern)
        
        if main_pattern_key:
            # è·å–ä¸»æ¨¡å¼çš„è¯„åˆ†
            main_scores = [p['scores'][main_pattern_key] for p in daily_patterns 
                          if p['classification'] == main_pattern]
            
            # è®¡ç®—è¯„åˆ†å¼ºåº¦ (å½’ä¸€åŒ–åˆ°0-1)
            if main_scores:
                avg_score = np.mean(main_scores)
                max_possible_score = 10  # ç†è®ºæœ€å¤§è¯„åˆ†
                score_confidence = min(avg_score / max_possible_score, 1.0)
            else:
                score_confidence = 0
        else:
            score_confidence = 0
        
        # 3. æ¨¡å¼åŒºåˆ†åº¦ç½®ä¿¡åº¦
        mixed_days = len([p for p in daily_patterns if self._is_mixed_pattern(p['scores'])])
        distinction_confidence = 1 - (mixed_days / total_days)
        
        # 4. æ—¶é—´è¿ç»­æ€§ç½®ä¿¡åº¦ (è¿ç»­å¤©æ•°è¶Šå¤šï¼Œç½®ä¿¡åº¦è¶Šé«˜)
        continuity_confidence = self._calculate_continuity_confidence(daily_patterns, main_pattern)
        
        # ç»¼åˆç½®ä¿¡åº¦è®¡ç®— (åŠ æƒå¹³å‡)
        weights = {
            'frequency': 0.4,      # é¢‘ç‡æƒé‡40%
            'score': 0.3,          # è¯„åˆ†å¼ºåº¦æƒé‡30%  
            'distinction': 0.2,    # æ¨¡å¼åŒºåˆ†åº¦æƒé‡20%
            'continuity': 0.1      # æ—¶é—´è¿ç»­æ€§æƒé‡10%
        }
        
        enhanced_confidence = (
            frequency_confidence * weights['frequency'] +
            score_confidence * weights['score'] + 
            distinction_confidence * weights['distinction'] +
            continuity_confidence * weights['continuity']
        )
        
        # ä¿å­˜è®¡ç®—è¯¦æƒ…ç”¨äºæ˜¾ç¤º
        self._last_confidence_details = {
            'frequency': frequency_confidence,
            'score': score_confidence,
            'distinction': distinction_confidence, 
            'continuity': continuity_confidence,
            'weights': weights,
            'final': enhanced_confidence
        }
        
        return enhanced_confidence
    
    def _print_confidence_breakdown(self):
        """æ‰“å°ç½®ä¿¡åº¦è®¡ç®—è¯¦æƒ…"""
        details = self._last_confidence_details
        print(f"\n   ğŸ“ˆ ç½®ä¿¡åº¦è®¡ç®—è¯¦æƒ… (æœ€ç»ˆ: {details['final']:.1%}):")
        print(f"     é¢‘ç‡ç½®ä¿¡åº¦: {details['frequency']:.1%} (æƒé‡ {details['weights']['frequency']:.0%})")
        print(f"     è¯„åˆ†å¼ºåº¦: {details['score']:.1%} (æƒé‡ {details['weights']['score']:.0%})")
        print(f"     æ¨¡å¼åŒºåˆ†åº¦: {details['distinction']:.1%} (æƒé‡ {details['weights']['distinction']:.0%})")
        print(f"     æ—¶é—´è¿ç»­æ€§: {details['continuity']:.1%} (æƒé‡ {details['weights']['continuity']:.0%})")
    
    def _calculate_continuity_confidence(self, daily_patterns, main_pattern):
        """è®¡ç®—æ—¶é—´è¿ç»­æ€§ç½®ä¿¡åº¦"""
        # æŒ‰æ—¥æœŸæ’åº
        sorted_patterns = sorted(daily_patterns, key=lambda x: x['date'])
        
        # æ‰¾åˆ°æœ€é•¿è¿ç»­åºåˆ—
        max_continuous = 0
        current_continuous = 0
        
        for pattern in sorted_patterns:
            if pattern['classification'] == main_pattern:
                current_continuous += 1
                max_continuous = max(max_continuous, current_continuous)
            else:
                current_continuous = 0
        
        # è¿ç»­æ€§ç½®ä¿¡åº¦ = æœ€é•¿è¿ç»­å¤©æ•° / æ€»å¤©æ•°
        continuity_confidence = max_continuous / len(daily_patterns)
        
        return continuity_confidence
    
    def _provide_clinical_recommendations(self, summary):
        """æä¾›ä¸´åºŠå»ºè®®"""
        print("\nğŸ’¡ ä¸´åºŠå»ºè®®:")
        
        main_pattern = summary['main_pattern']
        confidence = summary['confidence']
        
        if confidence < 0.6:
            print("     âš ï¸  æ¨¡å¼ä¸å¤Ÿæ˜ç¡®ï¼Œå»ºè®®:")
            print("        - å»¶é•¿ç›‘æµ‹æ—¶é—´")
            print("        - è®°å½•è¯¦ç»†çš„é¥®é£Ÿå’Œç”¨è¯æ—¶é—´")
            print("        - è€ƒè™‘å¤šç§å› ç´ å…±åŒä½œç”¨")
        
        elif main_pattern == "é»æ˜ç°è±¡":
            print("     âœ… ä¸»è¦ä¸ºé»æ˜ç°è±¡ï¼Œå»ºè®®:")
            print("        - è°ƒæ•´æ™šé¤æ—¶é—´å’Œè¯ç‰©å‰‚é‡")
            print("        - è€ƒè™‘ä½¿ç”¨é•¿æ•ˆèƒ°å²›ç´ ")
            print("        - é¿å…ç¡å‰åŠ é¤")
            
        elif main_pattern == "è‹æœ¨æ°æ•ˆåº”":
            print("     âš ï¸  å­˜åœ¨è‹æœ¨æ°æ•ˆåº”ï¼Œå»ºè®®:")
            print("        - å‡å°‘ç¡å‰èƒ°å²›ç´ å‰‚é‡")
            print("        - è°ƒæ•´æ™šé¤åç”¨è¯æ—¶é—´")
            print("        - ç¡å‰é€‚é‡åŠ é¤")
            print("        - å¯†åˆ‡ç›‘æµ‹å¤œé—´è¡€ç³–")
            
        elif main_pattern == "è¿›é£Ÿç›¸å…³":
            print("     ğŸ½ï¸ ä¸»è¦ä¸è¿›é£Ÿç›¸å…³ï¼Œå»ºè®®:")
            print("        - è°ƒæ•´æ—©é¤æ—¶é—´å’Œå†…å®¹")
            print("        - ä¼˜åŒ–é¤å‰ç”¨è¯æ—¶é—´")
            print("        - è®°å½•è¯¦ç»†é¥®é£Ÿæ—¥å¿—")
        
        else:
            print("     ğŸ“ æ¨¡å¼å¤æ‚ï¼Œå»ºè®®ç»¼åˆç®¡ç†:")
            print("        - è¯¦ç»†è®°å½•ç”Ÿæ´»ä½œæ¯")
            print("        - ä¸ªä½“åŒ–è°ƒæ•´æ²»ç–—æ–¹æ¡ˆ")
            print("        - å®šæœŸå¤è¯„è¡€ç³–æ¨¡å¼")
    
    def plot_analysis_results(self, subject_id=None, save_plot=False):
        """è¾“å‡ºåˆ†æç»“æœæ‘˜è¦ (ä¸ç”Ÿæˆå›¾è¡¨)"""
        if not self.analysis_results:
            print("âŒ æ²¡æœ‰åˆ†æç»“æœå¯è¾“å‡º")
            return
        
        subjects = [r for r in self.analysis_results if subject_id is None or r['subject_id'] == subject_id]
        
        for summary in subjects:
            self._output_analysis_summary(summary)
    
    def _output_analysis_summary(self, summary):
        """è¾“å‡ºåˆ†ææ‘˜è¦ (æ›¿ä»£å›¾è¡¨)"""
        print(f"\nğŸ“ˆ {summary['subject_id']} åˆ†ææ‘˜è¦:")
        print(f"   ç›‘æµ‹å¤©æ•°: {summary['analysis_days']}å¤©")
        print(f"   ä¸»è¦æ¨¡å¼: {summary['main_pattern']}")
        print(f"   ç½®ä¿¡åº¦: {summary['confidence']:.1%}")
        
        # è¾“å‡ºç»Ÿè®¡æ•°æ®è€Œéå›¾è¡¨
        daily_patterns = summary['daily_details']
        rise_amounts = [p['morning_rise']['rise_amount'] for p in daily_patterns if p['morning_rise']]
        
        if rise_amounts:
            print(f"   å¹³å‡è¡€ç³–å‡é«˜: {np.mean(rise_amounts):.1f} mmol/L")
            print(f"   å‡é«˜èŒƒå›´: {np.min(rise_amounts):.1f} - {np.max(rise_amounts):.1f} mmol/L")
        
        print("   âœ… åˆ†æå®Œæˆï¼Œæ— å›¾è¡¨ç”Ÿæˆ")

# ç¤ºä¾‹ä½¿ç”¨å‡½æ•°
def analyze_sample_data():
    """åˆ†æç¤ºä¾‹æ•°æ®"""
    analyzer = MorningGlucoseAnalyzer()
    
    print("ğŸ” æ¸…æ™¨è¡€ç³–å‡é«˜æ¨¡å¼åˆ†æå·¥å…·")
    print("=" * 50)
    
    # å°è¯•åŠ è½½HengRuiæ–‡ä»¶å¤¹ä¸­çš„æ•°æ®
    sample_files = [
        "/Users/williamsun/Documents/gplus/docs/HengRui/HRS9531_305_standardized_simulation.csv",
        "/Users/williamsun/Documents/gplus/HRS9531_305_cgms_simulation.csv",
        "/Users/williamsun/Documents/gplus/4million_cgms_simulation.csv"
    ]
    
    for file_path in sample_files:
        print(f"\nğŸ”„ å°è¯•åŠ è½½æ–‡ä»¶: {file_path}")
        if analyzer.load_data(file_path):
            print("âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå¼€å§‹åˆ†æ...")
            
            # åˆ†æå‰å‡ ä¸ªæ‚£è€…
            subjects = analyzer.glucose_data['subject_id'].unique()[:3]  # åˆ†æå‰3ä¸ªæ‚£è€…
            
            for subject in subjects:
                analyzer.analyze_morning_patterns(subject_id=subject, days_window=7)
            
            # è¾“å‡ºç»“æœæ‘˜è¦
            print(f"\nğŸ“Š è¾“å‡ºåˆ†ææ‘˜è¦...")
            analyzer.plot_analysis_results()
            
            break
    else:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ•°æ®æ–‡ä»¶")
        print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("   analyzer = MorningGlucoseAnalyzer()")
        print("   analyzer.load_data('your_data_file.csv')")
        print("   analyzer.analyze_morning_patterns()")
        print("   analyzer.plot_analysis_results()")

if __name__ == "__main__":
    analyze_sample_data()