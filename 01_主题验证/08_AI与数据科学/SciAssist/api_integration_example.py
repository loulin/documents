#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒ»å­¦æ–‡çŒ®å’Œä¸´åºŠè¯•éªŒAPIé›†æˆç¤ºä¾‹
Medical Literature and Clinical Trial API Integration Example
"""

import asyncio
import aiohttp
import json
import xml.etree.ElementTree as ET
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MedicalDataAPI:
    """åŒ»å­¦æ•°æ®APIé›†æˆç±»"""

    def __init__(self):
        self.pubmed_base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils"
        self.clinicaltrials_base_url = "https://clinicaltrials.gov/api/v2"
        self.your_email = "your_email@hospital.com"  # NCBIè¦æ±‚æä¾›é‚®ç®±
        self.api_key = "YOUR_NCBI_API_KEY"  # ç”³è¯·NCBI API key

    async def search_pubmed(self, query: str, max_results: int = 20):
        """
        æœç´¢PubMedæ–‡çŒ®

        Args:
            query: æœç´¢å…³é”®è¯
            max_results: æœ€å¤§ç»“æœæ•°
        """
        try:
            async with aiohttp.ClientSession() as session:
                # Step 1: æœç´¢è·å–PMIDåˆ—è¡¨
                search_params = {
                    'db': 'pubmed',
                    'term': query,
                    'retmax': max_results,
                    'tool': 'SciAssist',
                    'email': self.your_email,
                    'api_key': self.api_key
                }

                search_url = f"{self.pubmed_base_url}/esearch.fcgi"
                async with session.get(search_url, params=search_params) as response:
                    search_xml = await response.text()

                # è§£ææœç´¢ç»“æœè·å–PMIDåˆ—è¡¨
                root = ET.fromstring(search_xml)
                pmid_list = [id_elem.text for id_elem in root.findall('.//Id')]

                if not pmid_list:
                    return []

                # Step 2: è·å–æ–‡çŒ®è¯¦ç»†ä¿¡æ¯
                fetch_params = {
                    'db': 'pubmed',
                    'id': ','.join(pmid_list),
                    'retmode': 'xml',
                    'tool': 'SciAssist',
                    'email': self.your_email,
                    'api_key': self.api_key
                }

                fetch_url = f"{self.pubmed_base_url}/efetch.fcgi"
                async with session.get(fetch_url, params=fetch_params) as response:
                    fetch_xml = await response.text()

                # è§£ææ–‡çŒ®è¯¦æƒ…
                articles = self._parse_pubmed_xml(fetch_xml)

                logger.info(f"æˆåŠŸè·å– {len(articles)} ç¯‡PubMedæ–‡çŒ®")
                return articles

        except Exception as e:
            logger.error(f"PubMedæœç´¢å¤±è´¥: {str(e)}")
            return []

    def _parse_pubmed_xml(self, xml_content: str):
        """è§£æPubMed XMLå“åº”"""
        articles = []

        try:
            root = ET.fromstring(xml_content)

            for article_elem in root.findall('.//PubmedArticle'):
                article = {}

                # åŸºæœ¬ä¿¡æ¯
                pmid_elem = article_elem.find('.//PMID')
                article['pmid'] = pmid_elem.text if pmid_elem is not None else ''

                # æ ‡é¢˜
                title_elem = article_elem.find('.//ArticleTitle')
                article['title'] = title_elem.text if title_elem is not None else ''

                # æ‘˜è¦
                abstract_elem = article_elem.find('.//AbstractText')
                article['abstract'] = abstract_elem.text if abstract_elem is not None else ''

                # ä½œè€…
                authors = []
                for author_elem in article_elem.findall('.//Author'):
                    last_name = author_elem.find('LastName')
                    first_name = author_elem.find('ForeName')
                    if last_name is not None and first_name is not None:
                        authors.append(f"{first_name.text} {last_name.text}")
                article['authors'] = authors

                # æœŸåˆŠ
                journal_elem = article_elem.find('.//Title')
                article['journal'] = journal_elem.text if journal_elem is not None else ''

                # å‘è¡¨æ—¥æœŸ
                pub_date_elem = article_elem.find('.//PubDate')
                if pub_date_elem is not None:
                    year = pub_date_elem.find('Year')
                    month = pub_date_elem.find('Month')
                    article['publication_date'] = f"{year.text if year is not None else ''}-{month.text if month is not None else ''}"

                articles.append(article)

        except ET.ParseError as e:
            logger.error(f"XMLè§£æé”™è¯¯: {str(e)}")

        return articles

    async def search_clinical_trials(self, condition: str, max_studies: int = 20):
        """
        æœç´¢ä¸´åºŠè¯•éªŒ

        Args:
            condition: ç–¾ç—…æ¡ä»¶
            max_studies: æœ€å¤§ç»“æœæ•°
        """
        try:
            async with aiohttp.ClientSession() as session:
                params = {
                    'query.cond': condition,
                    'countTotal': True,
                    'pageSize': max_studies,
                    'format': 'json'
                }

                url = f"{self.clinicaltrials_base_url}/studies"
                async with session.get(url, params=params) as response:
                    data = await response.json()

                trials = []
                studies = data.get('studies', [])

                for study in studies:
                    protocol_section = study.get('protocolSection', {})
                    identification_module = protocol_section.get('identificationModule', {})
                    status_module = protocol_section.get('statusModule', {})
                    design_module = protocol_section.get('designModule', {})
                    conditions_module = protocol_section.get('conditionsModule', {})

                    trial = {
                        'nct_id': identification_module.get('nctId', ''),
                        'title': identification_module.get('briefTitle', ''),
                        'status': status_module.get('overallStatus', ''),
                        'phase': design_module.get('phases', []),
                        'conditions': conditions_module.get('conditions', []),
                        'brief_summary': identification_module.get('briefSummary', ''),
                        'start_date': status_module.get('startDateStruct', {}).get('date', ''),
                        'completion_date': status_module.get('completionDateStruct', {}).get('date', ''),
                    }
                    trials.append(trial)

                logger.info(f"æˆåŠŸè·å– {len(trials)} ä¸ªä¸´åºŠè¯•éªŒ")
                return trials

        except Exception as e:
            logger.error(f"ä¸´åºŠè¯•éªŒæœç´¢å¤±è´¥: {str(e)}")
            return []

    async def get_semantic_scholar_alternative(self, query: str, max_papers: int = 20):
        """
        ä½¿ç”¨Semantic Scholarä½œä¸ºGoogle Scholarçš„æ›¿ä»£

        Args:
            query: æœç´¢å…³é”®è¯
            max_papers: æœ€å¤§ç»“æœæ•°
        """
        try:
            async with aiohttp.ClientSession() as session:
                url = "https://api.semanticscholar.org/graph/v1/paper/search"
                params = {
                    'query': query,
                    'limit': max_papers,
                    'fields': 'paperId,title,abstract,authors,year,citationCount,journal,url'
                }

                headers = {
                    'User-Agent': 'SciAssist-Medical-Research-Tool'
                }

                async with session.get(url, params=params, headers=headers) as response:
                    data = await response.json()

                papers = []
                for paper_data in data.get('data', []):
                    paper = {
                        'id': paper_data.get('paperId', ''),
                        'title': paper_data.get('title', ''),
                        'abstract': paper_data.get('abstract', ''),
                        'authors': [author.get('name', '') for author in paper_data.get('authors', [])],
                        'year': paper_data.get('year', ''),
                        'citation_count': paper_data.get('citationCount', 0),
                        'journal': paper_data.get('journal', {}).get('name', '') if paper_data.get('journal') else '',
                        'url': paper_data.get('url', '')
                    }
                    papers.append(paper)

                logger.info(f"æˆåŠŸè·å– {len(papers)} ç¯‡Semantic Scholarè®ºæ–‡")
                return papers

        except Exception as e:
            logger.error(f"Semantic Scholaræœç´¢å¤±è´¥: {str(e)}")
            return []

class MedicalResearchService:
    """åŒ»å­¦ç ”ç©¶æœåŠ¡"""

    def __init__(self):
        self.api = MedicalDataAPI()

    async def comprehensive_research(self, topic: str, doctor_specialty: str = None):
        """
        ç»¼åˆç ”ç©¶ï¼šåŒæ—¶æœç´¢æ–‡çŒ®å’Œä¸´åºŠè¯•éªŒ

        Args:
            topic: ç ”ç©¶ä¸»é¢˜
            doctor_specialty: åŒ»ç”Ÿä¸“ç§‘ï¼ˆç”¨äºä¸ªæ€§åŒ–æ¨èï¼‰
        """
        results = {
            'topic': topic,
            'search_time': datetime.now().isoformat(),
            'pubmed_articles': [],
            'clinical_trials': [],
            'semantic_scholar_papers': [],
            'summary': {}
        }

        # å¹¶å‘æ‰§è¡Œå¤šä¸ªæœç´¢
        tasks = [
            self.api.search_pubmed(topic, max_results=10),
            self.api.search_clinical_trials(topic, max_studies=10),
            self.api.get_semantic_scholar_alternative(topic, max_papers=10)
        ]

        try:
            pubmed_results, trial_results, scholar_results = await asyncio.gather(*tasks)

            results['pubmed_articles'] = pubmed_results
            results['clinical_trials'] = trial_results
            results['semantic_scholar_papers'] = scholar_results

            # ç”Ÿæˆæ‘˜è¦
            results['summary'] = {
                'total_pubmed_articles': len(pubmed_results),
                'total_clinical_trials': len(trial_results),
                'total_scholar_papers': len(scholar_results),
                'active_trials': len([t for t in trial_results if t['status'] in ['Recruiting', 'Active, not recruiting']]),
                'recent_papers': len([p for p in pubmed_results if '2024' in str(p.get('publication_date', '')) or '2025' in str(p.get('publication_date', ''))])
            }

        except Exception as e:
            logger.error(f"ç»¼åˆç ”ç©¶å¤±è´¥: {str(e)}")

        return results

# ä½¿ç”¨ç¤ºä¾‹
async def demo_medical_research():
    """æ¼”ç¤ºåŒ»å­¦ç ”ç©¶APIçš„ä½¿ç”¨"""

    service = MedicalResearchService()

    # æ¨¡æ‹Ÿå†…åˆ†æ³ŒåŒ»ç”Ÿçš„ç ”ç©¶éœ€æ±‚
    research_topics = [
        "GLP-1 receptor agonists diabetes",
        "thyroid cancer treatment",
        "insulin resistance PCOS",
        "diabetic nephropathy"
    ]

    for topic in research_topics:
        print(f"\nğŸ” æ­£åœ¨ç ”ç©¶: {topic}")
        print("-" * 50)

        results = await service.comprehensive_research(topic, doctor_specialty="endocrinology")

        print(f"ğŸ“š PubMedæ–‡çŒ®: {results['summary']['total_pubmed_articles']} ç¯‡")
        print(f"ğŸ§ª ä¸´åºŠè¯•éªŒ: {results['summary']['total_clinical_trials']} ä¸ª")
        print(f"ğŸ“– å­¦æœ¯è®ºæ–‡: {results['summary']['total_scholar_papers']} ç¯‡")
        print(f"ğŸƒ è¿›è¡Œä¸­è¯•éªŒ: {results['summary']['active_trials']} ä¸ª")
        print(f"ğŸ†• è¿‘æœŸè®ºæ–‡: {results['summary']['recent_papers']} ç¯‡")

        # æ˜¾ç¤ºå‰3ä¸ªç»“æœç¤ºä¾‹
        if results['pubmed_articles']:
            print(f"\nğŸ“° æœ€æ–°PubMedæ–‡çŒ®:")
            for i, article in enumerate(results['pubmed_articles'][:3], 1):
                print(f"{i}. {article['title'][:100]}...")

        if results['clinical_trials']:
            print(f"\nğŸ§ª ç›¸å…³ä¸´åºŠè¯•éªŒ:")
            for i, trial in enumerate(results['clinical_trials'][:3], 1):
                print(f"{i}. {trial['title'][:80]}... [Status: {trial['status']}]")

if __name__ == "__main__":
    print("ğŸ¥ åŒ»å­¦æ–‡çŒ®ä¸ä¸´åºŠè¯•éªŒAPIé›†æˆæ¼”ç¤º")
    print("=" * 60)

    # è¿è¡Œæ¼”ç¤º
    asyncio.run(demo_medical_research())