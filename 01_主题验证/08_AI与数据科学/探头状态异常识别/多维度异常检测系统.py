#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šç»´åº¦CGMSå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ
æ•´åˆå¤šç§æ£€æµ‹æ–¹æ³•ï¼Œå…¨é¢è¯†åˆ«ä¼ æ„Ÿå™¨å¼‚å¸¸
"""

import numpy as np
import pandas as pd
from scipy import signal, stats
from scipy.fft import fft, fftfreq
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class ComprehensiveCGMSAnomalyDetector:
    """ç»¼åˆCGMSå¼‚å¸¸æ£€æµ‹å™¨ - å¤šç»´åº¦æ–¹æ³•"""

    def __init__(self):
        self.methods = {
            'rate_based': True,      # åŸºäºå˜åŒ–ç‡ï¼ˆå·²æœ‰ï¼‰
            'statistical': True,     # ç»Ÿè®¡å­¦æ–¹æ³•
            'pattern_based': True,   # æ¨¡å¼è¯†åˆ«
            'frequency': True,       # é¢‘åŸŸåˆ†æ
            'ml_based': True,        # æœºå™¨å­¦ä¹ 
            'physiological': True,   # ç”Ÿç†å­¦çº¦æŸ
            'temporal': True,        # æ—¶é—´åºåˆ—åˆ†æ
            'context_aware': True    # ä¸Šä¸‹æ–‡æ„ŸçŸ¥
        }

    def method_1_statistical_outliers(self, glucose_data, contamination=0.1):
        """
        æ–¹æ³•1ï¼šç»Ÿè®¡å­¦å¼‚å¸¸æ£€æµ‹

        åŸºäºç»Ÿè®¡åˆ†å¸ƒçš„å¼‚å¸¸å€¼æ£€æµ‹ï¼š
        - Z-scoreæ£€æµ‹
        - å››åˆ†ä½è·(IQR)æ£€æµ‹
        - æ”¹è¿›çš„Z-scoreï¼ˆMADï¼‰
        """
        results = {
            'method': 'ç»Ÿè®¡å­¦å¼‚å¸¸æ£€æµ‹',
            'anomalies': [],
            'scores': [],
            'details': {}
        }

        glucose_array = np.array(glucose_data)

        # 1. Z-scoreæ£€æµ‹
        z_scores = np.abs(stats.zscore(glucose_array))
        z_threshold = 2.5  # 2.5ä¸ªæ ‡å‡†å·®
        z_anomalies = z_scores > z_threshold

        # 2. IQRæ–¹æ³•
        Q1 = np.percentile(glucose_array, 25)
        Q3 = np.percentile(glucose_array, 75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        iqr_anomalies = (glucose_array < lower_bound) | (glucose_array > upper_bound)

        # 3. æ”¹è¿›çš„Z-score (MAD - Median Absolute Deviation)
        median = np.median(glucose_array)
        mad = np.median(np.abs(glucose_array - median))
        mad_z_scores = 0.6745 * (glucose_array - median) / mad
        mad_threshold = 3.5
        mad_anomalies = np.abs(mad_z_scores) > mad_threshold

        # ç»¼åˆè¯„åˆ†
        anomaly_indices = np.where(z_anomalies | iqr_anomalies | mad_anomalies)[0]

        results['anomalies'] = anomaly_indices.tolist()
        results['scores'] = z_scores.tolist()
        results['details'] = {
            'z_score_anomalies': np.sum(z_anomalies),
            'iqr_anomalies': np.sum(iqr_anomalies),
            'mad_anomalies': np.sum(mad_anomalies),
            'bounds': {'lower': lower_bound, 'upper': upper_bound},
            'mad_threshold': mad_threshold
        }

        return results

    def method_2_pattern_recognition(self, glucose_data, window_size=15):
        """
        æ–¹æ³•2ï¼šæ¨¡å¼è¯†åˆ«å¼‚å¸¸æ£€æµ‹

        è¯†åˆ«å¼‚å¸¸æ¨¡å¼ï¼š
        - å¹³å°æ¨¡å¼ï¼ˆè¿ç»­ç›¸åŒå€¼ï¼‰
        - é”¯é½¿æ¨¡å¼ï¼ˆé«˜é¢‘æŒ¯è¡ï¼‰
        - è¶‹åŠ¿çªå˜
        - å‘¨æœŸæ€§å¼‚å¸¸
        """
        results = {
            'method': 'æ¨¡å¼è¯†åˆ«å¼‚å¸¸æ£€æµ‹',
            'anomalies': [],
            'patterns': {},
            'details': {}
        }

        glucose_array = np.array(glucose_data)
        anomaly_indices = set()

        # 1. å¹³å°æ£€æµ‹ï¼ˆå¹³å¦ä¿¡å·ï¼‰
        flat_tolerance = 0.5  # mg/dL
        flat_min_length = 6   # è‡³å°‘6ä¸ªç‚¹

        flat_segments = []
        current_flat_start = None

        for i in range(1, len(glucose_array)):
            if abs(glucose_array[i] - glucose_array[i-1]) < flat_tolerance:
                if current_flat_start is None:
                    current_flat_start = i-1
            else:
                if current_flat_start is not None:
                    length = i - current_flat_start
                    if length >= flat_min_length:
                        flat_segments.append((current_flat_start, i-1, length))
                        anomaly_indices.update(range(current_flat_start, i))
                    current_flat_start = None

        # 2. é”¯é½¿æ¨¡å¼æ£€æµ‹ï¼ˆé«˜é¢‘æŒ¯è¡ï¼‰
        if len(glucose_array) > 10:
            # è®¡ç®—äºŒé˜¶å·®åˆ†æ£€æµ‹æŒ¯è¡
            second_diff = np.diff(glucose_array, n=2)
            oscillation_threshold = np.std(second_diff) * 2
            oscillation_indices = np.where(np.abs(second_diff) > oscillation_threshold)[0] + 1
            anomaly_indices.update(oscillation_indices)

        # 3. è¶‹åŠ¿çªå˜æ£€æµ‹
        if len(glucose_array) > window_size * 2:
            trend_changes = []
            for i in range(window_size, len(glucose_array) - window_size):
                # å‰åçª—å£çš„è¶‹åŠ¿æ¯”è¾ƒ
                before_trend = np.polyfit(range(window_size),
                                        glucose_array[i-window_size:i], 1)[0]
                after_trend = np.polyfit(range(window_size),
                                       glucose_array[i:i+window_size], 1)[0]

                trend_change = abs(after_trend - before_trend)
                if trend_change > 2.0:  # mg/dL/min è¶‹åŠ¿çªå˜é˜ˆå€¼
                    trend_changes.append(i)
                    anomaly_indices.add(i)

        # 4. å‘¨æœŸæ€§å¼‚å¸¸æ£€æµ‹
        if len(glucose_array) > 30:
            # æ£€æµ‹å¼‚å¸¸å‘¨æœŸæ€§æ¨¡å¼
            autocorr = np.correlate(glucose_array, glucose_array, mode='full')
            autocorr = autocorr[autocorr.size // 2:]

            # å¯»æ‰¾å¼‚å¸¸å¼ºçš„å‘¨æœŸæ€§
            peaks, _ = signal.find_peaks(autocorr[1:20], height=np.max(autocorr) * 0.3)
            if len(peaks) > 3:  # è¿‡å¤šçŸ­å‘¨æœŸå¯èƒ½æ˜¯ä¼ æ„Ÿå™¨å™ªå£°
                anomaly_indices.update(peaks + len(glucose_array) // 2)

        results['anomalies'] = list(anomaly_indices)
        results['patterns'] = {
            'flat_segments': flat_segments,
            'trend_changes': len([i for i in anomaly_indices if i in trend_changes]) if 'trend_changes' in locals() else 0,
            'oscillations': len(oscillation_indices) if 'oscillation_indices' in locals() else 0
        }

        return results

    def method_3_frequency_analysis(self, glucose_data, sampling_rate=1/15):
        """
        æ–¹æ³•3ï¼šé¢‘åŸŸåˆ†æå¼‚å¸¸æ£€æµ‹

        åˆ†æé¢‘è°±ç‰¹å¾ï¼š
        - å¼‚å¸¸é«˜é¢‘æˆåˆ†ï¼ˆä¼ æ„Ÿå™¨å™ªå£°ï¼‰
        - ä¸è‡ªç„¶çš„å‘¨æœŸæ€§
        - é¢‘è°±èƒ½é‡åˆ†å¸ƒå¼‚å¸¸
        """
        results = {
            'method': 'é¢‘åŸŸåˆ†æå¼‚å¸¸æ£€æµ‹',
            'anomalies': [],
            'frequency_features': {},
            'details': {}
        }

        glucose_array = np.array(glucose_data)
        n = len(glucose_array)

        if n < 10:
            return results

        # FFTåˆ†æ
        fft_values = fft(glucose_array)
        frequencies = fftfreq(n, d=1/sampling_rate)

        # åŠŸç‡è°±å¯†åº¦
        psd = np.abs(fft_values)**2

        # ç”Ÿç†å­¦é¢‘ç‡èŒƒå›´åˆ†æ
        # æ­£å¸¸è¡€ç³–å˜åŒ–ä¸»è¦åœ¨ä½é¢‘èŒƒå›´ (< 0.01 Hzï¼Œå³ > 100åˆ†é’Ÿå‘¨æœŸ)
        nyquist_freq = sampling_rate / 2

        # å®šä¹‰é¢‘æ®µ
        very_low_freq = frequencies < 0.005    # > 200åˆ†é’Ÿå‘¨æœŸï¼ˆç”Ÿç†æ€§ï¼‰
        low_freq = (frequencies >= 0.005) & (frequencies < 0.02)   # 50-200åˆ†é’Ÿ
        mid_freq = (frequencies >= 0.02) & (frequencies < 0.1)     # 10-50åˆ†é’Ÿ
        high_freq = frequencies >= 0.1         # < 10åˆ†é’Ÿï¼ˆå¯èƒ½å¼‚å¸¸ï¼‰

        # è®¡ç®—å„é¢‘æ®µèƒ½é‡
        total_energy = np.sum(psd)
        very_low_energy = np.sum(psd[very_low_freq])
        low_energy = np.sum(psd[low_freq])
        mid_energy = np.sum(psd[mid_freq])
        high_energy = np.sum(psd[high_freq])

        # å¼‚å¸¸æ£€æµ‹ï¼šé«˜é¢‘èƒ½é‡å æ¯”è¿‡é«˜
        high_freq_ratio = high_energy / total_energy
        if high_freq_ratio > 0.15:  # é«˜é¢‘èƒ½é‡è¶…è¿‡15%å¯èƒ½å¼‚å¸¸
            # é€šè¿‡æ»‘åŠ¨çª—å£æ‰¾å‡ºé«˜é¢‘å¼‚å¸¸åŒºåŸŸ
            window_size = 10
            for i in range(0, n - window_size, window_size//2):
                window_data = glucose_array[i:i+window_size]
                window_fft = fft(window_data)
                window_psd = np.abs(window_fft)**2
                window_high_energy = np.sum(window_psd[len(window_psd)//3:])
                window_total_energy = np.sum(window_psd)

                if window_high_energy / window_total_energy > 0.2:
                    results['anomalies'].extend(range(i, min(i+window_size, n)))

        # æ£€æµ‹å¼‚å¸¸å‘¨æœŸæ€§
        # å¯»æ‰¾ä¸è‡ªç„¶çš„å¼ºå‘¨æœŸä¿¡å·
        peak_indices = signal.find_peaks(psd[1:n//2], height=np.max(psd) * 0.1)[0]
        for peak_idx in peak_indices:
            freq = frequencies[peak_idx + 1]
            period_minutes = 1/freq if freq > 0 else float('inf')

            # 5-20åˆ†é’Ÿçš„å¼ºå‘¨æœŸå¯èƒ½æ˜¯ä¼ æ„Ÿå™¨å¼‚å¸¸
            if 5 <= period_minutes <= 20:
                # æ ‡è®°ç›¸å…³æ—¶é—´ç‚¹
                period_samples = int(period_minutes * sampling_rate * 60)
                for i in range(0, n, period_samples):
                    if i < n:
                        results['anomalies'].append(i)

        results['frequency_features'] = {
            'high_freq_ratio': high_freq_ratio,
            'dominant_frequency': frequencies[np.argmax(psd[1:n//2]) + 1],
            'energy_distribution': {
                'very_low': very_low_energy / total_energy,
                'low': low_energy / total_energy,
                'mid': mid_energy / total_energy,
                'high': high_energy / total_energy
            }
        }

        # å»é‡
        results['anomalies'] = list(set(results['anomalies']))

        return results

    def method_4_machine_learning(self, glucose_data, contamination=0.1):
        """
        æ–¹æ³•4ï¼šæœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹

        ä½¿ç”¨æ— ç›‘ç£å­¦ä¹ ï¼š
        - Isolation Forest
        - åŸºäºç‰¹å¾å·¥ç¨‹çš„å¼‚å¸¸æ£€æµ‹
        """
        results = {
            'method': 'æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹',
            'anomalies': [],
            'scores': [],
            'features': {}
        }

        glucose_array = np.array(glucose_data)
        n = len(glucose_array)

        if n < 20:
            return results

        # ç‰¹å¾å·¥ç¨‹
        features = []

        for i in range(2, n-2):
            feature_vector = [
                glucose_array[i],                                    # å½“å‰å€¼
                glucose_array[i] - glucose_array[i-1],              # ä¸€é˜¶å·®åˆ†
                glucose_array[i-1] - 2*glucose_array[i] + glucose_array[i+1],  # äºŒé˜¶å·®åˆ†
                np.mean(glucose_array[max(0, i-5):i+1]),           # 5ç‚¹ç§»åŠ¨å¹³å‡
                np.std(glucose_array[max(0, i-5):i+1]),            # 5ç‚¹ç§»åŠ¨æ ‡å‡†å·®
                glucose_array[i] - np.mean(glucose_array[max(0, i-10):i+1]),  # ä¸10ç‚¹å‡å€¼åå·®
            ]

            # æ·»åŠ æ›´å¤šç‰¹å¾
            if i >= 5:
                recent_trend = np.polyfit(range(5), glucose_array[i-4:i+1], 1)[0]
                feature_vector.append(recent_trend)  # çŸ­æœŸè¶‹åŠ¿
            else:
                feature_vector.append(0)

            features.append(feature_vector)

        features = np.array(features)

        # æ ‡å‡†åŒ–ç‰¹å¾
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)

        # Isolation Forestå¼‚å¸¸æ£€æµ‹
        iso_forest = IsolationForest(contamination=contamination, random_state=42)
        anomaly_labels = iso_forest.fit_predict(features_scaled)
        anomaly_scores = iso_forest.score_samples(features_scaled)

        # å¼‚å¸¸ç‚¹ç´¢å¼•ï¼ˆè°ƒæ•´åç§»ï¼‰
        anomaly_indices = np.where(anomaly_labels == -1)[0] + 2  # åŠ å›åç§»

        results['anomalies'] = anomaly_indices.tolist()
        results['scores'] = anomaly_scores.tolist()
        results['features'] = {
            'feature_count': features.shape[1],
            'anomaly_ratio': len(anomaly_indices) / len(features)
        }

        return results

    def method_5_physiological_constraints(self, glucose_data, timestamps=None):
        """
        æ–¹æ³•5ï¼šç”Ÿç†å­¦çº¦æŸæ£€éªŒ

        åŸºäºç”Ÿç†å­¦è§„å¾‹æ£€æµ‹å¼‚å¸¸ï¼š
        - ç»å¯¹å€¼èŒƒå›´æ£€æŸ¥
        - ç”Ÿç†å­¦å˜åŒ–é€Ÿåº¦é™åˆ¶
        - é¤åå“åº”æ¨¡å¼æ£€éªŒ
        - æ—¥èŠ‚å¾‹æ¨¡å¼æ£€éªŒ
        """
        results = {
            'method': 'ç”Ÿç†å­¦çº¦æŸæ£€éªŒ',
            'anomalies': [],
            'violations': {},
            'details': {}
        }

        glucose_array = np.array(glucose_data)
        anomaly_indices = set()

        # 1. ç»å¯¹èŒƒå›´æ£€æŸ¥
        ABSOLUTE_MIN = 20   # mg/dL
        ABSOLUTE_MAX = 600  # mg/dL
        NORMAL_MIN = 70     # mg/dL
        NORMAL_MAX = 200    # mg/dL

        absolute_violations = np.where((glucose_array < ABSOLUTE_MIN) |
                                     (glucose_array > ABSOLUTE_MAX))[0]
        extreme_violations = np.where((glucose_array < 40) |
                                    (glucose_array > 400))[0]

        anomaly_indices.update(absolute_violations)
        anomaly_indices.update(extreme_violations)

        # 2. ç”Ÿç†å˜åŒ–é€Ÿåº¦æ£€æŸ¥ï¼ˆå·²åœ¨å˜åŒ–ç‡ä¸­æ¶µç›–ï¼Œè¿™é‡Œæ£€æŸ¥æ›´ç»†è‡´çš„çº¦æŸï¼‰
        if len(glucose_array) > 1:
            time_intervals = np.ones(len(glucose_array)-1) * 15  # é»˜è®¤15åˆ†é’Ÿ
            if timestamps is not None:
                time_intervals = [(timestamps[i+1] - timestamps[i]).total_seconds()/60
                                for i in range(len(timestamps)-1)]

            rates = np.diff(glucose_array) / time_intervals

            # æé€Ÿå˜åŒ–æ£€æŸ¥ï¼ˆæ¯”åŸºæœ¬å˜åŒ–ç‡æ£€æŸ¥æ›´ä¸¥æ ¼ï¼‰
            EXTREME_RATE = 15.0  # mg/dL/min
            extreme_rate_violations = np.where(np.abs(rates) > EXTREME_RATE)[0]
            anomaly_indices.update(extreme_rate_violations)

        # 3. æŒç»­å¼‚å¸¸å€¼æ£€æŸ¥
        # è¿ç»­è¿‡é«˜æˆ–è¿‡ä½çš„å€¼å¯èƒ½æ˜¯ä¼ æ„Ÿå™¨é—®é¢˜
        if len(glucose_array) > 10:
            # è¿ç»­é«˜å€¼
            high_mask = glucose_array > 300
            high_segments = self._find_consecutive_segments(high_mask, min_length=6)
            for start, end in high_segments:
                anomaly_indices.update(range(start, end+1))

            # è¿ç»­ä½å€¼
            low_mask = glucose_array < 60
            low_segments = self._find_consecutive_segments(low_mask, min_length=4)
            for start, end in low_segments:
                anomaly_indices.update(range(start, end+1))

        # 4. éç”Ÿç†æ€§æ¨¡å¼æ£€æŸ¥
        # æ£€æŸ¥è¿‡äºè§„å¾‹çš„æ¨¡å¼ï¼ˆå¯èƒ½æ˜¯ä¼ æ„Ÿå™¨æ•…éšœï¼‰
        if len(glucose_array) > 20:
            # æ£€æŸ¥é‡å¤æ•°å€¼
            unique_values, counts = np.unique(np.round(glucose_array, 1), return_counts=True)
            repeated_values = unique_values[counts > len(glucose_array) * 0.1]  # è¶…è¿‡10%é‡å¤

            for repeated_val in repeated_values:
                repeated_indices = np.where(np.abs(glucose_array - repeated_val) < 0.1)[0]
                if len(repeated_indices) > 5:  # è¿ç»­é‡å¤
                    anomaly_indices.update(repeated_indices)

        results['anomalies'] = list(anomaly_indices)
        results['violations'] = {
            'absolute_violations': len(absolute_violations),
            'extreme_violations': len(extreme_violations),
            'extreme_rate_violations': len(extreme_rate_violations) if 'extreme_rate_violations' in locals() else 0,
        }

        return results

    def _find_consecutive_segments(self, boolean_mask, min_length=3):
        """æŸ¥æ‰¾è¿ç»­çš„Trueæ®µè½"""
        segments = []
        start = None

        for i, val in enumerate(boolean_mask):
            if val and start is None:
                start = i
            elif not val and start is not None:
                if i - start >= min_length:
                    segments.append((start, i-1))
                start = None

        # å¤„ç†ç»“å°¾
        if start is not None and len(boolean_mask) - start >= min_length:
            segments.append((start, len(boolean_mask)-1))

        return segments

    def method_6_temporal_analysis(self, glucose_data, timestamps=None):
        """
        æ–¹æ³•6ï¼šæ—¶é—´åºåˆ—åˆ†æ

        æ—¶é—´ç›¸å…³å¼‚å¸¸æ£€æµ‹ï¼š
        - æ—¶é—´é—´éš”å¼‚å¸¸
        - æ—¶åºé¢„æµ‹åå·®
        - å­£èŠ‚æ€§å¼‚å¸¸
        """
        results = {
            'method': 'æ—¶é—´åºåˆ—åˆ†æ',
            'anomalies': [],
            'temporal_features': {},
            'details': {}
        }

        glucose_array = np.array(glucose_data)
        anomaly_indices = set()

        # 1. æ—¶é—´é—´éš”å¼‚å¸¸
        if timestamps is not None:
            time_intervals = [(timestamps[i+1] - timestamps[i]).total_seconds()/60
                            for i in range(len(timestamps)-1)]

            median_interval = np.median(time_intervals)

            for i, interval in enumerate(time_intervals):
                # å¼‚å¸¸çš„æ—¶é—´é—´éš”å¯èƒ½è¡¨ç¤ºæ•°æ®è´¨é‡é—®é¢˜
                if interval < 2 or interval > 60:  # å°äº2åˆ†é’Ÿæˆ–å¤§äº60åˆ†é’Ÿ
                    anomaly_indices.add(i)
                    anomaly_indices.add(i+1)

        # 2. ç®€å•æ—¶åºé¢„æµ‹åå·®
        if len(glucose_array) > 10:
            # ä½¿ç”¨ç§»åŠ¨å¹³å‡ä½œä¸ºç®€å•é¢„æµ‹
            window_size = 5
            for i in range(window_size, len(glucose_array)):
                predicted = np.mean(glucose_array[i-window_size:i])
                actual = glucose_array[i]
                prediction_error = abs(actual - predicted)

                # å¦‚æœé¢„æµ‹è¯¯å·®è¿‡å¤§ï¼Œå¯èƒ½æ˜¯å¼‚å¸¸
                if prediction_error > 50:  # mg/dL
                    anomaly_indices.add(i)

        # 3. å±€éƒ¨å¼‚å¸¸æ£€æµ‹ï¼ˆåŸºäºå±€éƒ¨å¯†åº¦ï¼‰
        if len(glucose_array) > 15:
            window_size = 7
            for i in range(window_size, len(glucose_array) - window_size):
                local_window = glucose_array[i-window_size:i+window_size+1]
                center_value = glucose_array[i]

                # è®¡ç®—å±€éƒ¨ç»Ÿè®¡
                local_mean = np.mean(local_window)
                local_std = np.std(local_window)

                if local_std > 0:
                    z_score = abs(center_value - local_mean) / local_std
                    if z_score > 3:  # å±€éƒ¨å¼‚å¸¸
                        anomaly_indices.add(i)

        results['anomalies'] = list(anomaly_indices)
        results['temporal_features'] = {
            'time_interval_anomalies': len([i for i in anomaly_indices if i < len(glucose_array)-1]) if timestamps else 0,
            'prediction_anomalies': len(anomaly_indices),
        }

        return results

    def comprehensive_detection(self, glucose_data, timestamps=None, methods=None):
        """
        ç»¼åˆå¼‚å¸¸æ£€æµ‹ï¼šæ•´åˆæ‰€æœ‰æ–¹æ³•
        """
        if methods is None:
            methods = self.methods

        print("ğŸ” å¼€å§‹ç»¼åˆå¼‚å¸¸æ£€æµ‹...")
        print("=" * 50)

        all_results = {}
        all_anomalies = set()
        method_votes = {}

        # æ‰§è¡Œå„ç§æ£€æµ‹æ–¹æ³•
        if methods.get('statistical', True):
            print("ğŸ“Š ç»Ÿè®¡å­¦å¼‚å¸¸æ£€æµ‹...")
            result = self.method_1_statistical_outliers(glucose_data)
            all_results['statistical'] = result
            for idx in result['anomalies']:
                method_votes[idx] = method_votes.get(idx, 0) + 1
            all_anomalies.update(result['anomalies'])

        if methods.get('pattern_based', True):
            print("ğŸ” æ¨¡å¼è¯†åˆ«å¼‚å¸¸æ£€æµ‹...")
            result = self.method_2_pattern_recognition(glucose_data)
            all_results['pattern_based'] = result
            for idx in result['anomalies']:
                method_votes[idx] = method_votes.get(idx, 0) + 1
            all_anomalies.update(result['anomalies'])

        if methods.get('frequency', True):
            print("ğŸ“ˆ é¢‘åŸŸåˆ†æå¼‚å¸¸æ£€æµ‹...")
            result = self.method_3_frequency_analysis(glucose_data)
            all_results['frequency'] = result
            for idx in result['anomalies']:
                method_votes[idx] = method_votes.get(idx, 0) + 1
            all_anomalies.update(result['anomalies'])

        if methods.get('ml_based', True):
            print("ğŸ¤– æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹...")
            result = self.method_4_machine_learning(glucose_data)
            all_results['ml_based'] = result
            for idx in result['anomalies']:
                method_votes[idx] = method_votes.get(idx, 0) + 1
            all_anomalies.update(result['anomalies'])

        if methods.get('physiological', True):
            print("ğŸ§¬ ç”Ÿç†å­¦çº¦æŸæ£€éªŒ...")
            result = self.method_5_physiological_constraints(glucose_data, timestamps)
            all_results['physiological'] = result
            for idx in result['anomalies']:
                method_votes[idx] = method_votes.get(idx, 0) + 1
            all_anomalies.update(result['anomalies'])

        if methods.get('temporal', True):
            print("â° æ—¶é—´åºåˆ—åˆ†æ...")
            result = self.method_6_temporal_analysis(glucose_data, timestamps)
            all_results['temporal'] = result
            for idx in result['anomalies']:
                method_votes[idx] = method_votes.get(idx, 0) + 1
            all_anomalies.update(result['anomalies'])

        # ç»¼åˆè¯„ä¼°
        print("\nğŸ“Š ç»¼åˆç»“æœåˆ†æ...")

        # æŒ‰æŠ•ç¥¨æ•°æ’åºå¼‚å¸¸ç‚¹
        sorted_anomalies = sorted(method_votes.items(), key=lambda x: x[1], reverse=True)

        # åˆ†ç±»å¼‚å¸¸ä¸¥é‡ç¨‹åº¦
        high_confidence = [idx for idx, votes in sorted_anomalies if votes >= 3]
        medium_confidence = [idx for idx, votes in sorted_anomalies if votes == 2]
        low_confidence = [idx for idx, votes in sorted_anomalies if votes == 1]

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        comprehensive_result = {
            'total_methods': len([k for k, v in methods.items() if v]),
            'all_anomalies': list(all_anomalies),
            'high_confidence_anomalies': high_confidence,
            'medium_confidence_anomalies': medium_confidence,
            'low_confidence_anomalies': low_confidence,
            'method_results': all_results,
            'voting_results': method_votes,
            'summary': {
                'total_anomalies': len(all_anomalies),
                'high_confidence_count': len(high_confidence),
                'medium_confidence_count': len(medium_confidence),
                'low_confidence_count': len(low_confidence)
            }
        }

        return comprehensive_result

def demonstrate_comprehensive_detection():
    """æ¼”ç¤ºç»¼åˆå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ"""
    print("ğŸ©¸ å¤šç»´åº¦CGMSå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 70)

    # åˆ›å»ºæ£€æµ‹å™¨
    detector = ComprehensiveCGMSAnomalyDetector()

    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆåŒ…å«å„ç§ç±»å‹çš„å¼‚å¸¸ï¼‰
    np.random.seed(42)
    n_points = 100

    # åŸºç¡€è¡€ç³–æ¨¡å¼
    base_glucose = 120 + np.cumsum(np.random.normal(0, 2, n_points))

    # æ·»åŠ å„ç§å¼‚å¸¸
    test_glucose = base_glucose.copy()

    # ç»Ÿè®¡å¼‚å¸¸ï¼šæå€¼
    test_glucose[20] = 300  # ç»Ÿè®¡å¼‚å¸¸å€¼
    test_glucose[21] = 50   # å¦ä¸€ä¸ªå¼‚å¸¸å€¼

    # æ¨¡å¼å¼‚å¸¸ï¼šå¹³å°
    test_glucose[40:50] = 150  # å¹³å°å¼‚å¸¸

    # é¢‘åŸŸå¼‚å¸¸ï¼šé«˜é¢‘å™ªå£°
    noise_indices = range(60, 80)
    high_freq_noise = 20 * np.sin(np.arange(len(noise_indices)) * 0.5)
    test_glucose[60:80] += high_freq_noise

    # ç”Ÿç†å¼‚å¸¸ï¼šä¸åˆç†å˜åŒ–
    test_glucose[85] = test_glucose[84] + 100  # ç¬é—´è·³è·ƒ

    print(f"ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼š{len(test_glucose)} ä¸ªæ•°æ®ç‚¹")
    print(f"ğŸ¯ é¢„æ¤å…¥å¼‚å¸¸ï¼šç»Ÿè®¡å¼‚å¸¸ã€å¹³å°å¼‚å¸¸ã€é¢‘åŸŸå™ªå£°ã€ç”Ÿç†å¼‚å¸¸")

    # æ‰§è¡Œç»¼åˆæ£€æµ‹
    result = detector.comprehensive_detection(test_glucose)

    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“ˆ ç»¼åˆæ£€æµ‹ç»“æœ:")
    print(f"æ€»å¼‚å¸¸ç‚¹æ•°: {result['summary']['total_anomalies']}")
    print(f"é«˜ç½®ä¿¡åº¦å¼‚å¸¸: {result['summary']['high_confidence_count']} ä¸ª")
    print(f"ä¸­ç½®ä¿¡åº¦å¼‚å¸¸: {result['summary']['medium_confidence_count']} ä¸ª")
    print(f"ä½ç½®ä¿¡åº¦å¼‚å¸¸: {result['summary']['low_confidence_count']} ä¸ª")

    print(f"\nğŸ¯ å„æ–¹æ³•æ£€æµ‹ç»Ÿè®¡:")
    for method, method_result in result['method_results'].items():
        anomaly_count = len(method_result['anomalies'])
        print(f"  {method_result['method']}: {anomaly_count} ä¸ªå¼‚å¸¸")

    print(f"\nğŸ” é«˜ç½®ä¿¡åº¦å¼‚å¸¸ç‚¹è¯¦æƒ…:")
    for i, idx in enumerate(result['high_confidence_anomalies'][:10]):
        if idx < len(test_glucose):
            votes = result['voting_results'][idx]
            value = test_glucose[idx]
            print(f"  {i+1}. ä½ç½®{idx}: è¡€ç³–={value:.1f} mg/dL, æŠ•ç¥¨æ•°={votes}")

    print(f"\nâœ¨ ç³»ç»ŸæˆåŠŸæ•´åˆäº† {result['total_methods']} ç§æ£€æµ‹æ–¹æ³•ï¼")
    return result

if __name__ == "__main__":
    demonstrate_comprehensive_detection()