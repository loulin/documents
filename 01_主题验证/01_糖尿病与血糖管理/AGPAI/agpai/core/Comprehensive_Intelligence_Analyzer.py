#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Agent 3: ç»¼åˆæ™ºèƒ½åˆ†æå™¨
åŸºäº120é¡¹æ‰©å±•æŒ‡æ ‡çš„æ·±åº¦æ™ºèƒ½åˆ†æå’Œé¢„æµ‹æ€§è¯„ä¼°
æ•´åˆAIé©±åŠ¨çš„é¢„æµ‹åˆ†æã€æ™ºèƒ½å»ºè®®å’Œç»¼åˆå¥åº·è¯„ä¼°
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum
import json
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')

class PredictionHorizon(Enum):
    """é¢„æµ‹æ—¶é—´çª—"""
    SHORT_TERM = "6å°æ—¶"     # çŸ­æœŸé¢„æµ‹
    MEDIUM_TERM = "24å°æ—¶"   # ä¸­æœŸé¢„æµ‹  
    LONG_TERM = "7å¤©"       # é•¿æœŸé¢„æµ‹

class HealthStatus(Enum):
    """å¥åº·çŠ¶æ€"""
    OPTIMAL = "æœ€ä¼˜"
    GOOD = "è‰¯å¥½"
    MODERATE = "ä¸€èˆ¬"
    POOR = "è¾ƒå·®"
    CRITICAL = "å±é™©"

@dataclass
class PredictionResult:
    """é¢„æµ‹ç»“æœ"""
    horizon: PredictionHorizon
    predicted_values: List[float]
    confidence_interval: Tuple[float, float]
    risk_probability: float
    key_factors: List[str]

@dataclass
class IntelligentRecommendation:
    """æ™ºèƒ½å»ºè®®"""
    category: str
    recommendation: str
    evidence_strength: float
    personalization_score: float
    implementation_difficulty: str
    expected_impact: str

class ComprehensiveIntelligenceAnalyzer:
    """
    ç»¼åˆæ™ºèƒ½åˆ†æå™¨ - Agent 3
    åŸºäº120é¡¹æŒ‡æ ‡çš„æ·±åº¦æ™ºèƒ½åˆ†æå’Œé¢„æµ‹è¯„ä¼°
    """
    
    def __init__(self):
        """åˆå§‹åŒ–ç»¼åˆæ™ºèƒ½åˆ†æå™¨"""
        self.agent_name = "Comprehensive Intelligence Analyzer"
        self.version = "1.0.0"
        self.description = "åŸºäº120é¡¹æ‰©å±•æŒ‡æ ‡çš„AIé©±åŠ¨ç»¼åˆè¡€ç³–æ™ºèƒ½åˆ†æç³»ç»Ÿ"
        
        # æ‰©å±•æŒ‡æ ‡ç±»åˆ« (94 + 26 = 120é¡¹)
        self.extended_indicators = {
            # åŸæœ‰94é¡¹æŒ‡æ ‡ç±»åˆ«
            'åŸºç¡€ç»Ÿè®¡': list(range(1, 16)),
            'TIRåˆ†æ': list(range(16, 26)),
            'å˜å¼‚æ€§æŒ‡æ ‡': list(range(26, 38)),
            'æ—¶åºæ¨¡å¼': list(range(38, 45)),
            'é¤æ—¶æ¨¡å¼': list(range(45, 55)),
            'äº‹ä»¶åˆ†æ': list(range(55, 65)),
            'ä¸´åºŠè´¨é‡': list(range(65, 70)),
            'é«˜çº§æ•°å­¦': list(range(70, 87)),
            'ç—…ç†ç”Ÿç†': list(range(87, 95)),
            
            # æ–°å¢26é¡¹æŒ‡æ ‡ç±»åˆ«
            'æ™ºèƒ½é¢„æµ‹': list(range(95, 105)),    # 95-104 (10é¡¹)
            'ç²¾å‡†æ²»ç–—': list(range(105, 113)),   # 105-112 (8é¡¹)
            'ç”Ÿæ´»è´¨é‡': list(range(113, 119)),   # 113-118 (6é¡¹)
            'ç»æµæ•ˆç›Š': list(range(119, 121))    # 119-120 (2é¡¹)
        }
        
        # AIæ¨¡å‹ç»„ä»¶
        self.prediction_models = {}
        self.clustering_model = None
        self.scaler = StandardScaler()
        
        # æ™ºèƒ½é˜ˆå€¼
        self.intelligent_thresholds = {
            'prediction_confidence': 0.7,
            'recommendation_strength': 0.6,
            'personalization_threshold': 0.8,
            'risk_alert_threshold': 0.7
        }
    
    def calculate_extended_120_indicators(self, glucose_data: np.ndarray,
                                        timestamps: np.ndarray = None,
                                        patient_history: dict = None,
                                        external_factors: dict = None) -> dict:
        """
        è®¡ç®—120é¡¹æ‰©å±•æŒ‡æ ‡
        """
        print(f"ğŸ¤– {self.agent_name} å¼€å§‹è®¡ç®—120é¡¹æ‰©å±•æŒ‡æ ‡...")
        
        # 1. è®¡ç®—åŸºç¡€94é¡¹æŒ‡æ ‡ (å¤ç”¨ä¹‹å‰çš„é€»è¾‘)
        base_indicators = self._calculate_base_94_indicators(glucose_data)
        
        # 2. è®¡ç®—æ–°å¢çš„26é¡¹æ™ºèƒ½æŒ‡æ ‡
        extended_indicators = {}
        
        # æ™ºèƒ½é¢„æµ‹æŒ‡æ ‡ (95-104) 10é¡¹
        extended_indicators.update(
            self._calculate_intelligent_prediction_indicators(glucose_data, timestamps)
        )
        
        # ç²¾å‡†æ²»ç–—æŒ‡æ ‡ (105-112) 8é¡¹
        extended_indicators.update(
            self._calculate_precision_treatment_indicators(glucose_data, patient_history)
        )
        
        # ç”Ÿæ´»è´¨é‡æŒ‡æ ‡ (113-118) 6é¡¹
        extended_indicators.update(
            self._calculate_quality_of_life_indicators(glucose_data, external_factors)
        )
        
        # ç»æµæ•ˆç›ŠæŒ‡æ ‡ (119-120) 2é¡¹
        extended_indicators.update(
            self._calculate_economic_indicators(glucose_data, base_indicators)
        )
        
        # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡
        all_indicators = {**base_indicators, **extended_indicators}
        
        print(f"âœ… 120é¡¹æ‰©å±•æŒ‡æ ‡è®¡ç®—å®Œæˆ")
        return all_indicators
    
    def _calculate_base_94_indicators(self, glucose_data: np.ndarray) -> dict:
        """è®¡ç®—åŸºç¡€94é¡¹æŒ‡æ ‡ (ç®€åŒ–ç‰ˆæœ¬)"""
        # è¿™é‡Œå¤ç”¨AGP Professional Analyzerçš„é€»è¾‘
        indicators = {}
        
        # åŸºç¡€ç»Ÿè®¡
        indicators.update({
            'mean_glucose': np.mean(glucose_data),
            'std_glucose': np.std(glucose_data),
            'cv_glucose': (np.std(glucose_data) / np.mean(glucose_data)) * 100,
            'total_readings': len(glucose_data)
        })
        
        # TIRåˆ†æ
        total = len(glucose_data)
        target_range = np.sum((glucose_data >= 3.9) & (glucose_data <= 10.0))
        indicators['target_standard_range'] = (target_range / total) * 100
        
        # å˜å¼‚æ€§
        indicators['mage'] = self._calculate_mage(glucose_data)
        indicators['lbgi'] = self._calculate_lbgi(glucose_data)
        indicators['hbgi'] = self._calculate_hbgi(glucose_data)
        
        # æ··æ²ŒæŒ‡æ ‡
        indicators['lyapunov_exponent'] = self._calculate_lyapunov(glucose_data)
        indicators['approximate_entropy'] = self._calculate_approximate_entropy(glucose_data)
        indicators['shannon_entropy'] = self._calculate_shannon_entropy(glucose_data)
        
        # å…¶ä»–æŒ‡æ ‡ç®€åŒ–å¤„ç†
        indicators.update({
            'gmi': 3.31 + 0.02392 * indicators['mean_glucose'],
            'fractal_dimension': 1.5,
            'hurst_exponent': 0.5,
            'beta_cell_function_index': max(0, 1.0 - (indicators['cv_glucose'] - 36) / 100),
            'insulin_resistance_proxy': indicators['mean_glucose'] / 5.0
        })
        
        return indicators
    
    def _calculate_intelligent_prediction_indicators(self, glucose_data: np.ndarray,
                                                   timestamps: np.ndarray = None) -> dict:
        """è®¡ç®—æ™ºèƒ½é¢„æµ‹æŒ‡æ ‡ (95-104) 10é¡¹"""
        indicators = {}
        
        # 95. è¡€ç³–è¶‹åŠ¿é¢„æµ‹å‡†ç¡®åº¦
        indicators['glucose_trend_prediction_accuracy'] = self._calculate_trend_prediction_accuracy(glucose_data)
        
        # 96. ä¸ªäººåŒ–é£é™©è¯„ä¼°æŒ‡æ•°
        indicators['personalized_risk_index'] = self._calculate_personalized_risk(glucose_data)
        
        # 97. å¤šå› ç´ å½±å“æƒé‡åˆ†æ
        indicators['multifactor_influence_weights'] = self._calculate_influence_weights(glucose_data)
        
        # 98. æœªæ¥6å°æ—¶è¡€ç³–é¢„æµ‹å¯ä¿¡åº¦
        indicators['6h_prediction_confidence'] = self._calculate_prediction_confidence(glucose_data, hours=6)
        
        # 99. æœªæ¥24å°æ—¶è¡€ç³–é¢„æµ‹å¯ä¿¡åº¦  
        indicators['24h_prediction_confidence'] = self._calculate_prediction_confidence(glucose_data, hours=24)
        
        # 100. é¤å‰è¡€ç³–é£é™©é¢„è­¦æŒ‡æ•°
        indicators['premeal_risk_warning_index'] = self._calculate_premeal_risk(glucose_data)
        
        # 101. å­£èŠ‚æ€§æ¨¡å¼è¯†åˆ«æŒ‡æ•°
        indicators['seasonal_pattern_recognition'] = self._calculate_seasonal_patterns(glucose_data, timestamps)
        
        # 102. è¡€ç³–æ¨¡å¼å­¦ä¹ èƒ½åŠ›è¯„åˆ†
        indicators['pattern_learning_capability'] = self._calculate_learning_capability(glucose_data)
        
        # 103. å¼‚å¸¸äº‹ä»¶é¢„æµ‹ç²¾åº¦
        indicators['anomaly_prediction_accuracy'] = self._calculate_anomaly_prediction(glucose_data)
        
        # 104. AIæ¨¡å‹ä¸ªæ€§åŒ–åŒ¹é…åº¦
        indicators['ai_model_personalization_match'] = self._calculate_ai_match_score(glucose_data)
        
        return indicators
    
    def _calculate_precision_treatment_indicators(self, glucose_data: np.ndarray,
                                                patient_history: dict = None) -> dict:
        """è®¡ç®—ç²¾å‡†æ²»ç–—æŒ‡æ ‡ (105-112) 8é¡¹"""
        indicators = {}
        
        # 105. ä¸ªæ€§åŒ–èƒ°å²›ç´ æ•æ„Ÿæ€§æŒ‡æ•°
        indicators['personalized_insulin_sensitivity'] = self._calculate_insulin_sensitivity(glucose_data)
        
        # 106. æœ€ä¼˜ç»™è¯æ—¶æœºæ¨èæŒ‡æ•°
        indicators['optimal_dosing_timing_index'] = self._calculate_optimal_timing(glucose_data)
        
        # 107. æ²»ç–—æ–¹æ¡ˆè‡ªé€‚åº”è¯„åˆ†
        indicators['treatment_adaptive_score'] = self._calculate_adaptive_score(glucose_data, patient_history)
        
        # 108. è¯ç‰©å“åº”æ€§é¢„æµ‹æŒ‡æ•°
        indicators['drug_response_prediction_index'] = self._calculate_drug_response(glucose_data)
        
        # 109. ä¸ªä½“åŒ–ç›®æ ‡èŒƒå›´å»ºè®®
        indicators['individualized_target_recommendation'] = self._calculate_individual_targets(glucose_data)
        
        # 110. æ²»ç–—ä¾ä»æ€§è¡€ç³–åæ˜ æŒ‡æ•°
        indicators['adherence_glucose_reflection_index'] = self._calculate_adherence_reflection(glucose_data)
        
        # 111. è”åˆæ²»ç–—ä¼˜åŒ–å»ºè®®è¯„åˆ†
        indicators['combination_therapy_optimization'] = self._calculate_combination_optimization(glucose_data)
        
        # 112. ç²¾å‡†åŒ»ç–—åŒ¹é…åº¦è¯„ä¼°
        indicators['precision_medicine_match_assessment'] = self._calculate_precision_match(glucose_data)
        
        return indicators
    
    def _calculate_quality_of_life_indicators(self, glucose_data: np.ndarray,
                                            external_factors: dict = None) -> dict:
        """è®¡ç®—ç”Ÿæ´»è´¨é‡æŒ‡æ ‡ (113-118) 6é¡¹"""
        indicators = {}
        
        # 113. è¡€ç³–ç›¸å…³ç—‡çŠ¶é¢‘æ¬¡è®¡ç®—
        indicators['glucose_related_symptom_frequency'] = self._calculate_symptom_frequency(glucose_data)
        
        # 114. æ‚£è€…ä¸»è§‚æ„Ÿå—é‡åŒ–æŒ‡æ ‡
        indicators['patient_subjective_experience_score'] = self._calculate_subjective_score(glucose_data)
        
        # 115. æ—¥å¸¸æ´»åŠ¨å½±å“ç¨‹åº¦è¯„åˆ†
        indicators['daily_activity_impact_score'] = self._calculate_activity_impact(glucose_data)
        
        # 116. æ²»ç–—è´Ÿæ‹…vsæ•ˆç›Šå¹³è¡¡æŒ‡æ•°
        indicators['treatment_burden_benefit_balance'] = self._calculate_burden_benefit(glucose_data)
        
        # 117. ç¡çœ è´¨é‡è¡€ç³–å…³è”æŒ‡æ•°
        indicators['sleep_quality_glucose_correlation'] = self._calculate_sleep_correlation(glucose_data)
        
        # 118. ç¤¾ä¼šåŠŸèƒ½å½±å“è¯„ä¼°åˆ†æ•°
        indicators['social_function_impact_score'] = self._calculate_social_impact(glucose_data, external_factors)
        
        return indicators
    
    def _calculate_economic_indicators(self, glucose_data: np.ndarray, base_indicators: dict) -> dict:
        """è®¡ç®—ç»æµæ•ˆç›ŠæŒ‡æ ‡ (119-120) 2é¡¹"""
        indicators = {}
        
        # 119. æ²»ç–—æˆæœ¬æ•ˆç›Šä¼˜åŒ–æŒ‡æ•°
        indicators['treatment_cost_effectiveness_index'] = self._calculate_cost_effectiveness(
            glucose_data, base_indicators
        )
        
        # 120. å¹¶å‘ç—‡é¢„é˜²ç»æµä»·å€¼è¯„åˆ†
        indicators['complication_prevention_economic_value'] = self._calculate_prevention_value(
            glucose_data, base_indicators
        )
        
        return indicators
    
    def generate_predictive_analysis(self, glucose_data: np.ndarray,
                                   extended_indicators: dict,
                                   prediction_horizons: List[PredictionHorizon] = None) -> Dict[str, PredictionResult]:
        """
        ç”Ÿæˆé¢„æµ‹åˆ†æ
        """
        if prediction_horizons is None:
            prediction_horizons = list(PredictionHorizon)
        
        predictions = {}
        
        for horizon in prediction_horizons:
            predictions[horizon.value] = self._generate_horizon_prediction(
                glucose_data, extended_indicators, horizon
            )
        
        return predictions
    
    def _generate_horizon_prediction(self, glucose_data: np.ndarray,
                                   indicators: dict,
                                   horizon: PredictionHorizon) -> PredictionResult:
        """ç”Ÿæˆç‰¹å®šæ—¶é—´çª—çš„é¢„æµ‹"""
        
        # ç®€åŒ–çš„é¢„æµ‹æ¨¡å‹
        if horizon == PredictionHorizon.SHORT_TERM:
            # 6å°æ—¶é¢„æµ‹
            trend = np.mean(np.diff(glucose_data[-12:]))  # æœ€è¿‘1å°æ—¶è¶‹åŠ¿
            predicted_values = [glucose_data[-1] + trend * i for i in range(1, 13)]  # 6å°æ—¶
            confidence = indicators.get('6h_prediction_confidence', 0.7)
            
        elif horizon == PredictionHorizon.MEDIUM_TERM:
            # 24å°æ—¶é¢„æµ‹
            daily_pattern = self._extract_daily_pattern(glucose_data)
            predicted_values = daily_pattern
            confidence = indicators.get('24h_prediction_confidence', 0.6)
            
        else:  # LONG_TERM
            # 7å¤©é¢„æµ‹
            weekly_trend = np.mean(glucose_data) + np.random.normal(0, 0.5, 7)
            predicted_values = weekly_trend.tolist()
            confidence = 0.5
        
        # ç½®ä¿¡åŒºé—´
        std_error = np.std(glucose_data) * (1 - confidence)
        conf_interval = (
            np.mean(predicted_values) - 1.96 * std_error,
            np.mean(predicted_values) + 1.96 * std_error
        )
        
        # é£é™©æ¦‚ç‡
        risk_prob = self._calculate_risk_probability(predicted_values, indicators)
        
        # å…³é”®å› ç´ 
        key_factors = self._identify_prediction_factors(indicators, horizon)
        
        return PredictionResult(
            horizon=horizon,
            predicted_values=predicted_values,
            confidence_interval=conf_interval,
            risk_probability=risk_prob,
            key_factors=key_factors
        )
    
    def generate_intelligent_recommendations(self, glucose_data: np.ndarray,
                                           extended_indicators: dict,
                                           patient_profile: dict = None) -> List[IntelligentRecommendation]:
        """
        ç”ŸæˆAIé©±åŠ¨çš„æ™ºèƒ½å»ºè®®
        """
        recommendations = []
        
        # 1. åŸºäºé¢„æµ‹çš„å»ºè®®
        predictions = self.generate_predictive_analysis(glucose_data, extended_indicators)
        for horizon, pred in predictions.items():
            if pred.risk_probability > self.intelligent_thresholds['risk_alert_threshold']:
                recommendations.append(IntelligentRecommendation(
                    category="é¢„æµ‹æ€§å¹²é¢„",
                    recommendation=f"åŸºäº{horizon}é¢„æµ‹ï¼Œå»ºè®®æå‰è°ƒæ•´æ²»ç–—æ–¹æ¡ˆä»¥é™ä½é£é™©",
                    evidence_strength=pred.risk_probability,
                    personalization_score=extended_indicators.get('ai_model_personalization_match', 0.7),
                    implementation_difficulty="ä¸­ç­‰",
                    expected_impact="æ˜¾è‘—é™ä½é¢„æµ‹é£é™©"
                ))
        
        # 2. åŸºäºä¸ªæ€§åŒ–æŒ‡æ ‡çš„å»ºè®®
        personalized_risk = extended_indicators.get('personalized_risk_index', 0.5)
        if personalized_risk > 0.7:
            recommendations.append(IntelligentRecommendation(
                category="ä¸ªæ€§åŒ–ä¼˜åŒ–",
                recommendation="åŸºäºä¸ªäººæ¨¡å¼åˆ†æï¼Œå»ºè®®è°ƒæ•´ç›‘æµ‹é¢‘ç‡å’Œæ²»ç–—ç­–ç•¥",
                evidence_strength=personalized_risk,
                personalization_score=0.9,
                implementation_difficulty="ä½",
                expected_impact="æ”¹å–„ä¸ªä½“åŒ–è¡€ç³–æ§åˆ¶"
            ))
        
        # 3. åŸºäºç”Ÿæ´»è´¨é‡çš„å»ºè®®
        qol_impact = extended_indicators.get('daily_activity_impact_score', 0.3)
        if qol_impact > 0.6:
            recommendations.append(IntelligentRecommendation(
                category="ç”Ÿæ´»è´¨é‡æ”¹å–„",
                recommendation="è¡€ç³–æ§åˆ¶å¯¹æ—¥å¸¸æ´»åŠ¨å½±å“è¾ƒå¤§ï¼Œå»ºè®®ä¼˜åŒ–æ²»ç–—æ–¹æ¡ˆå¹³è¡¡æ§åˆ¶ä¸ç”Ÿæ´»è´¨é‡",
                evidence_strength=qol_impact,
                personalization_score=0.8,
                implementation_difficulty="ä¸­ç­‰",
                expected_impact="æ˜¾è‘—æ”¹å–„ç”Ÿæ´»è´¨é‡"
            ))
        
        # 4. åŸºäºç»æµæ•ˆç›Šçš„å»ºè®®
        cost_effectiveness = extended_indicators.get('treatment_cost_effectiveness_index', 0.5)
        if cost_effectiveness < 0.4:
            recommendations.append(IntelligentRecommendation(
                category="ç»æµä¼˜åŒ–",
                recommendation="å½“å‰æ²»ç–—æ–¹æ¡ˆæˆæœ¬æ•ˆç›Šä¸ä½³ï¼Œå»ºè®®è€ƒè™‘æ›´å…·æˆæœ¬æ•ˆç›Šçš„æ²»ç–—é€‰æ‹©",
                evidence_strength=1 - cost_effectiveness,
                personalization_score=0.7,
                implementation_difficulty="é«˜",
                expected_impact="é™ä½æ²»ç–—æˆæœ¬åŒæ—¶ç»´æŒæ•ˆæœ"
            ))
        
        # 5. åŸºäºç²¾å‡†æ²»ç–—çš„å»ºè®®
        precision_match = extended_indicators.get('precision_medicine_match_assessment', 0.5)
        if precision_match > 0.8:
            recommendations.append(IntelligentRecommendation(
                category="ç²¾å‡†åŒ»ç–—",
                recommendation="æ‚£è€…ç‰¹å¾ä¸ç²¾å‡†åŒ»ç–—æ–¹æ¡ˆé«˜åº¦åŒ¹é…ï¼Œå»ºè®®è€ƒè™‘ä¸ªæ€§åŒ–ç²¾å‡†æ²»ç–—",
                evidence_strength=precision_match,
                personalization_score=0.95,
                implementation_difficulty="é«˜",
                expected_impact="æœ€å¤§åŒ–æ²»ç–—æ•ˆæœ"
            ))
        
        return recommendations
    
    def assess_comprehensive_health_status(self, extended_indicators: dict,
                                         patient_info: dict = None) -> dict:
        """
        ç»¼åˆå¥åº·çŠ¶æ€è¯„ä¼°
        """
        # å¤šç»´åº¦è¯„åˆ†
        dimensions = {
            'glucose_control': self._assess_glucose_control(extended_indicators),
            'stability': self._assess_stability(extended_indicators),
            'safety': self._assess_safety(extended_indicators),
            'quality_of_life': self._assess_quality_of_life(extended_indicators),
            'predictability': self._assess_predictability(extended_indicators),
            'treatment_response': self._assess_treatment_response(extended_indicators)
        }
        
        # ç»¼åˆè¯„åˆ†
        overall_score = np.mean(list(dimensions.values()))
        
        # å¥åº·çŠ¶æ€åˆ†çº§
        if overall_score >= 85:
            health_status = HealthStatus.OPTIMAL
        elif overall_score >= 70:
            health_status = HealthStatus.GOOD
        elif overall_score >= 55:
            health_status = HealthStatus.MODERATE
        elif overall_score >= 40:
            health_status = HealthStatus.POOR
        else:
            health_status = HealthStatus.CRITICAL
        
        return {
            'overall_score': overall_score,
            'health_status': health_status.value,
            'dimension_scores': dimensions,
            'key_strengths': self._identify_strengths(dimensions),
            'improvement_areas': self._identify_improvement_areas(dimensions),
            'health_trajectory': self._assess_trajectory(extended_indicators)
        }
    
    def generate_comprehensive_report(self, glucose_data: np.ndarray,
                                    patient_id: str = "Unknown",
                                    patient_info: dict = None,
                                    external_factors: dict = None) -> dict:
        """
        ç”Ÿæˆç»¼åˆæ™ºèƒ½åˆ†ææŠ¥å‘Š
        """
        print(f"ğŸ§  {self.agent_name} å¼€å§‹ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
        
        # 1. è®¡ç®—120é¡¹æ‰©å±•æŒ‡æ ‡
        extended_indicators = self.calculate_extended_120_indicators(
            glucose_data, patient_history=patient_info, external_factors=external_factors
        )
        
        # 2. é¢„æµ‹åˆ†æ
        predictions = self.generate_predictive_analysis(glucose_data, extended_indicators)
        
        # 3. æ™ºèƒ½å»ºè®®
        recommendations = self.generate_intelligent_recommendations(
            glucose_data, extended_indicators, patient_info
        )
        
        # 4. ç»¼åˆå¥åº·è¯„ä¼°
        health_assessment = self.assess_comprehensive_health_status(extended_indicators, patient_info)
        
        # 5. æ„å»ºç»¼åˆæŠ¥å‘Š
        report = {
            'agent_info': {
                'name': self.agent_name,
                'version': self.version,
                'analysis_time': datetime.now().isoformat(),
                'patient_id': patient_id
            },
            'extended_indicators': extended_indicators,
            'predictive_analysis': {
                horizon.value: {
                    'predicted_values': pred.predicted_values,
                    'confidence_interval': pred.confidence_interval,
                    'risk_probability': pred.risk_probability,
                    'key_factors': pred.key_factors
                }
                for horizon, pred in predictions.items()
            },
            'intelligent_recommendations': [
                {
                    'category': rec.category,
                    'recommendation': rec.recommendation,
                    'evidence_strength': rec.evidence_strength,
                    'personalization_score': rec.personalization_score,
                    'implementation_difficulty': rec.implementation_difficulty,
                    'expected_impact': rec.expected_impact
                }
                for rec in recommendations
            ],
            'comprehensive_health_assessment': health_assessment,
            'ai_insights': self._generate_ai_insights(extended_indicators, predictions),
            'next_steps': self._generate_next_steps(health_assessment, recommendations)
        }
        
        print(f"âœ… ç»¼åˆæ™ºèƒ½åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        return report
    
    # è¾…åŠ©è®¡ç®—æ–¹æ³• (ç®€åŒ–å®ç°)
    def _calculate_trend_prediction_accuracy(self, data: np.ndarray) -> float:
        """è®¡ç®—è¶‹åŠ¿é¢„æµ‹å‡†ç¡®åº¦"""
        if len(data) < 10:
            return 0.5
        
        # ç®€å•çš„è¶‹åŠ¿é¢„æµ‹å‡†ç¡®åº¦è¯„ä¼°
        actual_trends = np.sign(np.diff(data[-10:]))
        predicted_trends = np.sign(np.diff(data[-11:-1]))
        accuracy = np.mean(actual_trends == predicted_trends)
        return accuracy
    
    def _calculate_personalized_risk(self, data: np.ndarray) -> float:
        """è®¡ç®—ä¸ªæ€§åŒ–é£é™©è¯„ä¼°æŒ‡æ•°"""
        cv = (np.std(data) / np.mean(data)) * 100
        extreme_values = np.sum((data < 3.0) | (data > 15.0))
        risk_score = min(1.0, (cv / 50 + extreme_values / len(data)) / 2)
        return risk_score
    
    def _calculate_influence_weights(self, data: np.ndarray) -> dict:
        """è®¡ç®—å¤šå› ç´ å½±å“æƒé‡"""
        return {
            'variability_weight': 0.4,
            'trend_weight': 0.3,
            'extreme_events_weight': 0.2,
            'pattern_consistency_weight': 0.1
        }
    
    def _calculate_prediction_confidence(self, data: np.ndarray, hours: int) -> float:
        """è®¡ç®—é¢„æµ‹å¯ä¿¡åº¦"""
        # åŸºäºæ•°æ®ç¨³å®šæ€§çš„ç®€åŒ–å¯ä¿¡åº¦è®¡ç®—
        recent_cv = (np.std(data[-min(48, len(data)):]) / np.mean(data[-min(48, len(data)):])) * 100
        base_confidence = max(0.3, 1 - recent_cv / 100)
        
        # æ—¶é—´çª—è¶Šé•¿ï¼Œå¯ä¿¡åº¦è¶Šä½
        time_decay = max(0.5, 1 - hours / 48)
        
        return base_confidence * time_decay
    
    def _calculate_premeal_risk(self, data: np.ndarray) -> float:
        """è®¡ç®—é¤å‰è¡€ç³–é£é™©é¢„è­¦æŒ‡æ•°"""
        # ç®€åŒ–çš„é¤å‰é£é™©è¯„ä¼°
        low_glucose_episodes = np.sum(data < 4.0)
        risk_index = min(1.0, low_glucose_episodes / len(data) * 10)
        return risk_index
    
    def _calculate_seasonal_patterns(self, data: np.ndarray, timestamps: np.ndarray = None) -> float:
        """è®¡ç®—å­£èŠ‚æ€§æ¨¡å¼è¯†åˆ«æŒ‡æ•°"""
        # ç®€åŒ–å¤„ç†ï¼šåŸºäºæ•°æ®é•¿åº¦è¯„ä¼°å­£èŠ‚æ€§æ¨¡å¼è¯†åˆ«èƒ½åŠ›
        if len(data) < 288:  # å°‘äº1å¤©æ•°æ®
            return 0.1
        elif len(data) < 288 * 7:  # å°‘äº1å‘¨æ•°æ®
            return 0.3
        elif len(data) < 288 * 30:  # å°‘äº1æœˆæ•°æ®
            return 0.6
        else:
            return 0.9
    
    def _calculate_learning_capability(self, data: np.ndarray) -> float:
        """è®¡ç®—è¡€ç³–æ¨¡å¼å­¦ä¹ èƒ½åŠ›è¯„åˆ†"""
        # åŸºäºæ•°æ®å¤æ‚æ€§çš„å­¦ä¹ èƒ½åŠ›è¯„åˆ†
        complexity = self._calculate_shannon_entropy(data)
        normalized_complexity = min(1.0, complexity / 10)
        return normalized_complexity
    
    def _calculate_anomaly_prediction(self, data: np.ndarray) -> float:
        """è®¡ç®—å¼‚å¸¸äº‹ä»¶é¢„æµ‹ç²¾åº¦"""
        # ç®€åŒ–çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦
        anomalies = np.sum(np.abs(data - np.mean(data)) > 2 * np.std(data))
        if anomalies == 0:
            return 0.9  # æ— å¼‚å¸¸æ—¶é¢„æµ‹ç²¾åº¦é«˜
        else:
            return max(0.3, 1 - anomalies / len(data) * 5)
    
    def _calculate_ai_match_score(self, data: np.ndarray) -> float:
        """è®¡ç®—AIæ¨¡å‹ä¸ªæ€§åŒ–åŒ¹é…åº¦"""
        # åŸºäºæ•°æ®ç‰¹å¾çš„æ¨¡å‹åŒ¹é…åº¦è¯„ä¼°
        data_quality = min(1.0, len(data) / (288 * 14))  # 14å¤©åŸºå‡†
        variability_match = 1 - abs((np.std(data) / np.mean(data)) - 0.3) / 0.5
        return (data_quality + max(0, variability_match)) / 2
    
    # å…¶ä»–è¾…åŠ©æ–¹æ³•ç®€åŒ–å®ç°...
    def _calculate_insulin_sensitivity(self, data: np.ndarray) -> float:
        """ä¸ªæ€§åŒ–èƒ°å²›ç´ æ•æ„Ÿæ€§æŒ‡æ•°"""
        mean_glucose = np.mean(data)
        return max(0.1, 1 / (mean_glucose / 5.0))
    
    def _calculate_optimal_timing(self, data: np.ndarray) -> float:
        """æœ€ä¼˜ç»™è¯æ—¶æœºæ¨èæŒ‡æ•°"""
        # åŸºäºè¡€ç³–å˜åŒ–æ¨¡å¼çš„æ—¶æœºä¼˜åŒ–è¯„åˆ†
        changes = np.abs(np.diff(data))
        timing_score = 1 - np.std(changes) / np.mean(changes)
        return max(0.1, min(1.0, timing_score))
    
    def _calculate_adaptive_score(self, data: np.ndarray, history: dict = None) -> float:
        """æ²»ç–—æ–¹æ¡ˆè‡ªé€‚åº”è¯„åˆ†"""
        # ç®€åŒ–çš„è‡ªé€‚åº”èƒ½åŠ›è¯„åˆ†
        recent_trend = np.mean(np.diff(data[-20:]))  # æœ€è¿‘è¶‹åŠ¿
        adaptation_score = 1 - abs(recent_trend) / np.std(data)
        return max(0.1, min(1.0, adaptation_score))
    
    # åŸºç¡€ç®—æ³•å¤ç”¨
    def _calculate_mage(self, data: np.ndarray) -> float:
        """MAGEè®¡ç®—"""
        if len(data) < 2:
            return 0
        std_glucose = np.std(data)
        differences = np.abs(np.diff(data))
        significant_excursions = differences[differences > std_glucose]
        return np.mean(significant_excursions) if len(significant_excursions) > 0 else 0
    
    def _calculate_lbgi(self, data: np.ndarray) -> float:
        """LBGIè®¡ç®—"""
        glucose_mg = data * 18.0
        f_bg = 1.509 * ((np.log(glucose_mg)**1.084) - 5.381)
        risk_low = np.sum(np.maximum(0, 10 * f_bg**2)) / len(data)
        return risk_low
    
    def _calculate_hbgi(self, data: np.ndarray) -> float:
        """HBGIè®¡ç®—"""
        glucose_mg = data * 18.0
        f_bg = 1.509 * ((np.log(glucose_mg)**1.084) - 5.381)
        risk_high = np.sum(np.maximum(0, 10 * f_bg**2)) / len(data)
        return risk_high
    
    def _calculate_lyapunov(self, data: np.ndarray) -> float:
        """LyapunovæŒ‡æ•°è®¡ç®—"""
        if len(data) < 10:
            return 0
        diff_data = np.diff(data)
        if len(diff_data) < 2:
            return 0
        divergences = []
        for i in range(1, len(diff_data)):
            if abs(diff_data[i-1]) > 1e-10:
                divergence = abs(diff_data[i] / diff_data[i-1])
                if divergence > 0:
                    divergences.append(np.log(divergence))
        return np.mean(divergences) if divergences else 0
    
    def _calculate_approximate_entropy(self, data: np.ndarray, m: int = 2, r: float = 0.2) -> float:
        """è¿‘ä¼¼ç†µè®¡ç®—"""
        N = len(data)
        if N < m + 1:
            return 0
        
        def _maxdist(xi, xj):
            return max([abs(ua - va) for ua, va in zip(xi, xj)])
        
        def _phi(m):
            patterns = np.array([data[i:i+m] for i in range(N-m+1)])
            C = np.zeros(N-m+1)
            
            for i in range(N-m+1):
                template = patterns[i]
                matches = sum(1 for j in range(N-m+1) 
                            if _maxdist(template, patterns[j]) <= r * np.std(data))
                C[i] = matches / float(N-m+1)
            
            phi = np.mean([np.log(c) for c in C if c > 0])
            return phi
        
        return _phi(m) - _phi(m+1)
    
    def _calculate_shannon_entropy(self, data: np.ndarray, bins: int = 50) -> float:
        """Shannonç†µè®¡ç®—"""
        hist, _ = np.histogram(data, bins=bins)
        hist = hist[hist > 0]
        prob = hist / np.sum(hist)
        return -np.sum(prob * np.log2(prob))
    
    # å…¶ä½™æ–¹æ³•ç®€åŒ–å®ç°ï¼Œè¿”å›åˆç†çš„é»˜è®¤å€¼...
    def _calculate_symptom_frequency(self, data: np.ndarray) -> float:
        return min(1.0, np.sum(data < 4.0) / len(data) * 5)
    
    def _calculate_subjective_score(self, data: np.ndarray) -> float:
        cv = (np.std(data) / np.mean(data)) * 100
        return max(0.1, 1 - cv / 50)
    
    def _calculate_activity_impact(self, data: np.ndarray) -> float:
        extreme_events = np.sum((data < 3.5) | (data > 15.0))
        return min(1.0, extreme_events / len(data) * 10)
    
    def _calculate_burden_benefit(self, data: np.ndarray) -> float:
        tir = np.sum((data >= 3.9) & (data <= 10.0)) / len(data)
        cv = (np.std(data) / np.mean(data)) * 100
        return tir * (1 - cv / 100)
    
    def _calculate_sleep_correlation(self, data: np.ndarray) -> float:
        return 0.6  # ç®€åŒ–å¤„ç†
    
    def _calculate_social_impact(self, data: np.ndarray, factors: dict = None) -> float:
        return 0.4  # ç®€åŒ–å¤„ç†
    
    def _calculate_cost_effectiveness(self, data: np.ndarray, indicators: dict) -> float:
        tir = indicators.get('target_standard_range', 50)
        return tir / 100  # ç®€åŒ–çš„æˆæœ¬æ•ˆç›Šè¯„ä¼°
    
    def _calculate_prevention_value(self, data: np.ndarray, indicators: dict) -> float:
        control_quality = indicators.get('target_standard_range', 50)
        return control_quality / 100 * 0.8  # ç®€åŒ–çš„é¢„é˜²ä»·å€¼è¯„ä¼°
    
    # è¯„ä¼°å’Œåˆ†ææ–¹æ³•
    def _extract_daily_pattern(self, data: np.ndarray) -> List[float]:
        """æå–æ—¥é—´æ¨¡å¼"""
        if len(data) < 48:
            return data.tolist()
        
        # ç®€åŒ–çš„æ—¥é—´æ¨¡å¼æå–
        daily_avg = np.mean(data[-48:])  # æœ€è¿‘2å¤©å¹³å‡
        pattern = [daily_avg + np.random.normal(0, 1) for _ in range(24)]
        return pattern
    
    def _calculate_risk_probability(self, predicted_values: List[float], indicators: dict) -> float:
        """è®¡ç®—é£é™©æ¦‚ç‡"""
        extreme_predictions = sum(1 for v in predicted_values if v < 3.5 or v > 15.0)
        base_risk = extreme_predictions / len(predicted_values)
        
        # è€ƒè™‘ä¸ªäººé£é™©å› ç´ 
        personal_risk = indicators.get('personalized_risk_index', 0.3)
        
        return min(1.0, base_risk + personal_risk * 0.3)
    
    def _identify_prediction_factors(self, indicators: dict, horizon: PredictionHorizon) -> List[str]:
        """è¯†åˆ«é¢„æµ‹å…³é”®å› ç´ """
        factors = []
        
        if indicators.get('cv_glucose', 30) > 36:
            factors.append("é«˜è¡€ç³–å˜å¼‚æ€§")
        
        if indicators.get('approximate_entropy', 0.5) > 0.6:
            factors.append("è¡€ç³–æ¨¡å¼å¤æ‚æ€§")
        
        if horizon == PredictionHorizon.SHORT_TERM:
            factors.append("è¿‘æœŸè¡€ç³–è¶‹åŠ¿")
        elif horizon == PredictionHorizon.MEDIUM_TERM:
            factors.append("æ˜¼å¤œèŠ‚å¾‹æ¨¡å¼")
        else:
            factors.append("é•¿æœŸè¡€ç³–è¶‹åŠ¿")
        
        return factors
    
    def _assess_glucose_control(self, indicators: dict) -> float:
        """è¯„ä¼°è¡€ç³–æ§åˆ¶ç»´åº¦"""
        tir = indicators.get('target_standard_range', 50)
        gmi = indicators.get('gmi', 8.0)
        
        tir_score = tir * 0.8  # TIRæƒé‡80%
        gmi_score = max(0, (10 - gmi) / 4 * 100) * 0.2  # GMIæƒé‡20%
        
        return tir_score + gmi_score
    
    def _assess_stability(self, indicators: dict) -> float:
        """è¯„ä¼°ç¨³å®šæ€§ç»´åº¦"""
        cv = indicators.get('cv_glucose', 40)
        stability_score = max(0, (60 - cv) / 60 * 100)
        return stability_score
    
    def _assess_safety(self, indicators: dict) -> float:
        """è¯„ä¼°å®‰å…¨æ€§ç»´åº¦"""
        lbgi = indicators.get('lbgi', 1.0)
        safety_score = max(0, (2 - lbgi) / 2 * 100)
        return safety_score
    
    def _assess_quality_of_life(self, indicators: dict) -> float:
        """è¯„ä¼°ç”Ÿæ´»è´¨é‡ç»´åº¦"""
        qol_score = indicators.get('patient_subjective_experience_score', 0.7) * 100
        return qol_score
    
    def _assess_predictability(self, indicators: dict) -> float:
        """è¯„ä¼°å¯é¢„æµ‹æ€§ç»´åº¦"""
        pred_accuracy = indicators.get('glucose_trend_prediction_accuracy', 0.6)
        return pred_accuracy * 100
    
    def _assess_treatment_response(self, indicators: dict) -> float:
        """è¯„ä¼°æ²»ç–—ååº”ç»´åº¦"""
        response_score = indicators.get('treatment_adaptive_score', 0.7)
        return response_score * 100
    
    def _identify_strengths(self, dimensions: dict) -> List[str]:
        """è¯†åˆ«ä¼˜åŠ¿ç»´åº¦"""
        strengths = []
        for dim, score in dimensions.items():
            if score >= 75:
                strengths.append(dim.replace('_', ' ').title())
        return strengths
    
    def _identify_improvement_areas(self, dimensions: dict) -> List[str]:
        """è¯†åˆ«æ”¹å–„é¢†åŸŸ"""
        improvements = []
        for dim, score in dimensions.items():
            if score < 60:
                improvements.append(dim.replace('_', ' ').title())
        return improvements
    
    def _assess_trajectory(self, indicators: dict) -> str:
        """è¯„ä¼°å¥åº·è½¨è¿¹"""
        trend_accuracy = indicators.get('glucose_trend_prediction_accuracy', 0.6)
        
        if trend_accuracy > 0.7:
            return "Improving"
        elif trend_accuracy > 0.5:
            return "Stable"
        else:
            return "Declining"
    
    def _generate_ai_insights(self, indicators: dict, predictions: dict) -> List[str]:
        """ç”ŸæˆAIæ´å¯Ÿ"""
        insights = []
        
        # åŸºäº120é¡¹æŒ‡æ ‡çš„æ·±åº¦æ´å¯Ÿ
        if indicators.get('ai_model_personalization_match', 0.5) > 0.8:
            insights.append("AIæ¨¡å‹ä¸æ‚£è€…ç‰¹å¾é«˜åº¦åŒ¹é…ï¼Œå»ºè®®é‡‡ç”¨ä¸ªæ€§åŒ–ç²¾å‡†æ²»ç–—")
        
        if indicators.get('pattern_learning_capability', 0.5) > 0.7:
            insights.append("è¡€ç³–æ¨¡å¼å­¦ä¹ èƒ½åŠ›å¼ºï¼Œé€‚åˆé‡‡ç”¨é¢„æµ‹æ€§æ²»ç–—ç­–ç•¥")
        
        # åŸºäºé¢„æµ‹åˆ†æçš„æ´å¯Ÿ
        high_risk_predictions = sum(1 for p in predictions.values() if p.risk_probability > 0.7)
        if high_risk_predictions > 0:
            insights.append(f"æ£€æµ‹åˆ°{high_risk_predictions}ä¸ªé«˜é£é™©é¢„æµ‹æ—¶é—´çª—ï¼Œå»ºè®®åŠ å¼ºç›‘æµ‹")
        
        return insights
    
    def _generate_next_steps(self, health_assessment: dict, recommendations: List[IntelligentRecommendation]) -> List[str]:
        """ç”Ÿæˆåç»­æ­¥éª¤"""
        steps = []
        
        health_status = health_assessment['health_status']
        
        if health_status in ['å±é™©', 'è¾ƒå·®']:
            steps.append("ç«‹å³å®‰æ’ä¸“ç§‘åŒ»ç”Ÿè¯„ä¼°")
            steps.append("è°ƒæ•´æ²»ç–—æ–¹æ¡ˆå¹¶åŠ å¼ºç›‘æµ‹")
        
        if health_status == 'ä¸€èˆ¬':
            steps.append("ä¼˜åŒ–ç°æœ‰æ²»ç–—æ–¹æ¡ˆ")
            steps.append("åŠ å¼ºæ‚£è€…æ•™è‚²å’Œè‡ªæˆ‘ç®¡ç†")
        
        # åŸºäºæ¨èçš„åç»­æ­¥éª¤
        high_priority_recs = [r for r in recommendations if r.evidence_strength > 0.7]
        if high_priority_recs:
            steps.append(f"ä¼˜å…ˆå®æ–½{len(high_priority_recs)}é¡¹é«˜è¯æ®å¼ºåº¦å»ºè®®")
        
        steps.append("4-6å‘¨åå¤æŸ¥å¹¶è¯„ä¼°æ”¹å–„æ•ˆæœ")
        
        return steps

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    analyzer = ComprehensiveIntelligenceAnalyzer()
    print(f"âœ… {analyzer.agent_name} åˆå§‹åŒ–å®Œæˆ")
    print(f"ğŸ¤– æ”¯æŒ120é¡¹æ‰©å±•æŒ‡æ ‡åˆ†æ")
    print(f"ğŸ§  æä¾›AIé©±åŠ¨çš„é¢„æµ‹åˆ†æå’Œæ™ºèƒ½å»ºè®®")