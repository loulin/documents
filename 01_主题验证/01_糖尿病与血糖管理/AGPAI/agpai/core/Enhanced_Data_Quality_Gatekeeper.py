#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºæ•°æ®è´¨é‡é—¨æ§ç³»ç»Ÿ
åœ¨è¿›è¡Œä»»ä½•AGPåˆ†æå‰ï¼Œä¸¥æ ¼è¯„ä¼°æ•°æ®è´¨é‡ï¼Œä¸åˆæ ¼æ•°æ®ç›´æ¥æ‹’ç»åˆ†æå¹¶å»ºè®®æ›´æ¢ä¼ æ„Ÿå™¨
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union
import warnings
import logging
from enum import Enum

class DataQualityLevel(Enum):
    """æ•°æ®è´¨é‡ç­‰çº§"""
    EXCELLENT = "ä¼˜ç§€"
    GOOD = "è‰¯å¥½" 
    ACCEPTABLE = "å¯æ¥å—"
    POOR = "è¾ƒå·®"
    UNACCEPTABLE = "ä¸å¯æ¥å—"

class QualityGateAction(Enum):
    """è´¨é‡é—¨æ§å†³ç­–"""
    PROCEED = "ç»§ç»­åˆ†æ"
    PROCEED_WITH_WARNING = "è­¦å‘Šä¸‹ç»§ç»­"
    REPAIR_AND_RETRY = "ä¿®å¤åé‡è¯•"
    REPLACE_SENSOR = "æ›´æ¢ä¼ æ„Ÿå™¨"
    REJECT_ANALYSIS = "æ‹’ç»åˆ†æ"

class EnhancedDataQualityGatekeeper:
    """å¢å¼ºæ•°æ®è´¨é‡é—¨æ§å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è´¨é‡æ ‡å‡†å’Œé˜ˆå€¼"""
        
        # ä¸¥æ ¼çš„è´¨é‡æ ‡å‡† - ä¸å¯æ¥å—é˜ˆå€¼
        self.unacceptable_thresholds = {
            'minimum_days': 7,                # æœ€å°‘7å¤©æ•°æ®
            'minimum_coverage': 60,           # æœ€ä½60%è¦†ç›–ç‡
            'maximum_gap_hours': 8,           # æœ€å¤§è¿ç»­ç¼ºå¤±8å°æ—¶
            'maximum_stuck_minutes': 120,     # ä¼ æ„Ÿå™¨å¡æ­»ä¸è¶…è¿‡2å°æ—¶
            'maximum_drift_rate': 0.3,        # æ¼‚ç§»ç‡ä¸è¶…è¿‡0.3 mmol/L/å°æ—¶
            'minimum_variability': 1.0,       # æœ€å°å˜å¼‚ç³»æ•°1%
            'maximum_delay_minutes': 90,      # æ•°æ®å»¶è¿Ÿä¸è¶…è¿‡1.5å°æ—¶
            'minimum_signal_quality': 0.3     # ä¿¡å·è´¨é‡æœ€ä½0.3
        }
        
        # å¯æ¥å—é˜ˆå€¼
        self.acceptable_thresholds = {
            'minimum_days': 10,
            'minimum_coverage': 70,
            'maximum_gap_hours': 6,
            'maximum_stuck_minutes': 60,
            'maximum_drift_rate': 0.15,
            'minimum_variability': 2.0,
            'maximum_delay_minutes': 30,
            'minimum_signal_quality': 0.5
        }
        
        # ä¼˜ç§€é˜ˆå€¼
        self.excellent_thresholds = {
            'minimum_days': 14,
            'minimum_coverage': 85,
            'maximum_gap_hours': 2,
            'maximum_stuck_minutes': 15,
            'maximum_drift_rate': 0.05,
            'minimum_variability': 5.0,
            'maximum_delay_minutes': 15,
            'minimum_signal_quality': 0.8
        }

    def evaluate_data_quality(self, cgm_data: pd.DataFrame, metadata: Dict = None) -> Dict:
        """
        ä¸»è¦è´¨é‡è¯„ä¼°å…¥å£ - æ•°æ®è´¨é‡é—¨æ§
        
        Args:
            cgm_data: CGMæ•°æ®
            metadata: å…ƒæ•°æ®ä¿¡æ¯
            
        Returns:
            å®Œæ•´çš„è´¨é‡è¯„ä¼°ç»“æœå’Œå†³ç­–å»ºè®®
        """
        
        logging.info("ğŸšª å¯åŠ¨æ•°æ®è´¨é‡é—¨æ§è¯„ä¼°...")
        
        try:
            # Step 1: æ•°æ®é¢„å¤„ç†å’ŒåŸºç¡€éªŒè¯
            preprocessed_data = self._preprocess_and_validate(cgm_data)
            if preprocessed_data is None:
                return self._generate_rejection_result("æ•°æ®é¢„å¤„ç†å¤±è´¥")
            
            # Step 2: æ‰§è¡Œå…¨é¢è´¨é‡æ£€æµ‹
            quality_metrics = self._comprehensive_quality_assessment(preprocessed_data)
            
            # Step 3: å®æ—¶æ€§å’ŒåŠæ—¶æ€§æ£€æŸ¥
            timeliness_check = self._evaluate_data_timeliness(preprocessed_data)
            quality_metrics.update(timeliness_check)
            
            # Step 4: ä¼ æ„Ÿå™¨æ•…éšœè¯Šæ–­
            sensor_health = self._diagnose_sensor_health(preprocessed_data)
            quality_metrics.update(sensor_health)
            
            # Step 5: æ•°æ®æ¥æºéªŒè¯
            if metadata:
                source_validation = self._validate_data_source(preprocessed_data, metadata)
                quality_metrics.update(source_validation)
            
            # Step 6: ç»¼åˆè´¨é‡è¯„ä¼°å’Œå†³ç­–
            final_assessment = self._make_quality_decision(quality_metrics)
            
            # Step 7: ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            quality_report = self._generate_quality_report(quality_metrics, final_assessment)
            
            # è®°å½•è´¨é‡é—¨æ§ç»“æœ
            self._log_gatekeeper_decision(final_assessment, quality_report)
            
            return quality_report
            
        except Exception as e:
            logging.error(f"è´¨é‡é—¨æ§è¯„ä¼°å¼‚å¸¸: {str(e)}")
            return self._generate_rejection_result(f"è¯„ä¼°è¿‡ç¨‹å¼‚å¸¸: {str(e)}")

    def _comprehensive_quality_assessment(self, data: pd.DataFrame) -> Dict:
        """å…¨é¢è´¨é‡è¯„ä¼°"""
        
        metrics = {}
        glucose_values = data['glucose'].dropna()
        
        # 1. æ•°æ®å®Œæ•´æ€§è¯„ä¼°
        metrics['completeness'] = self._assess_completeness(data)
        
        # 2. æ—¶é—´è¿ç»­æ€§è¯„ä¼°  
        metrics['continuity'] = self._assess_continuity(data)
        
        # 3. æ•°æ®æœ‰æ•ˆæ€§è¯„ä¼°
        metrics['validity'] = self._assess_validity(glucose_values)
        
        # 4. å˜å¼‚æ€§è¯„ä¼°
        metrics['variability'] = self._assess_variability(glucose_values)
        
        # 5. å¼‚å¸¸å€¼è¯„ä¼°
        metrics['outliers'] = self._assess_outliers(glucose_values)
        
        return metrics

    def _evaluate_data_timeliness(self, data: pd.DataFrame) -> Dict:
        """è¯„ä¼°æ•°æ®åŠæ—¶æ€§"""
        
        current_time = datetime.now()
        latest_data_time = pd.to_datetime(data['timestamp'].max())
        
        # è®¡ç®—æ•°æ®å»¶è¿Ÿ
        delay_minutes = (current_time - latest_data_time).total_seconds() / 60
        
        # è¯„ä¼°å®æ—¶æ€§çŠ¶æ€
        if delay_minutes <= 15:
            timeliness_status = "å®æ—¶"
            timeliness_score = 100
        elif delay_minutes <= 30:
            timeliness_status = "å‡†å®æ—¶"
            timeliness_score = 80
        elif delay_minutes <= 60:
            timeliness_status = "å»¶è¿Ÿ"
            timeliness_score = 60
        elif delay_minutes <= 90:
            timeliness_status = "ä¸¥é‡å»¶è¿Ÿ"
            timeliness_score = 30
        else:
            timeliness_status = "æ•°æ®è¿‡æœŸ"
            timeliness_score = 0
        
        return {
            'timeliness': {
                'delay_minutes': delay_minutes,
                'status': timeliness_status,
                'score': timeliness_score,
                'is_acceptable': delay_minutes <= self.unacceptable_thresholds['maximum_delay_minutes'],
                'latest_timestamp': latest_data_time.isoformat(),
                'evaluation_time': current_time.isoformat()
            }
        }

    def _diagnose_sensor_health(self, data: pd.DataFrame) -> Dict:
        """ä¼ æ„Ÿå™¨å¥åº·è¯Šæ–­"""
        
        glucose = data['glucose'].values
        timestamps = pd.to_datetime(data['timestamp'])
        
        diagnosis = {}
        
        # 1. ä¼ æ„Ÿå™¨å¡æ­»æ£€æµ‹
        stuck_analysis = self._detect_sensor_stuck_advanced(glucose)
        diagnosis['sensor_stuck'] = stuck_analysis
        
        # 2. ä¼ æ„Ÿå™¨æ¼‚ç§»æ£€æµ‹
        drift_analysis = self._detect_sensor_drift_advanced(glucose, timestamps)
        diagnosis['sensor_drift'] = drift_analysis
        
        # 3. ä¿¡å·è´¨é‡è¯„ä¼°
        signal_quality = self._assess_signal_quality(glucose)
        diagnosis['signal_quality'] = signal_quality
        
        # 4. æ ¡å‡†çŠ¶æ€è¯„ä¼°
        calibration_status = self._assess_calibration_status(glucose)
        diagnosis['calibration'] = calibration_status
        
        # 5. ä¼ æ„Ÿå™¨å¯¿å‘½è¯„ä¼°
        lifetime_assessment = self._assess_sensor_lifetime(data)
        diagnosis['lifetime'] = lifetime_assessment
        
        return {'sensor_health': diagnosis}

    def _detect_sensor_stuck_advanced(self, glucose: np.ndarray) -> Dict:
        """é«˜çº§ä¼ æ„Ÿå™¨å¡æ­»æ£€æµ‹"""
        
        consecutive_threshold = 0.1  # 0.1 mmol/Lä»¥å†…è®¤ä¸ºç›¸åŒ
        max_stuck_minutes = 0
        stuck_periods = []
        current_stuck = 0
        
        for i in range(1, len(glucose)):
            if abs(glucose[i] - glucose[i-1]) <= consecutive_threshold:
                current_stuck += 1
            else:
                if current_stuck > 0:
                    stuck_minutes = current_stuck * 15  # å‡è®¾15åˆ†é’Ÿé—´éš”
                    if stuck_minutes >= 30:  # è®°å½•30åˆ†é’Ÿä»¥ä¸Šçš„å¡æ­»
                        stuck_periods.append({
                            'start_index': i - current_stuck - 1,
                            'end_index': i - 1,
                            'duration_minutes': stuck_minutes,
                            'stuck_value': glucose[i-1]
                        })
                    max_stuck_minutes = max(max_stuck_minutes, stuck_minutes)
                current_stuck = 0
        
        # æ£€æŸ¥æœ«å°¾
        if current_stuck > 0:
            stuck_minutes = current_stuck * 15
            max_stuck_minutes = max(max_stuck_minutes, stuck_minutes)
        
        is_stuck = max_stuck_minutes > self.unacceptable_thresholds['maximum_stuck_minutes']
        severity = self._categorize_stuck_severity(max_stuck_minutes)
        
        return {
            'detected': is_stuck,
            'max_stuck_minutes': max_stuck_minutes,
            'stuck_periods': stuck_periods,
            'severity': severity,
            'is_acceptable': not is_stuck
        }

    def _detect_sensor_drift_advanced(self, glucose: np.ndarray, timestamps: pd.Series) -> Dict:
        """é«˜çº§ä¼ æ„Ÿå™¨æ¼‚ç§»æ£€æµ‹"""
        
        # è®¡ç®—æ—¶é—´åºåˆ—(å°æ—¶)
        time_hours = np.array([(t - timestamps.iloc[0]).total_seconds() / 3600 for t in timestamps])
        
        # æ•´ä½“çº¿æ€§è¶‹åŠ¿
        overall_slope = np.polyfit(time_hours, glucose, 1)[0]
        
        # åˆ†æ®µè¶‹åŠ¿åˆ†æ
        segment_size = min(48, len(glucose) // 4)  # 12å°æ—¶æ®µ
        segment_slopes = []
        
        if len(glucose) >= segment_size * 2:
            for i in range(0, len(glucose) - segment_size, segment_size // 2):
                end_idx = min(i + segment_size, len(glucose))
                segment_glucose = glucose[i:end_idx]
                segment_time = time_hours[i:end_idx]
                
                if len(segment_glucose) > 10:
                    slope = np.polyfit(segment_time, segment_glucose, 1)[0]
                    segment_slopes.append(slope)
        
        # æ¼‚ç§»è¯„ä¼°
        drift_rate = abs(overall_slope)
        progressive_drift = np.std(segment_slopes) if segment_slopes else 0
        
        severity = self._categorize_drift_severity(drift_rate)
        is_acceptable = drift_rate <= self.unacceptable_thresholds['maximum_drift_rate']
        
        return {
            'detected': drift_rate > 0.05,  # æ¯å°æ—¶æ¼‚ç§»è¶…è¿‡0.05
            'drift_rate_per_hour': drift_rate,
            'overall_slope': overall_slope,
            'progressive_drift': progressive_drift,
            'severity': severity,
            'is_acceptable': is_acceptable,
            'segment_slopes': segment_slopes
        }

    def _assess_signal_quality(self, glucose: np.ndarray) -> Dict:
        """ä¿¡å·è´¨é‡è¯„ä¼°"""
        
        # 1. ä¿¡å™ªæ¯”è¯„ä¼°
        signal_mean = np.mean(glucose)
        noise_std = np.std(np.diff(glucose))  # é«˜é¢‘å™ªå£°
        snr = signal_mean / noise_std if noise_std > 0 else float('inf')
        
        # 2. å¹³æ»‘åº¦è¯„ä¼°
        smoothness = self._calculate_smoothness_index(glucose)
        
        # 3. æ•°æ®ä¸€è‡´æ€§è¯„ä¼°
        consistency = self._calculate_consistency_index(glucose)
        
        # 4. ç»¼åˆä¿¡å·è´¨é‡è¯„åˆ†
        quality_score = min(1.0, (snr / 20 + smoothness + consistency) / 3)
        
        return {
            'snr': snr,
            'smoothness': smoothness,
            'consistency': consistency,
            'quality_score': quality_score,
            'is_acceptable': quality_score >= self.unacceptable_thresholds['minimum_signal_quality']
        }

    def _make_quality_decision(self, quality_metrics: Dict) -> Dict:
        """åšå‡ºè´¨é‡é—¨æ§å†³ç­–"""
        
        # æ”¶é›†æ‰€æœ‰è´¨é‡æ£€æŸ¥ç»“æœ
        checks = []
        critical_failures = []
        warnings = []
        
        # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        if not quality_metrics.get('completeness', {}).get('is_acceptable', False):
            critical_failures.append("æ•°æ®å®Œæ•´æ€§ä¸è¶³")
            
        # æ—¶é—´è¿ç»­æ€§æ£€æŸ¥  
        if not quality_metrics.get('continuity', {}).get('is_acceptable', False):
            critical_failures.append("æ—¶é—´è¿ç»­æ€§ä¸è¶³")
            
        # æ•°æ®åŠæ—¶æ€§æ£€æŸ¥
        if not quality_metrics.get('timeliness', {}).get('is_acceptable', False):
            critical_failures.append("æ•°æ®ä¸åŠæ—¶")
            
        # ä¼ æ„Ÿå™¨å¥åº·æ£€æŸ¥
        sensor_health = quality_metrics.get('sensor_health', {})
        
        if sensor_health.get('sensor_stuck', {}).get('detected', False):
            critical_failures.append("ä¼ æ„Ÿå™¨å¡æ­»")
            
        if not sensor_health.get('sensor_drift', {}).get('is_acceptable', False):
            critical_failures.append("ä¼ æ„Ÿå™¨ä¸¥é‡æ¼‚ç§»")
            
        if not sensor_health.get('signal_quality', {}).get('is_acceptable', False):
            critical_failures.append("ä¿¡å·è´¨é‡è¿‡å·®")
        
        # å†³ç­–é€»è¾‘
        if len(critical_failures) >= 3:
            decision = QualityGateAction.REJECT_ANALYSIS
            recommendation = "æ•°æ®è´¨é‡ä¸¥é‡ä¸åˆæ ¼ï¼Œå¼ºçƒˆå»ºè®®æ›´æ¢ä¼ æ„Ÿå™¨"
            quality_level = DataQualityLevel.UNACCEPTABLE
            
        elif len(critical_failures) >= 1:
            if any("ä¼ æ„Ÿå™¨" in failure for failure in critical_failures):
                decision = QualityGateAction.REPLACE_SENSOR
                recommendation = "æ£€æµ‹åˆ°ä¼ æ„Ÿå™¨æ•…éšœï¼Œå»ºè®®ç«‹å³æ›´æ¢ä¼ æ„Ÿå™¨"
                quality_level = DataQualityLevel.POOR
            else:
                decision = QualityGateAction.REPAIR_AND_RETRY
                recommendation = "æ•°æ®è´¨é‡ä¸åˆæ ¼ï¼Œè¯·æ£€æŸ¥æ•°æ®é‡‡é›†ç³»ç»Ÿ"
                quality_level = DataQualityLevel.POOR
                
        elif len(warnings) > 0:
            decision = QualityGateAction.PROCEED_WITH_WARNING
            recommendation = "æ•°æ®è´¨é‡å¯æ¥å—ä½†å­˜åœ¨è­¦å‘Šï¼Œå»ºè®®å…³æ³¨æ•°æ®è´¨é‡"
            quality_level = DataQualityLevel.ACCEPTABLE
            
        else:
            decision = QualityGateAction.PROCEED
            recommendation = "æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥è¿›è¡Œåˆ†æ"
            quality_level = DataQualityLevel.GOOD

        return {
            'decision': decision,
            'quality_level': quality_level,
            'recommendation': recommendation,
            'critical_failures': critical_failures,
            'warnings': warnings,
            'can_proceed': decision in [QualityGateAction.PROCEED, QualityGateAction.PROCEED_WITH_WARNING]
        }

    def _generate_quality_report(self, quality_metrics: Dict, assessment: Dict) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„è´¨é‡æŠ¥å‘Š"""
        
        return {
            'timestamp': datetime.now().isoformat(),
            'gatekeeper_version': '2.0',
            
            # é—¨æ§å†³ç­–ç»“æœ
            'gate_decision': {
                'action': assessment['decision'].value,
                'quality_level': assessment['quality_level'].value,
                'can_proceed_with_analysis': assessment['can_proceed'],
                'recommendation': assessment['recommendation']
            },
            
            # è¯¦ç»†è´¨é‡æŒ‡æ ‡
            'quality_metrics': quality_metrics,
            
            # é—®é¢˜æ€»ç»“
            'issues_summary': {
                'critical_failures': assessment['critical_failures'],
                'warnings': assessment['warnings'],
                'total_issues': len(assessment['critical_failures']) + len(assessment['warnings'])
            },
            
            # è¡ŒåŠ¨å»ºè®®
            'action_items': self._generate_action_items(assessment),
            
            # è´¨é‡è¯„åˆ†
            'overall_score': self._calculate_overall_quality_score(quality_metrics),
            
            # ä¸‹æ¬¡æ£€æŸ¥å»ºè®®
            'next_check_recommendation': self._recommend_next_check(assessment)
        }

    def _generate_action_items(self, assessment: Dict) -> List[Dict]:
        """ç”Ÿæˆè¡ŒåŠ¨å»ºè®®"""
        
        action_items = []
        
        if assessment['decision'] == QualityGateAction.REPLACE_SENSOR:
            action_items.extend([
                {
                    'priority': 'CRITICAL',
                    'action': 'ç«‹å³æ›´æ¢CGMä¼ æ„Ÿå™¨',
                    'reason': 'æ£€æµ‹åˆ°ä¼ æ„Ÿå™¨æ•…éšœæˆ–ä¸¥é‡å¼‚å¸¸',
                    'estimated_time': '15-30åˆ†é’Ÿ'
                },
                {
                    'priority': 'HIGH',
                    'action': 'æ ¡å‡†æ–°ä¼ æ„Ÿå™¨',
                    'reason': 'ç¡®ä¿æ–°ä¼ æ„Ÿå™¨å‡†ç¡®æ€§',
                    'estimated_time': '2-4å°æ—¶'
                },
                {
                    'priority': 'MEDIUM', 
                    'action': 'ç›‘æµ‹æ–°ä¼ æ„Ÿå™¨24å°æ—¶',
                    'reason': 'éªŒè¯æ–°ä¼ æ„Ÿå™¨å·¥ä½œçŠ¶æ€',
                    'estimated_time': '24å°æ—¶'
                }
            ])
            
        elif assessment['decision'] == QualityGateAction.REJECT_ANALYSIS:
            action_items.append({
                'priority': 'CRITICAL',
                'action': 'åœæ­¢å½“å‰åˆ†æå¹¶æ£€æŸ¥æ•°æ®é‡‡é›†ç³»ç»Ÿ',
                'reason': 'æ•°æ®è´¨é‡ä¸¥é‡ä¸åˆæ ¼',
                'estimated_time': '1-2å°æ—¶'
            })
        
        return action_items

    def _log_gatekeeper_decision(self, assessment: Dict, report: Dict):
        """è®°å½•é—¨æ§å†³ç­–"""
        
        decision = assessment['decision']
        quality_level = assessment['quality_level']
        
        if decision == QualityGateAction.REJECT_ANALYSIS:
            logging.error(f"ğŸš« æ•°æ®è´¨é‡é—¨æ§: æ‹’ç»åˆ†æ - {assessment['recommendation']}")
            
        elif decision == QualityGateAction.REPLACE_SENSOR:
            logging.warning(f"ğŸ”„ æ•°æ®è´¨é‡é—¨æ§: å»ºè®®æ›´æ¢ä¼ æ„Ÿå™¨ - {assessment['recommendation']}")
            
        elif decision == QualityGateAction.PROCEED_WITH_WARNING:
            logging.info(f"âš ï¸ æ•°æ®è´¨é‡é—¨æ§: è­¦å‘Šä¸‹ç»§ç»­ - {assessment['recommendation']}")
            
        else:
            logging.info(f"âœ… æ•°æ®è´¨é‡é—¨æ§: è´¨é‡åˆæ ¼ï¼Œç»§ç»­åˆ†æ")

    # è¾…åŠ©æ–¹æ³•
    def _preprocess_and_validate(self, data: pd.DataFrame) -> Optional[pd.DataFrame]:
        """æ•°æ®é¢„å¤„ç†å’ŒåŸºç¡€éªŒè¯"""
        if data.empty:
            return None
            
        if 'timestamp' not in data.columns or 'glucose' not in data.columns:
            return None
            
        try:
            data = data.copy()
            data['timestamp'] = pd.to_datetime(data['timestamp'])
            data['glucose'] = pd.to_numeric(data['glucose'], errors='coerce')
            data = data.sort_values('timestamp').reset_index(drop=True)
            return data
        except:
            return None

    def _assess_completeness(self, data: pd.DataFrame) -> Dict:
        """è¯„ä¼°æ•°æ®å®Œæ•´æ€§"""
        time_span_days = (data['timestamp'].max() - data['timestamp'].min()).days
        return {
            'time_span_days': time_span_days,
            'is_acceptable': time_span_days >= self.unacceptable_thresholds['minimum_days']
        }

    def _assess_continuity(self, data: pd.DataFrame) -> Dict:
        """è¯„ä¼°æ—¶é—´è¿ç»­æ€§"""  
        time_diffs = data['timestamp'].diff().dt.total_seconds() / 60
        max_gap_hours = time_diffs.max() / 60 if not time_diffs.empty else 0
        return {
            'max_gap_hours': max_gap_hours,
            'is_acceptable': max_gap_hours <= self.unacceptable_thresholds['maximum_gap_hours']
        }

    def _assess_validity(self, glucose: np.ndarray) -> Dict:
        """è¯„ä¼°æ•°æ®æœ‰æ•ˆæ€§"""
        valid_range = (glucose >= 1.0) & (glucose <= 33.3)
        valid_rate = np.sum(valid_range) / len(glucose) * 100
        return {
            'valid_rate': valid_rate,
            'is_acceptable': valid_rate >= 95
        }

    def _assess_variability(self, glucose: np.ndarray) -> Dict:
        """è¯„ä¼°æ•°æ®å˜å¼‚æ€§"""
        cv = (np.std(glucose) / np.mean(glucose)) * 100 if np.mean(glucose) > 0 else 0
        return {
            'coefficient_variation': cv,
            'is_acceptable': cv >= self.unacceptable_thresholds['minimum_variability']
        }

    def _assess_outliers(self, glucose: np.ndarray) -> Dict:
        """è¯„ä¼°å¼‚å¸¸å€¼"""
        q75, q25 = np.percentile(glucose, [75, 25])
        iqr = q75 - q25
        outliers = np.sum((glucose < q25 - 1.5 * iqr) | (glucose > q75 + 1.5 * iqr))
        outlier_rate = (outliers / len(glucose)) * 100
        return {
            'outlier_rate': outlier_rate,
            'is_acceptable': outlier_rate <= 10
        }

    def _assess_calibration_status(self, glucose: np.ndarray) -> Dict:
        """è¯„ä¼°æ ¡å‡†çŠ¶æ€"""
        # ç®€åŒ–çš„æ ¡å‡†è¯„ä¼°
        mean_glucose = np.mean(glucose)
        reasonable_range = 4.0 <= mean_glucose <= 15.0  # åˆç†çš„å¹³å‡è¡€ç³–èŒƒå›´
        
        return {
            'mean_glucose': mean_glucose,
            'in_reasonable_range': reasonable_range,
            'is_acceptable': reasonable_range
        }

    def _assess_sensor_lifetime(self, data: pd.DataFrame) -> Dict:
        """è¯„ä¼°ä¼ æ„Ÿå™¨å¯¿å‘½"""
        time_span = (data['timestamp'].max() - data['timestamp'].min()).days
        
        return {
            'current_age_days': time_span,
            'estimated_remaining_days': max(0, 14 - time_span),
            'replacement_due_soon': time_span >= 12,
            'is_acceptable': time_span <= 14
        }

    def _calculate_smoothness_index(self, glucose: np.ndarray) -> float:
        """è®¡ç®—å¹³æ»‘åº¦æŒ‡æ•°"""
        if len(glucose) < 3:
            return 0.5
        
        second_diff = np.diff(glucose, n=2)
        smoothness = 1 / (1 + np.std(second_diff))
        return min(1.0, smoothness)

    def _calculate_consistency_index(self, glucose: np.ndarray) -> float:
        """è®¡ç®—ä¸€è‡´æ€§æŒ‡æ•°"""
        if len(glucose) < 10:
            return 0.5
            
        segments = np.array_split(glucose, min(5, len(glucose)//10))
        segment_means = [np.mean(seg) for seg in segments if len(seg) > 0]
        
        if len(segment_means) < 2:
            return 0.5
            
        consistency = 1 / (1 + np.std(segment_means) / np.mean(segment_means))
        return min(1.0, consistency)

    def _categorize_stuck_severity(self, stuck_minutes: float) -> str:
        """åˆ†ç±»å¡æ­»ä¸¥é‡ç¨‹åº¦"""
        if stuck_minutes >= 120:
            return "ä¸¥é‡"
        elif stuck_minutes >= 60:
            return "ä¸­ç­‰"
        elif stuck_minutes >= 30:
            return "è½»å¾®"
        else:
            return "æ­£å¸¸"

    def _categorize_drift_severity(self, drift_rate: float) -> str:
        """åˆ†ç±»æ¼‚ç§»ä¸¥é‡ç¨‹åº¦"""
        if drift_rate >= 0.3:
            return "ä¸¥é‡"
        elif drift_rate >= 0.15:
            return "ä¸­ç­‰"
        elif drift_rate >= 0.05:
            return "è½»å¾®"
        else:
            return "æ­£å¸¸"

    def _calculate_overall_quality_score(self, metrics: Dict) -> float:
        """è®¡ç®—ç»¼åˆè´¨é‡è¯„åˆ†"""
        # ç®€åŒ–çš„ç»¼åˆè¯„åˆ†ç®—æ³•
        scores = []
        
        # å„é¡¹æŒ‡æ ‡æƒé‡è¯„åˆ†
        if metrics.get('completeness', {}).get('is_acceptable'):
            scores.append(25)
        if metrics.get('continuity', {}).get('is_acceptable'):
            scores.append(25)
        if metrics.get('timeliness', {}).get('is_acceptable'):
            scores.append(20)
        if metrics.get('sensor_health', {}).get('signal_quality', {}).get('is_acceptable'):
            scores.append(30)
            
        return sum(scores)

    def _recommend_next_check(self, assessment: Dict) -> str:
        """å»ºè®®ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´"""
        if assessment['decision'] == QualityGateAction.REPLACE_SENSOR:
            return "æ›´æ¢ä¼ æ„Ÿå™¨åç«‹å³æ£€æŸ¥"
        elif assessment['decision'] == QualityGateAction.REJECT_ANALYSIS:
            return "ä¿®å¤é—®é¢˜åé‡æ–°è¯„ä¼°"
        else:
            return "24å°æ—¶åä¾‹è¡Œæ£€æŸ¥"

    def _generate_rejection_result(self, reason: str) -> Dict:
        """ç”Ÿæˆæ‹’ç»ç»“æœ"""
        return {
            'timestamp': datetime.now().isoformat(),
            'gate_decision': {
                'action': QualityGateAction.REJECT_ANALYSIS.value,
                'quality_level': DataQualityLevel.UNACCEPTABLE.value,
                'can_proceed_with_analysis': False,
                'recommendation': f"æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {reason}ï¼Œè¯·æ£€æŸ¥æ•°æ®æºå¹¶è€ƒè™‘æ›´æ¢ä¼ æ„Ÿå™¨"
            },
            'issues_summary': {
                'critical_failures': [reason],
                'warnings': [],
                'total_issues': 1
            },
            'action_items': [{
                'priority': 'CRITICAL',
                'action': 'æ£€æŸ¥ä¼ æ„Ÿå™¨å’Œæ•°æ®é‡‡é›†ç³»ç»Ÿ',
                'reason': reason,
                'estimated_time': '30-60åˆ†é’Ÿ'
            }]
        }