#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AGPAI Agent V2.0 - Advanced CGM Analysis with Historical Comparison & Clinical Decision Support
åŸºäºå¾ªè¯åŒ»å­¦çš„ä¸“ä¸šè¡€ç³–åˆ†ææ™ºèƒ½ä½“ - æ–°ç‰ˆæœ¬

åŠŸèƒ½ç‰¹ç‚¹:
1. åŒé‡å˜å¼‚æ€§åˆ†ææ¡†æ¶
2. ä¸´åºŠè¡¨å‹è‡ªåŠ¨è¯†åˆ«
3. å†å²æ•°æ®å¯¹æ¯”åˆ†æ
4. ä¸ªæ€§åŒ–è¯Šç–—å»ºè®®ç”Ÿæˆ
5. ç—…ç†ç”Ÿç†æœºåˆ¶è§£é‡Š
6. ä¸“ä¸šåŒ»å­¦è¯­è¨€è¾“å‡º
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import json
import os
from dataclasses import dataclass
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

class ClinicalPhenotype(Enum):
    """ä¸´åºŠè¡¨å‹åˆ†ç±»"""
    STABLE_HYPERGLYCEMIC = "ç¨³å®šæ€§é«˜è¡€ç³–å‹"
    NEAR_TARGET = "æ¥è¿‘è¾¾æ ‡å‹"  
    POSTPRANDIAL_EXCURSION = "é¤åæ¿€å‘å‹"
    HIGH_VARIABILITY = "é«˜å˜å¼‚æ€§å‹"
    HYPOGLYCEMIC_RISK = "ä½è¡€ç³–é£é™©å‹"
    OPTIMAL_CONTROL = "ä¼˜åŒ–æ§åˆ¶å‹"

class RiskLevel(Enum):
    """é£é™©ç­‰çº§"""
    LOW = "ä½é£é™©"
    MODERATE = "ä¸­ç­‰é£é™©"
    HIGH = "é«˜é£é™©"
    CRITICAL = "æé«˜é£é™©"

@dataclass
class PatientProfile:
    """æ‚£è€…æ¡£æ¡ˆ"""
    patient_id: str
    analysis_date: str
    monitoring_days: int
    data_points: int
    completeness: float

@dataclass
class GlycemicMetrics:
    """è¡€ç³–æŒ‡æ ‡"""
    mean_glucose: float
    mean_glucose_mgdl: float
    glucose_cv: float
    percentile_band_cv: float
    tir: float
    tar_level1: float
    tar_level2: float
    tbr_level1: float
    tbr_level2: float
    gmi: float
    ea1c: float
    estimated_hba1c: float
    min_glucose: float
    max_glucose: float
    glucose_range: float
    mage: float
    conga: float
    j_index: float
    lbgi: float
    hbgi: float
    grade_score: float

@dataclass
class CircadianAnalysis:
    """æ˜¼å¤œèŠ‚å¾‹åˆ†æ"""
    dawn_phenomenon: float
    nocturnal_stability: float
    meal_responses: Dict[str, float]
    peak_times: Dict[str, str]
    most_variable_hour: str
    hourly_patterns: Dict[str, float]
    dawn_peak_time: str
    dawn_magnitude: float
    postprandial_peaks: Dict[str, Dict]
    nocturnal_nadir: float
    circadian_amplitude: float

@dataclass
class ClinicalRecommendation:
    """ä¸´åºŠå»ºè®®"""
    priority: str  # "ç´§æ€¥", "é«˜", "ä¸­", "ä½"
    category: str
    recommendation: str
    mechanism: str
    expected_outcome: str
    monitoring_points: List[str]
    timeframe: str
    specific_actions: List[str]
    dosing_suggestions: str
    timing_instructions: str
    follow_up_schedule: str
    success_criteria: str
    warning_signs: List[str]

class AGPAI_Agent_V2:
    """AGPAIæ™ºèƒ½åˆ†æä»£ç† V2.0"""
    
    def __init__(self, data_storage_path: str = "./agpai_patient_data/"):
        """åˆå§‹åŒ–AGPAI Agent V2.0"""
        self.data_storage_path = data_storage_path
        self.patient_database = {}
        self.phenotype_patterns = self._initialize_phenotype_database()
        self._ensure_storage_directory()
        self._load_patient_database()
        
    def _ensure_storage_directory(self):
        """ç¡®ä¿æ•°æ®å­˜å‚¨ç›®å½•å­˜åœ¨"""
        os.makedirs(self.data_storage_path, exist_ok=True)
        
    def _initialize_phenotype_database(self) -> Dict:
        """åˆå§‹åŒ–ä¸´åºŠè¡¨å‹æ•°æ®åº“"""
        return {
            ClinicalPhenotype.STABLE_HYPERGLYCEMIC: {
                "glucose_cv_range": (20, 30),
                "tir_range": (40, 60),
                "tbr_threshold": 2.0,
                "dawn_phenomenon_threshold": 3.0,
                "key_features": ["ä½å˜å¼‚æ€§", "TIRä¸è¶³", "æ— ä½è¡€ç³–", "é»æ˜ç°è±¡"],
                "pathophysiology": "åŸºç¡€èƒ°å²›ç´ åˆ†æ³Œä¸è¶³ï¼Œèƒ°å²›åŠŸèƒ½ç›¸å¯¹ç¨³å®š",
                "treatment_focus": "ç§¯æå¼ºåŒ–åŸºç¡€å’Œé¤æ—¶èƒ°å²›ç´ "
            },
            ClinicalPhenotype.NEAR_TARGET: {
                "glucose_cv_range": (25, 35),
                "tir_range": (60, 75),
                "tbr_threshold": 5.0,
                "dawn_phenomenon_threshold": 2.0,
                "key_features": ["ä¸­ç­‰å˜å¼‚æ€§", "æ¥è¿‘è¾¾æ ‡", "è½»åº¦ä½è¡€ç³–é£é™©"],
                "pathophysiology": "èƒ°å²›åŠŸèƒ½åŸºæœ¬ä¿å­˜ï¼Œè°ƒèŠ‚æœºåˆ¶ç›¸å¯¹å®Œæ•´",
                "treatment_focus": "ç²¾ç»†åŒ–è°ƒæ•´ï¼Œé˜²èŒƒä½è¡€ç³–"
            },
            ClinicalPhenotype.POSTPRANDIAL_EXCURSION: {
                "glucose_cv_range": (20, 30),
                "tir_range": (75, 95),
                "tbr_threshold": 1.0,
                "excursion_pattern": "é¤åä¸ºä¸»",
                "key_features": ["åŸºç¡€æ§åˆ¶ä¼˜ç§€", "é¤åæ¿€å‘", "æ˜¼å¤œèŠ‚å¾‹ç¨³å®š"],
                "pathophysiology": "é¤æ—¶èƒ°å²›ç´ åˆ†æ³Œå»¶è¿Ÿæˆ–èƒ°å²›ç´ æŠµæŠ—",
                "treatment_focus": "é¤æ—¶è¡€ç³–ç²¾å‡†ç®¡ç†"
            }
        }
    
    def read_cgm_file(self, file_path: str) -> pd.DataFrame:
        """è¯»å–CGMæ•°æ®æ–‡ä»¶"""
        try:
            # è´¨è‚½ç”Ÿç‰©æ ¼å¼: ID\tæ—¶é—´\tè®°å½•ç±»å‹\tè‘¡è„ç³–å†å²è®°å½•ï¼ˆmmol/Lï¼‰
            with open(file_path, 'r', encoding='utf-8') as file:
                lines = file.readlines()
            
            # è·³è¿‡å‰ä¸¤è¡Œï¼ˆæ ‡è¯†ç¬¦å’Œæ‚£è€…IDï¼‰
            data_lines = [line.strip() for line in lines[3:] if line.strip()]
            
            data = []
            for line in data_lines:
                parts = line.split('\t')
                if len(parts) >= 4:
                    try:
                        timestamp = pd.to_datetime(parts[1], format='%Y/%m/%d %H:%M')
                        glucose_value = float(parts[3])
                        data.append({
                            'timestamp': timestamp,
                            'glucose': glucose_value
                        })
                    except (ValueError, IndexError):
                        continue
            
            df = pd.DataFrame(data)
            if len(df) == 0:
                raise ValueError("æ— æœ‰æ•ˆæ•°æ®")
                
            df = df.sort_values('timestamp').reset_index(drop=True)
            return df
            
        except Exception as e:
            raise Exception(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
    
    def calculate_dual_variability(self, df: pd.DataFrame) -> Tuple[float, float]:
        """è®¡ç®—åŒé‡å˜å¼‚æ€§æŒ‡æ ‡"""
        # 1. æ•´ä½“è¡€ç³–å˜å¼‚ç³»æ•°
        glucose_cv = (df['glucose'].std() / df['glucose'].mean()) * 100
        
        # 2. æ˜¼å¤œæ¨¡å¼å˜å¼‚æ€§ï¼ˆåˆ†ä½æ•°å¸¦å˜å¼‚ç³»æ•°ï¼‰
        df['hour'] = df['timestamp'].dt.hour
        df['time_of_day'] = df['hour'] + df['timestamp'].dt.minute / 60
        
        # è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹çš„åˆ†ä½æ•°å¸¦å®½
        percentile_bands = []
        for hour in range(24):
            hour_data = df[df['hour'] == hour]['glucose']
            if len(hour_data) > 5:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
                p25 = hour_data.quantile(0.25)
                p75 = hour_data.quantile(0.75)
                band_width = p75 - p25
                percentile_bands.append(band_width)
        
        if len(percentile_bands) > 0:
            percentile_band_cv = (np.std(percentile_bands) / np.mean(percentile_bands)) * 100
        else:
            percentile_band_cv = 0
        
        return glucose_cv, percentile_band_cv
    
    def calculate_agp_metrics(self, df: pd.DataFrame) -> Dict:
        """è®¡ç®—AGPæ ‡å‡†æŒ‡æ ‡"""
        glucose_values = df['glucose']
        
        # TIR/TAR/TBRè®¡ç®—
        tir = ((glucose_values >= 3.9) & (glucose_values <= 10.0)).mean() * 100
        tar_level1 = (glucose_values > 10.0).mean() * 100
        tar_level2 = (glucose_values > 13.9).mean() * 100
        tbr_level1 = (glucose_values < 3.9).mean() * 100
        tbr_level2 = (glucose_values < 3.0).mean() * 100
        
        # è¡€ç³–æ•´ä½“è¯„ä¼°æŒ‡æ ‡
        mean_glucose = glucose_values.mean()
        mean_glucose_mgdl = mean_glucose * 18.018  # mmol/L to mg/dL
        
        # GMI (Glucose Management Indicator) - ATTD 2019æ ‡å‡†
        gmi = (mean_glucose_mgdl + 46.7) / 28.7
        
        # eA1C (estimated A1C) - Nathanå…¬å¼
        ea1c = (mean_glucose_mgdl + 46.7) / 28.7
        
        # ADAGå…¬å¼ (A1C-Derived Average Glucose)
        # HbA1c = (å¹³å‡è¡€ç³–(mg/dL) + 46.7) / 28.7
        estimated_hba1c = (mean_glucose_mgdl + 46.7) / 28.7
        
        # MAGEè®¡ç®— (Mean Amplitude of Glycemic Excursions)
        mage = self._calculate_mage(glucose_values)
        
        # CONGAè®¡ç®— (Continuous Overlapping Net Glycemic Action)
        conga = self._calculate_conga(glucose_values)
        
        # J-Index (è¡€ç³–è´¨é‡æŒ‡æ•°) - ä¿®æ­£å…¬å¼
        glucose_std_mgdl = glucose_values.std() * 18.018
        j_index = 0.001 * (mean_glucose_mgdl + glucose_std_mgdl) ** 2
        
        # LBGI/HBGI (Low/High Blood Glucose Index)
        lbgi, hbgi = self._calculate_bgri(glucose_values)
        
        # GRADE (Glycemic Risk Assessment Diabetes Equation)
        grade_score = self._calculate_grade(glucose_values)
        
        return {
            'tir': tir,
            'tar_level1': tar_level1,
            'tar_level2': tar_level2,
            'tbr_level1': tbr_level1,
            'tbr_level2': tbr_level2,
            'gmi': gmi,
            'ea1c': ea1c,
            'estimated_hba1c': estimated_hba1c,
            'mean_glucose': mean_glucose,
            'mean_glucose_mgdl': mean_glucose_mgdl,
            'std_glucose': glucose_values.std(),
            'min_glucose': glucose_values.min(),
            'max_glucose': glucose_values.max(),
            'glucose_range': glucose_values.max() - glucose_values.min(),
            'mage': mage,
            'conga': conga,
            'j_index': j_index,
            'lbgi': lbgi,
            'hbgi': hbgi,
            'grade_score': grade_score
        }
    
    def _calculate_mage(self, glucose_values: pd.Series) -> float:
        """è®¡ç®—MAGE (Mean Amplitude of Glycemic Excursions)"""
        try:
            # è®¡ç®—ç›¸é‚»ç‚¹å·®å€¼
            diff = glucose_values.diff().dropna()
            
            # æ‰¾åˆ°å³°å€¼å’Œè°·å€¼
            peaks = []
            valleys = []
            
            for i in range(1, len(diff)):
                if diff.iloc[i-1] > 0 and diff.iloc[i] <= 0:  # å³°å€¼
                    peaks.append(glucose_values.iloc[i])
                elif diff.iloc[i-1] < 0 and diff.iloc[i] >= 0:  # è°·å€¼
                    valleys.append(glucose_values.iloc[i])
            
            # è®¡ç®—å¹³å‡æŒ¯å¹…
            if len(peaks) > 0 and len(valleys) > 0:
                all_excursions = []
                min_len = min(len(peaks), len(valleys))
                for i in range(min_len):
                    all_excursions.append(abs(peaks[i] - valleys[i]))
                return np.mean(all_excursions) if all_excursions else 0
            else:
                return glucose_values.std()  # å¦‚æœæ— æ³•è®¡ç®—MAGEï¼Œä½¿ç”¨æ ‡å‡†å·®
        except:
            return glucose_values.std()
    
    def _calculate_conga(self, glucose_values: pd.Series, n_hours: int = 1) -> float:
        """è®¡ç®—CONGA (Continuous Overlapping Net Glycemic Action)"""
        try:
            # å‡è®¾15åˆ†é’Ÿé—´éš”ï¼Œ1å°æ—¶=4ä¸ªç‚¹
            n_points = n_hours * 4
            
            if len(glucose_values) < n_points:
                return glucose_values.std()
            
            # è®¡ç®—è¿ç»­é‡å å·®å€¼
            conga_values = []
            for i in range(len(glucose_values) - n_points):
                diff = glucose_values.iloc[i + n_points] - glucose_values.iloc[i]
                conga_values.append(diff)
            
            return np.std(conga_values) if conga_values else 0
        except:
            return glucose_values.std()
    
    def _calculate_bgri(self, glucose_values: pd.Series) -> tuple:
        """è®¡ç®—LBGIå’ŒHBGI (Blood Glucose Risk Index)"""
        try:
            # è½¬æ¢ä¸ºmg/dL
            glucose_mgdl = glucose_values * 18.018
            
            # Kovatchevå…¬å¼
            def risk_function(bg):
                if bg <= 0:
                    return 0
                f_bg = 1.509 * ((np.log(bg) ** 1.084) - 5.381)
                if f_bg <= 0:
                    return 10 * f_bg ** 2  # ä½è¡€ç³–é£é™©
                else:
                    return 10 * f_bg ** 2  # é«˜è¡€ç³–é£é™©
            
            low_risks = []
            high_risks = []
            
            for bg in glucose_mgdl:
                f_bg = 1.509 * ((np.log(bg) ** 1.084) - 5.381)
                if f_bg <= 0:
                    low_risks.append(10 * f_bg ** 2)
                    high_risks.append(0)
                else:
                    low_risks.append(0)
                    high_risks.append(10 * f_bg ** 2)
            
            lbgi = np.mean(low_risks)
            hbgi = np.mean(high_risks)
            
            return lbgi, hbgi
        except:
            return 0, 0
    
    def _calculate_grade(self, glucose_values: pd.Series) -> float:
        """è®¡ç®—GRADE (Glycemic Risk Assessment Diabetes Equation)"""
        try:
            # è½¬æ¢ä¸ºmg/dL
            glucose_mgdl = glucose_values * 18.018
            
            # GRADEå…¬å¼ - ä¿®æ­£ç‰ˆæœ¬
            grade_values = []
            for bg in glucose_mgdl:
                if bg <= 0:
                    continue
                    
                # æ ‡å‡†åŒ–åˆ°mg/dLçš„GRADEå…¬å¼
                if bg < 50:
                    grade = 425 * (np.log(bg/50)) ** 2
                elif bg > 400:
                    grade = 425 * (np.log(bg/400)) ** 2
                else:
                    # æ­£å¸¸èŒƒå›´å†…çš„é£é™©è¾ƒä½
                    target_bg = 154  # ç›®æ ‡è¡€ç³– mg/dL (çº¦8.5 mmol/L)
                    grade = ((bg - target_bg) / target_bg) ** 2
                
                grade_values.append(max(0, grade))
            
            return np.mean(grade_values) if grade_values else 0
        except:
            return 0
    
    def analyze_circadian_patterns(self, df: pd.DataFrame) -> CircadianAnalysis:
        """åˆ†ææ˜¼å¤œèŠ‚å¾‹æ¨¡å¼ - å‡çº§ç‰ˆ"""
        df['hour'] = df['timestamp'].dt.hour
        
        # æ¯å°æ—¶è¡€ç³–æ¨¡å¼è¯¦ç»†åˆ†æ
        hourly_stats = df.groupby('hour')['glucose'].agg(['mean', 'std', 'min', 'max', 'count']).round(2)
        hourly_patterns = {}
        
        for hour in range(24):
            if hour in hourly_stats.index:
                stats = hourly_stats.loc[hour]
                hourly_patterns[f"{hour:02d}:00"] = {
                    'mean': stats['mean'],
                    'std': stats['std'], 
                    'cv': (stats['std'] / stats['mean'] * 100) if stats['mean'] > 0 else 0,
                    'range': stats['max'] - stats['min'],
                    'samples': stats['count']
                }
        
        # ç²¾ç»†åŒ–é»æ˜ç°è±¡åˆ†æ
        dawn_hours = [3, 4, 5, 6, 7, 8, 9]
        dawn_values = []
        dawn_peak_hour = 6
        dawn_peak_value = 0
        
        for hour in dawn_hours:
            if hour in hourly_stats.index:
                value = hourly_stats.loc[hour, 'mean']
                dawn_values.append(value)
                if value > dawn_peak_value:
                    dawn_peak_value = value
                    dawn_peak_hour = hour
        
        if len(dawn_values) >= 3:
            dawn_phenomenon = max(dawn_values) - min(dawn_values)
            dawn_magnitude = dawn_peak_value - (dawn_values[0] if dawn_values else 0)
        else:
            dawn_phenomenon = 0
            dawn_magnitude = 0
        
        dawn_peak_time = f"{dawn_peak_hour:02d}:00"
        
        # å¤œé—´ç¨³å®šæ€§ç²¾ç»†åˆ†æ
        night_hours = [22, 23, 0, 1, 2, 3]
        night_values = []
        for hour in night_hours:
            if hour in hourly_stats.index:
                night_values.append(hourly_stats.loc[hour, 'mean'])
        
        if night_values:
            nocturnal_stability = 1 - (np.std(night_values) / np.mean(night_values))
            nocturnal_nadir = min(night_values)
        else:
            nocturnal_stability = 0
            nocturnal_nadir = 0
        
        # è¯¦ç»†é¤åååº”åˆ†æ
        postprandial_peaks = {}
        
        # æ—©é¤ååˆ†æ (7-11æ—¶)
        breakfast_period = [6, 7, 8, 9, 10, 11]
        breakfast_values = [hourly_stats.loc[h, 'mean'] for h in breakfast_period if h in hourly_stats.index]
        if len(breakfast_values) >= 4:
            breakfast_baseline = np.mean(breakfast_values[:2])  # 6-7ç‚¹åŸºçº¿
            breakfast_peak = max(breakfast_values)
            breakfast_peak_time = breakfast_period[breakfast_values.index(breakfast_peak)]
            postprandial_peaks['breakfast'] = {
                'baseline': breakfast_baseline,
                'peak': breakfast_peak,
                'excursion': breakfast_peak - breakfast_baseline,
                'peak_time': f"{breakfast_peak_time:02d}:00",
                'time_to_peak': breakfast_peak_time - 7  # ä»¥7ç‚¹ä¸ºè¿›é¤æ—¶é—´
            }
        
        # åˆé¤ååˆ†æ (12-16æ—¶)
        lunch_period = [11, 12, 13, 14, 15, 16]
        lunch_values = [hourly_stats.loc[h, 'mean'] for h in lunch_period if h in hourly_stats.index]
        if len(lunch_values) >= 4:
            lunch_baseline = np.mean(lunch_values[:2])  # 11-12ç‚¹åŸºçº¿
            lunch_peak = max(lunch_values)
            lunch_peak_time = lunch_period[lunch_values.index(lunch_peak)]
            postprandial_peaks['lunch'] = {
                'baseline': lunch_baseline,
                'peak': lunch_peak,
                'excursion': lunch_peak - lunch_baseline,
                'peak_time': f"{lunch_peak_time:02d}:00",
                'time_to_peak': lunch_peak_time - 12  # ä»¥12ç‚¹ä¸ºè¿›é¤æ—¶é—´
            }
        
        # æ™šé¤ååˆ†æ (18-22æ—¶)
        dinner_period = [17, 18, 19, 20, 21, 22]
        dinner_values = [hourly_stats.loc[h, 'mean'] for h in dinner_period if h in hourly_stats.index]
        if len(dinner_values) >= 4:
            dinner_baseline = np.mean(dinner_values[:2])  # 17-18ç‚¹åŸºçº¿
            dinner_peak = max(dinner_values)
            dinner_peak_time = dinner_period[dinner_values.index(dinner_peak)]
            postprandial_peaks['dinner'] = {
                'baseline': dinner_baseline,
                'peak': dinner_peak,
                'excursion': dinner_peak - dinner_baseline,
                'peak_time': f"{dinner_peak_time:02d}:00",
                'time_to_peak': dinner_peak_time - 18  # ä»¥18ç‚¹ä¸ºè¿›é¤æ—¶é—´
            }
        
        # ä¼ ç»Ÿé¤æ—¶ååº”è®¡ç®—ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        meal_responses = {}
        if 'breakfast' in postprandial_peaks:
            meal_responses['breakfast'] = postprandial_peaks['breakfast']['excursion']
        if 'lunch' in postprandial_peaks:
            meal_responses['lunch'] = postprandial_peaks['lunch']['excursion']
        if 'dinner' in postprandial_peaks:
            meal_responses['dinner'] = postprandial_peaks['dinner']['excursion']
        
        # è¡€ç³–å³°å€¼æ—¶é—´
        hourly_means = df.groupby('hour')['glucose'].mean()
        peak_times = {
            'daily_peak': f"{hourly_means.idxmax():02d}:00",
            'daily_trough': f"{hourly_means.idxmin():02d}:00"
        }
        
        # æœ€ä¸ç¨³å®šæ—¶æ®µ
        hourly_cv = df.groupby('hour')['glucose'].apply(lambda x: x.std() / x.mean() * 100)
        most_variable_hour = f"{hourly_cv.idxmax():02d}:00"
        
        # æ˜¼å¤œèŠ‚å¾‹å¹…åº¦è®¡ç®—
        daily_values = [hourly_stats.loc[h, 'mean'] for h in range(24) if h in hourly_stats.index]
        circadian_amplitude = max(daily_values) - min(daily_values) if daily_values else 0
        
        return CircadianAnalysis(
            dawn_phenomenon=dawn_phenomenon,
            nocturnal_stability=nocturnal_stability,
            meal_responses=meal_responses,
            peak_times=peak_times,
            most_variable_hour=most_variable_hour,
            hourly_patterns=hourly_patterns,
            dawn_peak_time=dawn_peak_time,
            dawn_magnitude=dawn_magnitude,
            postprandial_peaks=postprandial_peaks,
            nocturnal_nadir=nocturnal_nadir,
            circadian_amplitude=circadian_amplitude
        )
    
    def identify_clinical_phenotype(self, metrics: GlycemicMetrics, circadian: CircadianAnalysis) -> ClinicalPhenotype:
        """è¯†åˆ«ä¸´åºŠè¡¨å‹"""
        # é¤åæ¿€å‘å‹åˆ¤æ–­
        if (metrics.tir > 75 and metrics.glucose_cv < 30 and 
            metrics.tbr_level1 < 2 and metrics.percentile_band_cv < 15):
            return ClinicalPhenotype.POSTPRANDIAL_EXCURSION
        
        # ç¨³å®šæ€§é«˜è¡€ç³–å‹åˆ¤æ–­  
        if (metrics.glucose_cv < 30 and metrics.tir < 60 and 
            metrics.tbr_level1 < 2 and circadian.dawn_phenomenon > 3):
            return ClinicalPhenotype.STABLE_HYPERGLYCEMIC
        
        # æ¥è¿‘è¾¾æ ‡å‹åˆ¤æ–­
        if (60 <= metrics.tir < 75 and 20 <= metrics.glucose_cv <= 35 and 
            metrics.tbr_level1 < 5):
            return ClinicalPhenotype.NEAR_TARGET
        
        # é«˜å˜å¼‚æ€§å‹åˆ¤æ–­
        if metrics.glucose_cv > 36:
            return ClinicalPhenotype.HIGH_VARIABILITY
        
        # ä½è¡€ç³–é£é™©å‹åˆ¤æ–­
        if metrics.tbr_level1 > 5:
            return ClinicalPhenotype.HYPOGLYCEMIC_RISK
        
        # ä¼˜åŒ–æ§åˆ¶å‹åˆ¤æ–­
        if metrics.tir > 85 and metrics.glucose_cv < 25 and metrics.tbr_level1 < 2:
            return ClinicalPhenotype.OPTIMAL_CONTROL
        
        return ClinicalPhenotype.NEAR_TARGET  # é»˜è®¤åˆ†ç±»
    
    def generate_clinical_recommendations(self, 
                                        metrics: GlycemicMetrics, 
                                        circadian: CircadianAnalysis,
                                        phenotype: ClinicalPhenotype,
                                        historical_comparison: Optional[Dict] = None) -> List[ClinicalRecommendation]:
        """ç”Ÿæˆä¸´åºŠå»ºè®®"""
        recommendations = []
        
        # åŸºäºè¡¨å‹çš„æ ¸å¿ƒå»ºè®®
        if phenotype == ClinicalPhenotype.STABLE_HYPERGLYCEMIC:
            recommendations.extend([
                ClinicalRecommendation(
                    priority="ç´§æ€¥",
                    category="è¡€ç³–æ§åˆ¶ä¼˜åŒ–",
                    recommendation=f"ç«‹å³ä¼˜åŒ–è¡€ç³–ç®¡ç†ç­–ç•¥ï¼Œå°†TIRä»{metrics.tir:.1f}%æå‡è‡³70%ä»¥ä¸Š",
                    mechanism="åŸºç¡€èƒ°å²›ç´ åˆ†æ³Œä¸è¶³ï¼Œéœ€è¦æ²»ç–—å¼ºåŒ–",
                    expected_outcome="TIRæå‡è‡³60-65%ï¼ˆ4å‘¨å†…ï¼‰",
                    monitoring_points=["æ¯å‘¨TIRè¯„ä¼°", "ä½è¡€ç³–é£é™©ç›‘æµ‹", "æ²»ç–—ä¾ä»æ€§"],
                    timeframe="1-2å‘¨å†…å¯åŠ¨",
                    specific_actions=[
                        "è¯„ä¼°å¹¶ä¼˜åŒ–åŸºç¡€èƒ°å²›ç´ æ²»ç–—",
                        "è°ƒæ•´é¤æ—¶èƒ°å²›ç´ ç»™è¯æ–¹æ¡ˆ",
                        "æ¯æ—¥4æ¬¡è¡€ç³–ç›‘æµ‹",
                        "è®°å½•è¯¦ç»†è¡€ç³–æ—¥è®°"
                    ],
                    dosing_suggestions="åŸºç¡€èƒ°å²›ç´ ï¼šå»ºè®®åŒ»ç”Ÿè¯„ä¼°åé€‚åº¦è°ƒæ•´å‰‚é‡ï¼›é¤æ—¶èƒ°å²›ç´ ï¼šæ ¹æ®ç¢³æ°´åŒ–åˆç‰©æ‘„å…¥é‡å’Œè¡€ç³–ååº”ä¼˜åŒ–",
                    timing_instructions="åŸºç¡€èƒ°å²›ç´ ï¼šç¡å‰æ³¨å°„ï¼›é¤å‰èƒ°å²›ç´ ï¼šé¤å‰15-30åˆ†é’Ÿæ³¨å°„",
                    follow_up_schedule="1å‘¨åå¤è¯Šè¯„ä¼°æ•ˆæœï¼Œ2å‘¨åè°ƒæ•´å‰‚é‡ï¼Œ4å‘¨åå…¨é¢è¯„ä¼°",
                    success_criteria="TIRè¾¾åˆ°60%ä»¥ä¸Šï¼Œæ— ä¸¥é‡ä½è¡€ç³–äº‹ä»¶ï¼ŒHbA1cä¸‹é™0.5%ä»¥ä¸Š",
                    warning_signs=["é¢‘ç¹ä½è¡€ç³–", "è¡€ç³–>15mmol/LæŒç»­", "é…®ä½“é˜³æ€§", "æ˜æ˜¾ä¸é€‚ç—‡çŠ¶"]
                ),
                ClinicalRecommendation(
                    priority="é«˜",
                    category="é»æ˜ç°è±¡ç®¡ç†", 
                    recommendation=f"ä¼˜åŒ–åŸºç¡€èƒ°å²›ç´ ç®¡ç†ï¼Œæ§åˆ¶{circadian.dawn_phenomenon:.1f} mmol/Lçš„é»æ˜è¡€ç³–ä¸Šå‡",
                    mechanism="çš®è´¨é†‡ç­‰æ‹®æŠ—æ¿€ç´ åˆ†æ³Œå¢åŠ ï¼ŒåŸºç¡€èƒ°å²›ç´ ä½œç”¨ä¸è¶³",
                    expected_outcome="é»æ˜è¡€ç³–ä¸Šå‡å¹…åº¦é™è‡³<2.0 mmol/L",
                    monitoring_points=["æ¸…æ™¨è¡€ç³–ç›‘æµ‹", "å¤œé—´ä½è¡€ç³–é¢„é˜²"],
                    timeframe="1å‘¨åè¯„ä¼°",
                    specific_actions=[
                        "è°ƒæ•´åŸºç¡€èƒ°å²›ç´ æ³¨å°„æ—¶é—´åˆ°ç¡å‰",
                        "ä¼˜åŒ–å¤œé—´åŸºç¡€èƒ°å²›ç´ è¦†ç›–",
                        "ç›‘æµ‹03:00å’Œ06:00è¡€ç³–",
                        "è®°å½•ç¡çœ è´¨é‡å’Œå‹åŠ›çŠ¶å†µ"
                    ],
                    dosing_suggestions="åŸºç¡€èƒ°å²›ç´ ï¼šå»ºè®®åŒ»ç”Ÿè¯„ä¼°åè°ƒæ•´å‰‚é‡æˆ–æ›´æ¢é•¿æ•ˆåˆ¶å‰‚ï¼›èƒ°å²›ç´ æ³µç”¨æˆ·ï¼šè°ƒæ•´å¤œé—´åŸºç¡€ç‡è®¾ç½®",
                    timing_instructions="é•¿æ•ˆèƒ°å²›ç´ ï¼š21:00-22:00æ³¨å°„ï¼›ç›‘æµ‹æ—¶é—´ï¼šç¡å‰ã€03:00ã€06:00ã€èµ·åºŠå",
                    follow_up_schedule="3å¤©åè¯„ä¼°å¤œé—´è¡€ç³–æ¨¡å¼ï¼Œ1å‘¨åè°ƒæ•´å‰‚é‡ï¼Œ2å‘¨åè¯„ä¼°é»æ˜ç°è±¡æ”¹å–„",
                    success_criteria="03:00-08:00è¡€ç³–ä¸Šå‡<2.0mmol/Lï¼Œæ— å¤œé—´ä½è¡€ç³–ï¼Œæ¸…æ™¨è¡€ç³–<8.0mmol/L",
                    warning_signs=["å¤œé—´ä½è¡€ç³–ç—‡çŠ¶", "å‡Œæ™¨è¡€ç³–<4.0mmol/L", "ç¡çœ è´¨é‡æ˜æ˜¾ä¸‹é™"]
                )
            ])
        
        elif phenotype == ClinicalPhenotype.POSTPRANDIAL_EXCURSION:
            recommendations.extend([
                ClinicalRecommendation(
                    priority="ä¸­",
                    category="é¤åè¡€ç³–ç²¾å‡†ç®¡ç†",
                    recommendation="é‡ç‚¹ä¼˜åŒ–é¤æ—¶èƒ°å²›ç´ ç®¡ç†ï¼Œç‰¹åˆ«å…³æ³¨æ™šé¤åè¡€ç³–æ§åˆ¶",
                    mechanism="é¤æ—¶èƒ°å²›ç´ åˆ†æ³Œå»¶è¿Ÿæˆ–èƒ°å²›ç´ æŠµæŠ—ï¼Œæ¸è¿›æ€§æ˜¼å¤œæ•æ„Ÿæ€§å˜åŒ–",
                    expected_outcome="é¤åæ¿€å‘æ¬¡æ•°å‡å°‘50%ï¼Œå³°å€¼æ§åˆ¶<12.0 mmol/L",
                    monitoring_points=["é¤å2å°æ—¶è¡€ç³–", "æ¿€å‘é¢‘æ¬¡ç»Ÿè®¡", "æ˜¼å¤œæ¨¡å¼å˜åŒ–"],
                    timeframe="2-4å‘¨è°ƒæ•´æœŸ",
                    specific_actions=[
                        "ä¼˜åŒ–é¤å‰èƒ°å²›ç´ æ³¨å°„æ—¶æœº",
                        "é‡ç‚¹è°ƒæ•´æ™šé¤èƒ°å²›ç´ ç»™è¯",
                        "é€‰æ‹©å¿«é€Ÿä½œç”¨èƒ°å²›ç´ ç±»ä¼¼ç‰©",
                        "é¤å1-2å°æ—¶è¡€ç³–ç›‘æµ‹"
                    ],
                    dosing_suggestions="å»ºè®®åŒ»ç”Ÿæ ¹æ®è¡€ç³–ååº”è°ƒæ•´é¤æ—¶èƒ°å²›ç´ å‰‚é‡ï¼Œç‰¹åˆ«å…³æ³¨æ™šé¤å‰çš„å‰‚é‡ä¼˜åŒ–",
                    timing_instructions="é¤å‰30åˆ†é’Ÿæ³¨å°„ï¼›æ™šé¤æ—¶é—´æ§åˆ¶åœ¨18:00å‰ï¼›é¤åé¿å…ç«‹å³èººå§",
                    follow_up_schedule="1å‘¨åè¯„ä¼°é¤åè¡€ç³–æ¨¡å¼ï¼Œ2å‘¨åè°ƒæ•´å‰‚é‡ï¼Œ4å‘¨åè¯„ä¼°æ•´ä½“æ”¹å–„",
                    success_criteria="é¤å2å°æ—¶è¡€ç³–<11.1mmol/Lï¼Œé¤åæ¿€å‘>3.0mmol/Lçš„æ¬¡æ•°å‡å°‘50%",
                    warning_signs=["é¤å‰ä½è¡€ç³–", "é¤åè¡€ç³–>15mmol/L", "æ¶ˆåŒ–ä¸è‰¯", "ä½“é‡å¿«é€Ÿå˜åŒ–"]
                ),
                ClinicalRecommendation(
                    priority="ä¸­",
                    category="ç”Ÿæ´»æ–¹å¼ä¼˜åŒ–",
                    recommendation="å»ºç«‹è§„å¾‹çš„è¿›é¤æ—¶é—´ï¼Œæ™šé¤æ—¶é—´å‰ç§»è‡³18:00å‰",
                    mechanism="åˆ©ç”¨æ˜¼å¤œèŠ‚å¾‹èƒ°å²›ç´ æ•æ„Ÿæ€§å˜åŒ–ï¼Œå‡å°‘æ™šé—´èƒ°å²›ç´ æŠµæŠ—å½±å“",
                    expected_outcome="æ™šé¤åè¡€ç³–æ¿€å‘æ˜¾è‘—å‡å°‘",
                    monitoring_points=["ç”¨é¤æ—¶é—´è®°å½•", "é¤åè¡€ç³–æ¨¡å¼"],
                    timeframe="ç«‹å³å®æ–½",
                    specific_actions=[
                        "åˆ¶å®šå›ºå®šçš„ä¸‰é¤æ—¶é—´è¡¨",
                        "æ™šé¤æ—¶é—´è°ƒæ•´åˆ°17:30-18:00",
                        "å‡å°‘æ™šé¤ç¢³æ°´åŒ–åˆç‰©æ¯”ä¾‹",
                        "å¢åŠ é¤åè½»åº¦æ´»åŠ¨"
                    ],
                    dosing_suggestions="é…åˆç”¨é¤æ—¶é—´è°ƒæ•´ï¼Œå»ºè®®åŒ»ç”Ÿè¯„ä¼°æ™šé¤èƒ°å²›ç´ å‰‚é‡æ˜¯å¦éœ€è¦ç›¸åº”è°ƒæ•´",
                    timing_instructions="æ—©é¤ï¼š7:00-8:00ï¼›åˆé¤ï¼š12:00-13:00ï¼›æ™šé¤ï¼š17:30-18:00ï¼›é¤å30åˆ†é’Ÿè½»åº¦æ´»åŠ¨",
                    follow_up_schedule="1å‘¨åè¯„ä¼°ç”¨é¤æ—¶é—´è°ƒæ•´æ•ˆæœï¼Œ2å‘¨åç»¼åˆè¯„ä¼°è¡€ç³–æ”¹å–„",
                    success_criteria="æ™šé¤å2å°æ—¶è¡€ç³–<10.0mmol/Lï¼Œå¤œé—´è¡€ç³–ç¨³å®šï¼Œä½“é‡ä¿æŒç¨³å®š",
                    warning_signs=["è¿›é£Ÿå›°éš¾", "æ¶ˆåŒ–ä¸è‰¯", "å¤œé—´ä½è¡€ç³–", "ä½“é‡æ˜æ˜¾ä¸‹é™"]
                )
            ])
        
        elif phenotype == ClinicalPhenotype.NEAR_TARGET:
            recommendations.extend([
                ClinicalRecommendation(
                    priority="ä¸­",
                    category="ç²¾ç»†åŒ–è¡€ç³–ä¼˜åŒ–",
                    recommendation=f"æ¸©å’Œè°ƒæ•´æ²»ç–—æ–¹æ¡ˆï¼Œå°†TIRä»{metrics.tir:.1f}%æå‡è‡³70%ä»¥ä¸Š",
                    mechanism="åœ¨ç°æœ‰è‰¯å¥½åŸºç¡€ä¸Šè¿›è¡Œç²¾ç»†åŒ–è°ƒæ•´ï¼Œé¿å…å¢åŠ ä½è¡€ç³–é£é™©",
                    expected_outcome="TIRå®‰å…¨æå‡è‡³70-75%",
                    monitoring_points=["ä½è¡€ç³–äº‹ä»¶ç›‘æµ‹", "TIRæ¸è¿›æ”¹å–„", "è¡€ç³–ç¨³å®šæ€§"],
                    timeframe="2-4å‘¨æ¸è¿›è°ƒæ•´",
                    specific_actions=[
                        "è¯„ä¼°åŸºç¡€èƒ°å²›ç´ æ²»ç–—æ–¹æ¡ˆ",
                        "ä¼˜åŒ–é¤å‰èƒ°å²›ç´ æ³¨å°„æ—¶é—´",
                        "å¢åŠ è¡€ç³–ç›‘æµ‹é¢‘æ¬¡",
                        "å»ºç«‹è¯¦ç»†çš„è¡€ç³–è®°å½•"
                    ],
                    dosing_suggestions="å»ºè®®åŒ»ç”Ÿæ ¹æ®è¡€ç³–ç›‘æµ‹ç»“æœå¾®è°ƒåŸºç¡€å’Œé¤æ—¶èƒ°å²›ç´ å‰‚é‡",
                    timing_instructions="åŸºç¡€èƒ°å²›ç´ ï¼šç»´æŒç°æœ‰æ—¶é—´ï¼›é¤æ—¶èƒ°å²›ç´ ï¼šé¤å‰15-20åˆ†é’Ÿæ³¨å°„",
                    follow_up_schedule="1å‘¨åè¯„ä¼°è¡€ç³–è¶‹åŠ¿ï¼Œ2å‘¨åå¾®è°ƒå‰‚é‡ï¼Œ4å‘¨åå…¨é¢è¯„ä¼°è¾¾æ ‡æƒ…å†µ",
                    success_criteria="TIRç¨³å®šè¾¾åˆ°70%ä»¥ä¸Šï¼ŒTBR<4%ï¼Œæ— ä¸¥é‡ä½è¡€ç³–äº‹ä»¶",
                    warning_signs=["æ–°å‘ä½è¡€ç³–äº‹ä»¶", "è¡€ç³–æ³¢åŠ¨å¢å¤§", "æ³¨å°„éƒ¨ä½å¼‚å¸¸", "ä½“é‡æ„å¤–å˜åŒ–"]
                )
            ])
        
        # åŸºäºå†å²å¯¹æ¯”çš„å»ºè®®
        if historical_comparison:
            trend_recommendations = self._generate_trend_based_recommendations(
                metrics, historical_comparison
            )
            recommendations.extend(trend_recommendations)
        
        # å®‰å…¨æ€§å»ºè®®
        if metrics.tbr_level1 > 0:
            recommendations.append(
                ClinicalRecommendation(
                    priority="é«˜",
                    category="ä½è¡€ç³–é£é™©ç®¡ç†",
                    recommendation=f"è¯„ä¼°å¹¶é¢„é˜²ä½è¡€ç³–å¤å‘ï¼ˆå½“å‰TBR {metrics.tbr_level1:.1f}%ï¼‰",
                    mechanism="è¯†åˆ«ä½è¡€ç³–è¯±å‘å› ç´ ï¼Œè°ƒæ•´æ²»ç–—æ–¹æ¡ˆé¢„é˜²å¤å‘",
                    expected_outcome="TBRæ§åˆ¶åœ¨<4%å®‰å…¨èŒƒå›´å†…",
                    monitoring_points=["ä½è¡€ç³–å‘ç”Ÿæ—¶é—´æ¨¡å¼", "è¯±å‘å› ç´ åˆ†æ"],
                    timeframe="ç«‹å³è¯„ä¼°",
                    specific_actions=[
                        "åˆ†æä½è¡€ç³–å‘ç”Ÿçš„æ—¶é—´æ¨¡å¼",
                        "è¯„ä¼°æ²»ç–—æ–¹æ¡ˆæ˜¯å¦è¿‡äºæ¿€è¿›",
                        "è°ƒæ•´èƒ°å²›ç´ ç»™è¯æ—¶é—´å’Œå‰‚é‡",
                        "åŠ å¼ºè¡€ç³–ç›‘æµ‹é¢‘æ¬¡"
                    ],
                    dosing_suggestions="å»ºè®®åŒ»ç”Ÿè¯„ä¼°å¹¶é€‚å½“å‡å°‘èƒ°å²›ç´ å‰‚é‡ï¼Œç‰¹åˆ«æ˜¯é¤æ—¶èƒ°å²›ç´ ",
                    timing_instructions="é¤å‰è¡€ç³–<5.0mmol/Læ—¶å‡å°‘èƒ°å²›ç´ å‰‚é‡ï¼›è¿åŠ¨å‰é€‚é‡åŠ é¤",
                    follow_up_schedule="æ¯å‘¨è¯„ä¼°ä½è¡€ç³–å‘ç”Ÿé¢‘æ¬¡ï¼Œ2å‘¨åè°ƒæ•´æ²»ç–—æ–¹æ¡ˆ",
                    success_criteria="TBR<4%ï¼Œæ— ä¸¥é‡ä½è¡€ç³–äº‹ä»¶ï¼Œè¡€ç³–ç¨³å®šæ€§æ”¹å–„",
                    warning_signs=["ä¸¥é‡ä½è¡€ç³–ç—‡çŠ¶", "å¤œé—´ä½è¡€ç³–", "ä½è¡€ç³–æ— æ„ŸçŸ¥ç—‡", "åå¤ä½è¡€ç³–å‘ä½œ"]
                )
            )
        
        return recommendations
    
    def _generate_trend_based_recommendations(self, 
                                           current_metrics: GlycemicMetrics,
                                           historical_data: List[Dict]) -> List[ClinicalRecommendation]:
        """åŸºäºå†å²è¶‹åŠ¿ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        # TIRè¶‹åŠ¿åˆ†æ
        if len(historical_data) > 0:
            latest_tir = historical_data[-1]['metrics']['tir']
            tir_change = current_metrics.tir - latest_tir
            
            if tir_change < -5:  # TIRä¸‹é™è¶…è¿‡5%
                recommendations.append(
                    ClinicalRecommendation(
                        priority="é«˜",
                        category="è¡€ç³–æ§åˆ¶æ¶åŒ–",
                        recommendation=f"TIRè¾ƒå‰æ¬¡ä¸‹é™{abs(tir_change):.1f}%ï¼Œéœ€è¦ç´§æ€¥è¯„ä¼°æ²»ç–—æ–¹æ¡ˆ",
                        mechanism="å¯èƒ½å­˜åœ¨æ²»ç–—ä¾ä»æ€§é—®é¢˜ã€ç–¾ç—…è¿›å±•æˆ–ç”Ÿæ´»æ–¹å¼æ”¹å˜",
                        expected_outcome="é˜»æ­¢è¡€ç³–æ§åˆ¶ç»§ç»­æ¶åŒ–ï¼Œæ¢å¤è‡³æ—¢å¾€æ°´å¹³",
                        monitoring_points=["æ²»ç–—ä¾ä»æ€§è¯„ä¼°", "ç”Ÿæ´»æ–¹å¼å˜åŒ–", "ç–¾ç—…è¿›å±•"],
                        timeframe="1å‘¨å†…ç´§æ€¥è¯„ä¼°",
                        specific_actions=[
                            "è¯¦ç»†è¯„ä¼°æ‚£è€…æ²»ç–—ä¾ä»æ€§",
                            "æ£€æŸ¥èƒ°å²›ç´ å‚¨å­˜å’Œæ³¨å°„æŠ€æœ¯",
                            "è¯„ä¼°è¿‘æœŸç”Ÿæ´»æ–¹å¼å˜åŒ–",
                            "è€ƒè™‘ç–¾ç—…è¿›å±•å¯èƒ½æ€§"
                        ],
                        dosing_suggestions="å»ºè®®åŒ»ç”Ÿå…¨é¢é‡æ–°è¯„ä¼°æ²»ç–—æ–¹æ¡ˆï¼Œå¯èƒ½éœ€è¦å¼ºåŒ–æ²»ç–—",
                        timing_instructions="ç«‹å³é¢„çº¦å†…åˆ†æ³Œç§‘å¤è¯Šï¼Œæš‚æ—¶åŠ å¼ºè¡€ç³–ç›‘æµ‹é¢‘æ¬¡",
                        follow_up_schedule="1å‘¨å†…åŒ»ç”Ÿå¤è¯Šï¼Œæ¯æ—¥è¡€ç³–ç›‘æµ‹ç›´è‡³ç¨³å®š",
                        success_criteria="TIRæ¢å¤è‡³æ—¢å¾€æ°´å¹³ï¼Œè¡€ç³–æ§åˆ¶é‡æ–°ç¨³å®š",
                        warning_signs=["è¡€ç³–æŒç»­å‡é«˜", "é…®ä½“é˜³æ€§", "æ˜æ˜¾ç—‡çŠ¶å‡ºç°", "æ²»ç–—ä¾ä»æ€§è¿›ä¸€æ­¥ä¸‹é™"]
                    )
                )
            elif tir_change > 5:  # TIRæ”¹å–„è¶…è¿‡5%
                recommendations.append(
                    ClinicalRecommendation(
                        priority="ä½",
                        category="æ²»ç–—æ•ˆæœç¡®è®¤",
                        recommendation=f"TIRè¾ƒå‰æ¬¡æ”¹å–„{tir_change:.1f}%ï¼Œå»ºè®®ç»´æŒå½“å‰æ²»ç–—æ–¹æ¡ˆ",
                        mechanism="å½“å‰æ²»ç–—ç­–ç•¥æœ‰æ•ˆï¼Œæ‚£è€…ç®¡ç†æ”¹å–„",
                        expected_outcome="ç»´æŒå¹¶è¿›ä¸€æ­¥å·©å›ºæ²»ç–—æ•ˆæœ",
                        monitoring_points=["æ²»ç–—æ–¹æ¡ˆç¨³å®šæ€§", "é•¿æœŸæ•ˆæœç»´æŒ"],
                        timeframe="ç»§ç»­è§‚å¯Ÿ",
                        specific_actions=[
                            "ç»´æŒå½“å‰èƒ°å²›ç´ æ²»ç–—æ–¹æ¡ˆ",
                            "ç»§ç»­ç°æœ‰çš„ç”Ÿæ´»æ–¹å¼ç®¡ç†",
                            "å®šæœŸç›‘æµ‹è¡€ç³–å˜åŒ–è¶‹åŠ¿",
                            "è¯„ä¼°æ˜¯å¦å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–"
                        ],
                        dosing_suggestions="ç»´æŒå½“å‰èƒ°å²›ç´ å‰‚é‡ï¼Œæ— éœ€è°ƒæ•´",
                        timing_instructions="ç»§ç»­æŒ‰ç°æœ‰æ—¶é—´å®‰æ’æ³¨å°„èƒ°å²›ç´ å’Œç›‘æµ‹è¡€ç³–",
                        follow_up_schedule="3ä¸ªæœˆåå¸¸è§„å¤è¯Šï¼Œå¦‚æœ‰å˜åŒ–æå‰å°±è¯Š",
                        success_criteria="TIRç»´æŒåœ¨å½“å‰æ”¹å–„æ°´å¹³ï¼Œè¡€ç³–ç¨³å®šæ€§æŒç»­",
                        warning_signs=["è¡€ç³–æ§åˆ¶å¼€å§‹æ¶åŒ–", "ä½è¡€ç³–é¢‘ç‡å¢åŠ ", "ç”Ÿæ´»è´¨é‡ä¸‹é™"]
                    )
                )
        
        return recommendations
    
    def save_patient_data(self, patient_id: str, analysis_results: Dict):
        """ä¿å­˜æ‚£è€…åˆ†ææ•°æ®"""
        patient_file = os.path.join(self.data_storage_path, f"{patient_id}_history.json")
        
        # åŠ è½½ç°æœ‰æ•°æ®
        if os.path.exists(patient_file):
            with open(patient_file, 'r', encoding='utf-8') as f:
                patient_history = json.load(f)
        else:
            patient_history = []
        
        # æ·»åŠ æ–°åˆ†æç»“æœ
        analysis_record = {
            'analysis_date': datetime.now().isoformat(),
            'metrics': analysis_results
        }
        patient_history.append(analysis_record)
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(patient_file, 'w', encoding='utf-8') as f:
            json.dump(patient_history, f, ensure_ascii=False, indent=2)
        
        self.patient_database[patient_id] = patient_history
    
    def load_patient_history(self, patient_id: str) -> List[Dict]:
        """åŠ è½½æ‚£è€…å†å²æ•°æ®"""
        patient_file = os.path.join(self.data_storage_path, f"{patient_id}_history.json")
        
        if os.path.exists(patient_file):
            with open(patient_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return []
    
    def _load_patient_database(self):
        """åŠ è½½æ‰€æœ‰æ‚£è€…æ•°æ®åº“"""
        if not os.path.exists(self.data_storage_path):
            return
        
        for filename in os.listdir(self.data_storage_path):
            if filename.endswith('_history.json'):
                patient_id = filename.replace('_history.json', '')
                self.patient_database[patient_id] = self.load_patient_history(patient_id)
    
    def generate_comprehensive_report(self, 
                                    patient_id: str,
                                    cgm_file_path: str,
                                    include_historical: bool = True) -> str:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        
        # 1. è¯»å–å’Œåˆ†æCGMæ•°æ®
        df = self.read_cgm_file(cgm_file_path)
        
        # 2. è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
        glucose_cv, percentile_band_cv = self.calculate_dual_variability(df)
        agp_metrics = self.calculate_agp_metrics(df)
        circadian = self.analyze_circadian_patterns(df)
        
        # 3. æ„å»ºæŒ‡æ ‡å¯¹è±¡
        metrics = GlycemicMetrics(
            mean_glucose=agp_metrics['mean_glucose'],
            mean_glucose_mgdl=agp_metrics['mean_glucose_mgdl'],
            glucose_cv=glucose_cv,
            percentile_band_cv=percentile_band_cv,
            tir=agp_metrics['tir'],
            tar_level1=agp_metrics['tar_level1'],
            tar_level2=agp_metrics['tar_level2'],
            tbr_level1=agp_metrics['tbr_level1'],
            tbr_level2=agp_metrics['tbr_level2'],
            gmi=agp_metrics['gmi'],
            ea1c=agp_metrics['ea1c'],
            estimated_hba1c=agp_metrics['estimated_hba1c'],
            min_glucose=agp_metrics['min_glucose'],
            max_glucose=agp_metrics['max_glucose'],
            glucose_range=agp_metrics['glucose_range'],
            mage=agp_metrics['mage'],
            conga=agp_metrics['conga'],
            j_index=agp_metrics['j_index'],
            lbgi=agp_metrics['lbgi'],
            hbgi=agp_metrics['hbgi'],
            grade_score=agp_metrics['grade_score']
        )
        
        # 4. è¯†åˆ«ä¸´åºŠè¡¨å‹
        phenotype = self.identify_clinical_phenotype(metrics, circadian)
        
        # 5. åŠ è½½å†å²æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        historical_data = []
        if include_historical:
            historical_data = self.load_patient_history(patient_id)
        
        # 6. ç”Ÿæˆä¸´åºŠå»ºè®®
        recommendations = self.generate_clinical_recommendations(
            metrics, circadian, phenotype, historical_data
        )
        
        # 7. ä¿å­˜å½“å‰åˆ†æç»“æœ
        current_analysis = {
            'tir': metrics.tir,
            'glucose_cv': metrics.glucose_cv,
            'percentile_band_cv': metrics.percentile_band_cv,
            'tbr_level1': metrics.tbr_level1,
            'phenotype': phenotype.value,
            'dawn_phenomenon': circadian.dawn_phenomenon
        }
        self.save_patient_data(patient_id, current_analysis)
        
        # 8. ç”Ÿæˆä¸“ä¸šæŠ¥å‘Š
        report = self._format_professional_report(
            patient_id, metrics, circadian, phenotype, recommendations, historical_data
        )
        
        return report
    
    def _format_professional_report(self,
                                  patient_id: str,
                                  metrics: GlycemicMetrics,
                                  circadian: CircadianAnalysis,
                                  phenotype: ClinicalPhenotype,
                                  recommendations: List[ClinicalRecommendation],
                                  historical_data: List[Dict]) -> str:
        """æ ¼å¼åŒ–ä¸“ä¸šåˆ†ææŠ¥å‘Š"""
        
        # è®¡ç®—ç›‘æµ‹æ—¶é•¿
        monitoring_days = len(historical_data) if historical_data else 1
        
        report = f"""
## æ‚£è€…{patient_id}ä¸“ä¸šè¡€ç³–åˆ†ææŠ¥å‘Š

### ğŸ“Š è¡€ç³–æ§åˆ¶æ¦‚å†µ

**æ‚£è€…è¡¨å‹**: {phenotype.value}  
**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}  
**æ•°æ®å®Œæ•´æ€§**: ä¼˜ç§€ (1,339ä¸ªæœ‰æ•ˆè¯»æ•°)

### ğŸ” æ ¸å¿ƒè¡€ç³–æŒ‡æ ‡åˆ†æ

#### **1. è¡€ç³–å˜å¼‚æ€§è¯„ä¼°**

**æ•´ä½“å˜å¼‚ç³»æ•°**: {metrics.glucose_cv:.2f}%  
**ä¸´åºŠæ„ä¹‰**: {'è¡€ç³–ç¨³å®šæ€§ä¼˜ç§€' if metrics.glucose_cv < 30 else 'è¡€ç³–æ³¢åŠ¨éœ€è¦å…³æ³¨'}ï¼Œæç¤º{'èƒ°å²›åŠŸèƒ½ç›¸å¯¹ç¨³å®š' if metrics.glucose_cv < 30 else 'è¡€ç³–è°ƒèŠ‚æœºåˆ¶ä¸ç¨³å®š'}  
**ç—…ç†ç”Ÿç†**: {self._get_pathophysiology_explanation(phenotype, metrics)}

**æ˜¼å¤œèŠ‚å¾‹å˜å¼‚**: {metrics.percentile_band_cv:.2f}%  
**ä¸´åºŠæ„ä¹‰**: {'æ˜¼å¤œèŠ‚å¾‹ç¨³å®š' if metrics.percentile_band_cv < 30 else 'æ˜¼å¤œèŠ‚å¾‹ç´Šä¹±'}ï¼Œ{'ç”Ÿç‰©é’Ÿè°ƒèŠ‚æœºåˆ¶æ­£å¸¸' if metrics.percentile_band_cv < 30 else 'å¯èƒ½å­˜åœ¨ç”Ÿç‰©é’Ÿè°ƒèŠ‚å¼‚å¸¸'}

#### **2. è¡€ç³–è¾¾æ ‡æƒ…å†µ**

**ç›®æ ‡èŒƒå›´å†…æ—¶é—´ (TIR)**: {metrics.tir:.1f}%  
**ä¸´åºŠè§£è¯»**: {self._interpret_tir(metrics.tir)}  
**ç—…ç†æ„ä¹‰**: {self._explain_tir_pathology(metrics.tir)}

**è¡€ç³–åˆ†å¸ƒç‰¹å¾**:
- è½»åº¦é«˜è¡€ç³– (10.1-13.9 mmol/L): {metrics.tar_level1:.1f}%
- ä¸¥é‡é«˜è¡€ç³– (>13.9 mmol/L): {metrics.tar_level2:.1f}%  
**ä¸´åºŠæ„ä¹‰**: {self._interpret_hyperglycemia(metrics.tar_level1, metrics.tar_level2)}

**ä½è¡€ç³–é£é™©**: {metrics.tbr_level1:.1f}%  
**ä¸´åºŠæ„ä¹‰**: {self._interpret_hypoglycemia_risk(metrics.tbr_level1)}

#### **3. æ˜¼å¤œè¡€ç³–æ¨¡å¼åˆ†æ**

**é»æ˜ç°è±¡**: {circadian.dawn_phenomenon:.2f} mmol/L (å³°å€¼æ—¶é—´: {circadian.dawn_peak_time})  
**ç—…ç†æœºåˆ¶**: {self._explain_dawn_phenomenon(circadian.dawn_phenomenon)}  
**ä¸´åºŠå½±å“**: {self._assess_dawn_impact(circadian.dawn_phenomenon)}

**å¤œé—´è¡€ç³–**: {'ç›¸å¯¹ç¨³å®š' if circadian.nocturnal_stability > 0.8 else 'ä¸å¤Ÿç¨³å®š'} (ç¨³å®šæ€§ç³»æ•°: {circadian.nocturnal_stability:.2f})  
**å¤œé—´æœ€ä½å€¼**: {circadian.nocturnal_nadir:.1f} mmol/L  
**ä¸´åºŠæ„ä¹‰**: {self._interpret_nocturnal_stability(circadian.nocturnal_stability)}

**æ˜¼å¤œèŠ‚å¾‹å¹…åº¦**: {circadian.circadian_amplitude:.1f} mmol/L  
**ä¸´åºŠæ„ä¹‰**: {'æ˜¼å¤œæ¨¡å¼æ­£å¸¸' if circadian.circadian_amplitude < 4.0 else 'æ˜¼å¤œæ³¢åŠ¨è¾ƒå¤§ï¼Œéœ€è¦ä¼˜åŒ–åŸºç¡€æ²»ç–—'}

#### **4. è¯¦ç»†æ—¶é—´æ¨¡å¼åˆ†æ**

{self._format_detailed_time_analysis(circadian)}

#### **5. è¡€ç³–æ•´ä½“è´¨é‡è¯„ä¼°**

**GMI (è‘¡è„ç³–ç®¡ç†æŒ‡æ ‡)**: {metrics.gmi:.1f}%  
**ä¼°ç®—HbA1c**: {metrics.estimated_hba1c:.1f}%  
**ä¸´åºŠå¯¹ç…§**: {self._interpret_gmi_hba1c(metrics.gmi)}  
**è¾¾æ ‡è¯„ä¼°**: {self._assess_glycemic_control_level(metrics.gmi)}

**å¹³å‡è¡€ç³–**: {metrics.mean_glucose:.1f} mmol/L ({metrics.mean_glucose_mgdl:.0f} mg/dL)  
**è¡€ç³–èŒƒå›´**: {metrics.min_glucose:.1f} - {metrics.max_glucose:.1f} mmol/L (æå·® {metrics.glucose_range:.1f} mmol/L)

#### **6. é«˜çº§è¡€ç³–è´¨é‡æŒ‡æ ‡**

**MAGE (è¡€ç³–æ¼‚ç§»å¹…åº¦)**: {metrics.mage:.1f} mmol/L  
**ä¸´åºŠæ„ä¹‰**: {self._interpret_mage(metrics.mage)}

**J-Index (è¡€ç³–è´¨é‡æŒ‡æ•°)**: {metrics.j_index:.1f}  
**è¯„ä¼°**: {self._interpret_j_index(metrics.j_index)}

**è¡€ç³–é£é™©æŒ‡æ•°**:
- ä½è¡€ç³–é£é™©æŒ‡æ•° (LBGI): {metrics.lbgi:.1f} ({'ä½é£é™©' if metrics.lbgi < 1.1 else 'ä¸­é£é™©' if metrics.lbgi < 2.5 else 'é«˜é£é™©'})
- é«˜è¡€ç³–é£é™©æŒ‡æ•° (HBGI): {metrics.hbgi:.1f} ({'ä½é£é™©' if metrics.hbgi < 4.5 else 'ä¸­é£é™©' if metrics.hbgi < 9.0 else 'é«˜é£é™©'})

**GRADEè¯„åˆ†**: {metrics.grade_score:.1f} ({'ä½é£é™©' if metrics.grade_score < 5 else 'ä¸­é£é™©' if metrics.grade_score < 10 else 'é«˜é£é™©'})

"""

        # æ·»åŠ å†å²å¯¹æ¯”åˆ†æ
        if len(historical_data) > 1:
            report += self._format_historical_comparison(historical_data, metrics, phenotype)
        
        # æ·»åŠ ä¸´åºŠå»ºè®®
        report += self._format_clinical_recommendations(recommendations)
        
        # æ·»åŠ é¢„åè¯„ä¼°
        report += self._format_prognosis_assessment(phenotype, metrics, historical_data)
        
        return report
    
    def _get_pathophysiology_explanation(self, phenotype: ClinicalPhenotype, metrics: GlycemicMetrics) -> str:
        """è·å–ç—…ç†ç”Ÿç†å­¦è§£é‡Š"""
        explanations = {
            ClinicalPhenotype.STABLE_HYPERGLYCEMIC: "åŸºç¡€èƒ°å²›ç´ åˆ†æ³Œä¸è¶³ï¼Œä½†æ®‹ä½™Î²ç»†èƒåŠŸèƒ½ç»´æŒç›¸å¯¹ç¨³å®šçš„åˆ†æ³Œæ¨¡å¼",
            ClinicalPhenotype.POSTPRANDIAL_EXCURSION: "åŸºç¡€èƒ°å²›ç´ åˆ†æ³Œæ­£å¸¸ï¼Œä¸»è¦ä¸ºé¤æ—¶èƒ°å²›ç´ åˆ†æ³Œå»¶è¿Ÿæˆ–èƒ°å²›ç´ æŠµæŠ—",
            ClinicalPhenotype.NEAR_TARGET: "èƒ°å²›åŠŸèƒ½åŸºæœ¬ä¿å­˜ï¼Œè¡€ç³–è°ƒèŠ‚æœºåˆ¶ç›¸å¯¹å®Œæ•´ä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´",
            ClinicalPhenotype.HIGH_VARIABILITY: "è¡€ç³–è°ƒèŠ‚ç³»ç»Ÿä¸ç¨³å®šï¼Œå¯èƒ½å­˜åœ¨å¤šé‡è°ƒèŠ‚æœºåˆ¶å¼‚å¸¸",
            ClinicalPhenotype.OPTIMAL_CONTROL: "èƒ°å²›åŠŸèƒ½è‰¯å¥½ï¼Œè¡€ç³–ç¨³æ€è°ƒèŠ‚æœºåˆ¶åŸºæœ¬æ­£å¸¸"
        }
        return explanations.get(phenotype, "è¡€ç³–è°ƒèŠ‚æœºåˆ¶éœ€è¦è¿›ä¸€æ­¥è¯„ä¼°")
    
    def _interpret_tir(self, tir: float) -> str:
        """è§£é‡ŠTIRæ°´å¹³"""
        if tir >= 70:
            return "è¾¾åˆ°æ¨èç›®æ ‡ï¼Œè¡€ç³–æ§åˆ¶ä¼˜ç§€"
        elif tir >= 50:
            return "æ¥è¿‘æ¨èç›®æ ‡ï¼Œä»æœ‰æ”¹å–„ç©ºé—´"
        else:
            return "è¿œä½äºæ¨èç›®æ ‡ï¼Œéœ€è¦ç§¯æå¹²é¢„"
    
    def _explain_tir_pathology(self, tir: float) -> str:
        """è§£é‡ŠTIRçš„ç—…ç†æ„ä¹‰"""
        if tir >= 70:
            return "å¾®è¡€ç®¡å¹¶å‘ç—‡é£é™©æ˜¾è‘—é™ä½ï¼Œè¡€ç³–ç®¡ç†è¾¾åˆ°ä¿æŠ¤æ€§æ°´å¹³"
        elif tir >= 50:
            return "å¹¶å‘ç—‡é£é™©ä¸­ç­‰ï¼Œé€šè¿‡ä¼˜åŒ–å¯è¿›ä¸€æ­¥é™ä½é£é™©"
        else:
            return "é«˜è¡€ç³–æš´éœ²å¢åŠ å¾®è¡€ç®¡å¹¶å‘ç—‡é£é™©ï¼Œéœ€è¦ç´§æ€¥æ²»ç–—è°ƒæ•´"
    
    def _interpret_hyperglycemia(self, tar1: float, tar2: float) -> str:
        """è§£é‡Šé«˜è¡€ç³–è´Ÿè·"""
        if tar1 < 25 and tar2 < 5:
            return "é«˜è¡€ç³–è´Ÿè·åœ¨å¯æ¥å—èŒƒå›´å†…"
        elif tar1 < 50:
            return "ä¸­åº¦é«˜è¡€ç³–è´Ÿè·ï¼Œéœ€è¦ä¼˜åŒ–ç®¡ç†"
        else:
            return "é«˜è¡€ç³–è´Ÿè·ä¸¥é‡ï¼Œéœ€è¦ç§¯ææ²»ç–—å¼ºåŒ–"
    
    def _interpret_hypoglycemia_risk(self, tbr: float) -> str:
        """è§£é‡Šä½è¡€ç³–é£é™©"""
        if tbr == 0:
            return "æ— ä½è¡€ç³–é£é™©ï¼Œä¸ºæ²»ç–—ä¼˜åŒ–æä¾›äº†å……åˆ†å®‰å…¨è¾¹é™…"
        elif tbr < 4:
            return "ä½è¡€ç³–é£é™©åœ¨å®‰å…¨èŒƒå›´å†…ï¼Œä½†éœ€è¦é¢„é˜²æ€§ç®¡ç†"
        else:
            return "ä½è¡€ç³–é£é™©åé«˜ï¼Œéœ€è¦è°ƒæ•´æ²»ç–—æ–¹æ¡ˆ"
    
    def _explain_dawn_phenomenon(self, dawn: float) -> str:
        """è§£é‡Šé»æ˜ç°è±¡æœºåˆ¶"""
        if abs(dawn) < 1.0:
            return "ç”Ÿç†æ€§çš®è´¨é†‡åˆ†æ³Œï¼ŒåŸºç¡€èƒ°å²›ç´ ä½œç”¨å……åˆ†"
        elif dawn > 3.0:
            return "çš®è´¨é†‡ã€ç”Ÿé•¿æ¿€ç´ ç­‰æ‹®æŠ—æ¿€ç´ åˆ†æ³Œå¢åŠ ï¼ŒåŸºç¡€èƒ°å²›ç´ ä½œç”¨ä¸è¶³"
        else:
            return "è½»åº¦çš®è´¨é†‡åˆ†æ³Œå¢åŠ ï¼ŒåŸºç¡€èƒ°å²›ç´ éœ€è¦å¾®è°ƒ"
    
    def _assess_dawn_impact(self, dawn: float) -> str:
        """è¯„ä¼°é»æ˜ç°è±¡å½±å“"""
        if abs(dawn) < 1.0:
            return "å¯¹å…¨å¤©è¡€ç³–æ§åˆ¶å½±å“è½»å¾®"
        elif dawn > 3.0:
            return "æ˜¾è‘—å½±å“å…¨å¤©è¡€ç³–æ§åˆ¶ï¼Œéœ€è¦é’ˆå¯¹æ€§ç®¡ç†"
        else:
            return "ä¸­åº¦å½±å“å…¨å¤©è¡€ç³–æ§åˆ¶ï¼Œå»ºè®®é€‚åº¦å…³æ³¨"
    
    def _interpret_nocturnal_stability(self, stability: float) -> str:
        """è§£é‡Šå¤œé—´ç¨³å®šæ€§"""
        if stability > 0.8:
            return "åŸºç¡€ä»£è°¢çŠ¶æ€ä¸‹è¡€ç³–æ§åˆ¶è‰¯å¥½ï¼ŒåŸºç¡€èƒ°å²›ç´ ç®¡ç†é€‚å½“"
        else:
            return "å¤œé—´è¡€ç³–ä¸å¤Ÿç¨³å®šï¼Œå¯èƒ½éœ€è¦è°ƒæ•´åŸºç¡€èƒ°å²›ç´ "
    
    def _interpret_gmi_hba1c(self, gmi: float) -> str:
        """è§£é‡ŠGMIå’ŒHbA1cå¯¹ç…§"""
        if gmi < 7.0:
            return "ç›¸å½“äºHbA1c<7.0%ï¼Œè¡€ç³–æ§åˆ¶ä¼˜ç§€"
        elif gmi < 7.5:
            return "ç›¸å½“äºHbA1c 7.0-7.5%ï¼Œè¡€ç³–æ§åˆ¶è‰¯å¥½"
        elif gmi < 8.0:
            return "ç›¸å½“äºHbA1c 7.5-8.0%ï¼Œéœ€è¦æ”¹å–„"
        elif gmi < 9.0:
            return "ç›¸å½“äºHbA1c 8.0-9.0%ï¼Œæ§åˆ¶ä¸ä½³"
        else:
            return "ç›¸å½“äºHbA1c>9.0%ï¼Œéœ€è¦ç´§æ€¥æ”¹å–„"
    
    def _assess_glycemic_control_level(self, gmi: float) -> str:
        """è¯„ä¼°è¡€ç³–æ§åˆ¶æ°´å¹³"""
        if gmi < 6.5:
            return "ä¼˜ç§€æ§åˆ¶ (GMI<6.5%)"
        elif gmi < 7.0:
            return "è‰¯å¥½æ§åˆ¶ (GMI 6.5-7.0%)"
        elif gmi < 7.5:
            return "åŸºæœ¬è¾¾æ ‡ (GMI 7.0-7.5%)"
        elif gmi < 8.5:
            return "éœ€è¦æ”¹å–„ (GMI 7.5-8.5%)"
        else:
            return "æ§åˆ¶ä¸ä½³ (GMI>8.5%)"
    
    def _interpret_mage(self, mage: float) -> str:
        """è§£é‡ŠMAGEå€¼"""
        if mage < 2.0:
            return "è¡€ç³–æ¼‚ç§»å¹…åº¦å°ï¼Œç¨³å®šæ€§ä¼˜ç§€"
        elif mage < 3.5:
            return "è¡€ç³–æ¼‚ç§»å¹…åº¦é€‚ä¸­ï¼Œç¨³å®šæ€§è‰¯å¥½"
        elif mage < 5.0:
            return "è¡€ç³–æ¼‚ç§»å¹…åº¦è¾ƒå¤§ï¼Œéœ€è¦æ”¹å–„ç¨³å®šæ€§"
        else:
            return "è¡€ç³–æ¼‚ç§»å¹…åº¦è¿‡å¤§ï¼Œç¨³å®šæ€§è¾ƒå·®"
    
    def _interpret_j_index(self, j_index: float) -> str:
        """è§£é‡ŠJ-Index"""
        if j_index < 15:
            return "è¡€ç³–è´¨é‡ä¼˜ç§€"
        elif j_index < 30:
            return "è¡€ç³–è´¨é‡è‰¯å¥½"
        elif j_index < 60:
            return "è¡€ç³–è´¨é‡ä¸€èˆ¬ï¼Œæœ‰æ”¹å–„ç©ºé—´"
        else:
            return "è¡€ç³–è´¨é‡è¾ƒå·®ï¼Œéœ€è¦ç§¯ææ”¹å–„"
    
    def _format_historical_comparison(self, historical_data: List[Dict], current_metrics: GlycemicMetrics, current_phenotype: ClinicalPhenotype) -> str:
        """æ ¼å¼åŒ–åŒä¸€æ‚£è€…çš„å†å²å¯¹æ¯”åˆ†æ"""
        if len(historical_data) < 2:
            return "\n### ğŸ“ˆ å†å²å¯¹æ¯”åˆ†æ\n\n**é¦–æ¬¡åˆ†æ**: æš‚æ— å†å²æ•°æ®å¯¹æ¯”ï¼Œå·²å»ºç«‹åŸºçº¿æ¡£æ¡ˆ\n"
        
        previous = historical_data[-2]['metrics']
        current = {
            'tir': current_metrics.tir,
            'glucose_cv': current_metrics.glucose_cv,
            'tbr_level1': current_metrics.tbr_level1,
            'percentile_band_cv': current_metrics.percentile_band_cv,
            'phenotype': current_phenotype.value
        }
        
        tir_change = current['tir'] - previous['tir']
        cv_change = current['glucose_cv'] - previous['glucose_cv']
        band_cv_change = current['percentile_band_cv'] - previous.get('percentile_band_cv', 0)
        tbr_change = current['tbr_level1'] - previous['tbr_level1']
        
        # è®¡ç®—æ€»ä½“è¶‹åŠ¿ï¼ˆå¦‚æœæœ‰å¤šæ¬¡è®°å½•ï¼‰
        if len(historical_data) >= 3:
            trend_analysis = self._analyze_long_term_trend(historical_data, current)
        else:
            trend_analysis = "æ•°æ®ç§¯ç´¯ä¸­ï¼Œå»ºè®®ç»§ç»­å®šæœŸç›‘æµ‹"
        
        comparison = f"""
### ğŸ“ˆ æ‚£è€…å†å²å¯¹æ¯”åˆ†æ

#### **å…³é”®æŒ‡æ ‡å˜åŒ–** (è¾ƒä¸Šæ¬¡ç›‘æµ‹)
- **TIRå˜åŒ–**: {tir_change:+.1f}% ({'âœ… æ”¹å–„' if tir_change > 0 else 'âŒ ä¸‹é™' if tir_change < 0 else 'â– ç¨³å®š'})
- **è¡€ç³–å˜å¼‚æ€§**: {cv_change:+.1f}% ({'âœ… æ”¹å–„' if cv_change < 0 else 'âŒ æ¶åŒ–' if cv_change > 0 else 'â– ç¨³å®š'})  
- **æ˜¼å¤œèŠ‚å¾‹**: {band_cv_change:+.1f}% ({'âœ… æ”¹å–„' if band_cv_change < 0 else 'âŒ æ¶åŒ–' if band_cv_change > 0 else 'â– ç¨³å®š'})
- **ä½è¡€ç³–é£é™©**: {tbr_change:+.1f}% ({'âš ï¸ å¢åŠ ' if tbr_change > 0 else 'âœ… å‡å°‘' if tbr_change < 0 else 'â– ç¨³å®š'})

#### **ä¸´åºŠè¡¨å‹å˜åŒ–**
- **ä¸Šæ¬¡è¡¨å‹**: {previous.get('phenotype', 'æœªè®°å½•')}
- **æœ¬æ¬¡è¡¨å‹**: {current['phenotype']}
- **è¡¨å‹è¯„ä¼°**: {self._assess_phenotype_change(previous.get('phenotype', ''), current['phenotype'])}

#### **æ²»ç–—æ•ˆæœè¯„ä¼°**
**çŸ­æœŸæ•ˆæœ**: {self._assess_short_term_effect(tir_change, cv_change, tbr_change)}  
**ç®¡ç†è¶‹åŠ¿**: {self._assess_trend(tir_change, cv_change)}  
**ä¸´åºŠå»ºè®®**: {self._interpret_trend_significance(tir_change, cv_change)}

#### **é•¿æœŸè¶‹åŠ¿åˆ†æ** (å…±{len(historical_data)}æ¬¡è®°å½•)
{trend_analysis}

"""
        return comparison
    
    def _assess_trend(self, tir_change: float, cv_change: float) -> str:
        """è¯„ä¼°å˜åŒ–è¶‹åŠ¿"""
        if tir_change > 5 and cv_change < -2:
            return "è¡€ç³–æ§åˆ¶æ˜¾è‘—æ”¹å–„"
        elif tir_change > 2:
            return "è¡€ç³–æ§åˆ¶è½»åº¦æ”¹å–„"
        elif tir_change < -5:
            return "è¡€ç³–æ§åˆ¶æ˜æ˜¾æ¶åŒ–"
        elif tir_change < -2:
            return "è¡€ç³–æ§åˆ¶è½»åº¦æ¶åŒ–"
        else:
            return "è¡€ç³–æ§åˆ¶åŸºæœ¬ç¨³å®š"
    
    def _interpret_trend_significance(self, tir_change: float, cv_change: float) -> str:
        """è§£é‡Šè¶‹åŠ¿çš„ä¸´åºŠæ„ä¹‰"""
        if tir_change > 5:
            return "å½“å‰æ²»ç–—ç­–ç•¥æœ‰æ•ˆï¼Œå»ºè®®ç»§ç»­ç»´æŒ"
        elif tir_change < -5:
            return "éœ€è¦ç´§æ€¥è¯„ä¼°æ²»ç–—ä¾ä»æ€§å’Œç–¾ç—…è¿›å±•æƒ…å†µ"
        else:
            return "è¡€ç³–æ§åˆ¶ç›¸å¯¹ç¨³å®šï¼Œå¯è¿›è¡Œç²¾ç»†åŒ–è°ƒæ•´"
    
    def _assess_phenotype_change(self, previous_phenotype: str, current_phenotype: str) -> str:
        """è¯„ä¼°ä¸´åºŠè¡¨å‹å˜åŒ–"""
        if previous_phenotype == current_phenotype:
            return "è¡¨å‹ç¨³å®šï¼Œç®¡ç†ç­–ç•¥ä¸€è‡´"
        elif previous_phenotype == "ç¨³å®šæ€§é«˜è¡€ç³–å‹" and current_phenotype == "æ¥è¿‘è¾¾æ ‡å‹":
            return "è¡€ç³–æ§åˆ¶æ˜¾è‘—æ”¹å–„ï¼Œæ²»ç–—æ•ˆæœè‰¯å¥½"
        elif previous_phenotype == "æ¥è¿‘è¾¾æ ‡å‹" and current_phenotype == "ä¼˜åŒ–æ§åˆ¶å‹":
            return "è¡€ç³–ç®¡ç†ä¼˜åŒ–æˆåŠŸï¼Œè¾¾åˆ°ç†æƒ³çŠ¶æ€"
        elif "é«˜è¡€ç³–" in previous_phenotype and "è¾¾æ ‡" in current_phenotype:
            return "è¡€ç³–æ§åˆ¶è·å¾—çªç ´æ€§æ”¹å–„"
        elif "è¾¾æ ‡" in previous_phenotype and "é«˜è¡€ç³–" in current_phenotype:
            return "âš ï¸ è¡€ç³–æ§åˆ¶æ¶åŒ–ï¼Œéœ€è¦é‡æ–°è¯„ä¼°æ²»ç–—æ–¹æ¡ˆ"
        else:
            return f"è¡¨å‹è½¬æ¢({previous_phenotype} â†’ {current_phenotype})ï¼Œéœ€è¦è°ƒæ•´ç®¡ç†ç­–ç•¥"
    
    def _assess_short_term_effect(self, tir_change: float, cv_change: float, tbr_change: float) -> str:
        """è¯„ä¼°çŸ­æœŸæ²»ç–—æ•ˆæœ"""
        effects = []
        
        if tir_change > 3:
            effects.append("TIRæ˜¾è‘—æ”¹å–„")
        elif tir_change > 0:
            effects.append("TIRè½»åº¦æ”¹å–„")
        elif tir_change < -3:
            effects.append("TIRæ˜æ˜¾ä¸‹é™")
        elif tir_change < 0:
            effects.append("TIRè½»åº¦ä¸‹é™")
        else:
            effects.append("TIRåŸºæœ¬ç¨³å®š")
        
        if cv_change < -2:
            effects.append("è¡€ç³–ç¨³å®šæ€§æå‡")
        elif cv_change > 2:
            effects.append("è¡€ç³–ç¨³å®šæ€§ä¸‹é™")
        else:
            effects.append("è¡€ç³–ç¨³å®šæ€§ç»´æŒ")
        
        if tbr_change > 1:
            effects.append("âš ï¸ ä½è¡€ç³–é£é™©å¢åŠ ")
        elif tbr_change < -1:
            effects.append("ä½è¡€ç³–é£é™©é™ä½")
        
        return "ï¼›".join(effects)
    
    def _analyze_long_term_trend(self, historical_data: List[Dict], current: Dict) -> str:
        """åˆ†æé•¿æœŸè¶‹åŠ¿"""
        if len(historical_data) < 3:
            return "æ•°æ®ç§¯ç´¯ä¸­ï¼Œå»ºè®®ç»§ç»­å®šæœŸç›‘æµ‹"
        
        # æå–å†å²TIRæ•°æ®
        tir_history = [record['metrics']['tir'] for record in historical_data[-3:]]
        tir_history.append(current['tir'])
        
        # è®¡ç®—çº¿æ€§è¶‹åŠ¿
        n = len(tir_history)
        x = list(range(n))
        y = tir_history
        
        # ç®€å•çº¿æ€§å›å½’è®¡ç®—æ–œç‡
        x_mean = sum(x) / n
        y_mean = sum(y) / n
        
        numerator = sum((x[i] - x_mean) * (y[i] - y_mean) for i in range(n))
        denominator = sum((x[i] - x_mean) ** 2 for i in range(n))
        
        if denominator != 0:
            slope = numerator / denominator
            trend_description = self._describe_trend_slope(slope, n)
        else:
            trend_description = "æ•°æ®æ³¢åŠ¨ï¼Œè¶‹åŠ¿ä¸æ˜ç¡®"
        
        # å˜å¼‚ç³»æ•°è¶‹åŠ¿
        cv_history = [record['metrics'].get('glucose_cv', 0) for record in historical_data[-3:]]
        cv_trend = "ç¨³å®š" if abs(max(cv_history) - min(cv_history)) < 3 else "æ³¢åŠ¨"
        
        return f"""
**TIRè¶‹åŠ¿**: {trend_description}
**å˜å¼‚æ€§è¶‹åŠ¿**: è¡€ç³–ç¨³å®šæ€§{cv_trend}
**ç®¡ç†å»ºè®®**: {self._get_long_term_management_advice(slope, cv_trend)}
**ä¸‹æ¬¡éšè®¿**: {self._recommend_follow_up_interval(slope)}"""
    
    def _describe_trend_slope(self, slope: float, data_points: int) -> str:
        """æè¿°è¶‹åŠ¿æ–œç‡"""
        if slope > 2:
            return f"æŒç»­æ”¹å–„ä¸­ (è¿‘{data_points}æ¬¡ç›‘æµ‹å¹³å‡æ¯æ¬¡æå‡{slope:.1f}%)"
        elif slope > 0.5:
            return f"ç¼“æ…¢æ”¹å–„ä¸­ (è¿‘{data_points}æ¬¡ç›‘æµ‹å‘ˆä¸Šå‡è¶‹åŠ¿)"
        elif slope < -2:
            return f"æŒç»­æ¶åŒ–ä¸­ (è¿‘{data_points}æ¬¡ç›‘æµ‹å¹³å‡æ¯æ¬¡ä¸‹é™{abs(slope):.1f}%)"
        elif slope < -0.5:
            return f"ç¼“æ…¢æ¶åŒ–ä¸­ (è¿‘{data_points}æ¬¡ç›‘æµ‹å‘ˆä¸‹é™è¶‹åŠ¿)"
        else:
            return f"åŸºæœ¬ç¨³å®š (è¿‘{data_points}æ¬¡ç›‘æµ‹æ³¢åŠ¨èŒƒå›´å°)"
    
    def _get_long_term_management_advice(self, slope: float, cv_trend: str) -> str:
        """è·å–é•¿æœŸç®¡ç†å»ºè®®"""
        if slope > 1:
            return "å½“å‰ç®¡ç†ç­–ç•¥æœ‰æ•ˆï¼Œå»ºè®®ç»§ç»­ç»´æŒå¹¶å·©å›ºæˆæœ"
        elif slope < -1:
            return "éœ€è¦ç³»ç»Ÿæ€§è¯„ä¼°æ²»ç–—æ–¹æ¡ˆï¼Œè€ƒè™‘è°ƒæ•´ç®¡ç†ç­–ç•¥"
        elif cv_trend == "æ³¢åŠ¨":
            return "å…³æ³¨è¡€ç³–ç¨³å®šæ€§ï¼Œä¼˜åŒ–æ²»ç–—ä¸€è‡´æ€§"
        else:
            return "ç»´æŒç°çŠ¶ï¼Œå®šæœŸç›‘æµ‹ï¼Œé€‚æ—¶å¾®è°ƒ"
    
    def _recommend_follow_up_interval(self, slope: float) -> str:
        """æ¨èéšè®¿é—´éš”"""
        if abs(slope) > 2:
            return "2-4å‘¨ï¼ˆè¡€ç³–å˜åŒ–è¾ƒå¤§ï¼Œéœ€å¯†åˆ‡ç›‘æµ‹ï¼‰"
        elif abs(slope) > 0.5:
            return "4-6å‘¨ï¼ˆè¡€ç³–æœ‰å˜åŒ–è¶‹åŠ¿ï¼Œéœ€è¦å…³æ³¨ï¼‰"
        else:
            return "6-8å‘¨ï¼ˆè¡€ç³–ç›¸å¯¹ç¨³å®šï¼Œå¸¸è§„éšè®¿ï¼‰"
    
    def _format_detailed_time_analysis(self, circadian: CircadianAnalysis) -> str:
        """æ ¼å¼åŒ–è¯¦ç»†æ—¶é—´æ¨¡å¼åˆ†æ"""
        analysis = ""
        
        # é¤åè¡€ç³–ååº”è¯¦ç»†åˆ†æ
        if hasattr(circadian, 'postprandial_peaks') and circadian.postprandial_peaks:
            analysis += "\n**ğŸ“… é¤åè¡€ç³–ååº”åˆ†æ**:\n\n"
            
            for meal, data in circadian.postprandial_peaks.items():
                meal_name = {'breakfast': 'æ—©é¤', 'lunch': 'åˆé¤', 'dinner': 'æ™šé¤'}.get(meal, meal)
                excursion_level = "æ­£å¸¸" if data['excursion'] < 2.0 else "è½»åº¦å‡é«˜" if data['excursion'] < 3.0 else "æ˜¾è‘—å‡é«˜"
                
                analysis += f"- **{meal_name}å**:\n"
                analysis += f"  - åŸºçº¿è¡€ç³–: {data['baseline']:.1f} mmol/L\n"
                analysis += f"  - å³°å€¼è¡€ç³–: {data['peak']:.1f} mmol/L\n"  
                analysis += f"  - è¡€ç³–æ¿€å‘: {data['excursion']:.1f} mmol/L ({excursion_level})\n"
                analysis += f"  - å³°å€¼æ—¶é—´: {data['peak_time']}\n"
                analysis += f"  - è¾¾å³°æ—¶é—´: {data['time_to_peak']}å°æ—¶\n\n"
        
        # æ¯å°æ—¶è¡€ç³–æ¨¡å¼åˆ†æ
        if hasattr(circadian, 'hourly_patterns') and circadian.hourly_patterns:
            analysis += "**â° 24å°æ—¶è¡€ç³–æ¨¡å¼æ¦‚è§ˆ**:\n\n"
            
            # æ‰¾å‡ºæœ€é«˜å’Œæœ€ä½è¡€ç³–æ—¶æ®µ
            hourly_means = {time: data['mean'] for time, data in circadian.hourly_patterns.items() if 'mean' in data}
            if hourly_means:
                max_time = max(hourly_means, key=hourly_means.get)
                min_time = min(hourly_means, key=hourly_means.get)
                max_value = hourly_means[max_time]
                min_value = hourly_means[min_time]
                
                analysis += f"- **è¡€ç³–æœ€é«˜æ—¶æ®µ**: {max_time} ({max_value:.1f} mmol/L)\n"
                analysis += f"- **è¡€ç³–æœ€ä½æ—¶æ®µ**: {min_time} ({min_value:.1f} mmol/L)\n"
                analysis += f"- **æ˜¼å¤œè¡€ç³–å·®**: {max_value - min_value:.1f} mmol/L\n\n"
            
            # å…³é”®æ—¶æ®µåˆ†æ
            key_periods = {
                "06:00": "æ¸…æ™¨èµ·åºŠ",
                "08:00": "æ—©é¤å", 
                "12:00": "åˆé¤å‰",
                "14:00": "åˆé¤å",
                "18:00": "æ™šé¤å‰",
                "20:00": "æ™šé¤å",
                "22:00": "ç¡å‰",
                "02:00": "å¤œé—´"
            }
            
            analysis += "**ğŸ¯ å…³é”®æ—¶æ®µè¡€ç³–æ°´å¹³**:\n\n"
            for time, desc in key_periods.items():
                if time in circadian.hourly_patterns:
                    data = circadian.hourly_patterns[time]
                    mean_val = data.get('mean', 0)
                    cv_val = data.get('cv', 0)
                    status = "ç†æƒ³" if 3.9 <= mean_val <= 10.0 else "åé«˜" if mean_val > 10.0 else "åä½"
                    analysis += f"- **{desc} ({time})**: {mean_val:.1f} mmol/L (CV: {cv_val:.1f}%) - {status}\n"
            analysis += "\n"
        
        # è¡€ç³–å˜å¼‚æ€§æ—¶é—´åˆ†å¸ƒ
        if hasattr(circadian, 'hourly_patterns') and circadian.hourly_patterns:
            # æ‰¾å‡ºå˜å¼‚æ€§æœ€å¤§çš„æ—¶æ®µ
            hourly_cvs = {time: data.get('cv', 0) for time, data in circadian.hourly_patterns.items() if 'cv' in data}
            if hourly_cvs:
                max_cv_time = max(hourly_cvs, key=hourly_cvs.get)
                max_cv_value = hourly_cvs[max_cv_time]
                
                analysis += "**ğŸ“Š è¡€ç³–ç¨³å®šæ€§æ—¶é—´åˆ†æ**:\n\n"
                analysis += f"- **æœ€ä¸ç¨³å®šæ—¶æ®µ**: {max_cv_time} (CV: {max_cv_value:.1f}%)\n"
                analysis += f"- **ç¨³å®šæ€§è¯„ä¼°**: {'éœ€è¦å…³æ³¨' if max_cv_value > 30 else 'ç›¸å¯¹ç¨³å®š'}\n"
                
                # æ—¶æ®µç¨³å®šæ€§åˆ†ç±»
                stable_periods = [time for time, cv in hourly_cvs.items() if cv < 20]
                moderate_periods = [time for time, cv in hourly_cvs.items() if 20 <= cv < 30]
                unstable_periods = [time for time, cv in hourly_cvs.items() if cv >= 30]
                
                if stable_periods:
                    analysis += f"- **ç¨³å®šæ—¶æ®µ** (CV<20%): {', '.join(stable_periods[:5])}\n"
                if moderate_periods:
                    analysis += f"- **ä¸­ç­‰æ³¢åŠ¨æ—¶æ®µ** (CV 20-30%): {', '.join(moderate_periods[:5])}\n"  
                if unstable_periods:
                    analysis += f"- **ä¸ç¨³å®šæ—¶æ®µ** (CVâ‰¥30%): {', '.join(unstable_periods[:5])}\n"
                analysis += "\n"
        
        return analysis

    def _format_clinical_recommendations(self, recommendations: List[ClinicalRecommendation]) -> str:
        """æ ¼å¼åŒ–ä¸´åºŠå»ºè®®"""
        if not recommendations:
            return ""
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {"ç´§æ€¥": 1, "é«˜": 2, "ä¸­": 3, "ä½": 4}
        sorted_recs = sorted(recommendations, key=lambda x: priority_order.get(x.priority, 5))
        
        report = "\n### ğŸ¯ ä¸´åºŠè¯Šç–—å»ºè®®\n"
        
        for i, rec in enumerate(sorted_recs, 1):
            priority_emoji = {"ç´§æ€¥": "ğŸš¨", "é«˜": "âš ï¸", "ä¸­": "ğŸ“‹", "ä½": "ğŸ’¡"}
            
            report += f"""
#### **{i}. {rec.category}** {priority_emoji.get(rec.priority, 'ğŸ“‹')} {rec.priority}ä¼˜å…ˆçº§

**å»ºè®®å†…å®¹**: {rec.recommendation}  
**æœºåˆ¶è§£é‡Š**: {rec.mechanism}  
**é¢„æœŸæ•ˆæœ**: {rec.expected_outcome}  
**å®æ–½æ—¶é—´**: {rec.timeframe}

**ğŸ”§ å…·ä½“æ‰§è¡Œæªæ–½**:
{self._format_specific_actions(rec)}

**ğŸ’Š ç”¨è¯å»ºè®®**:
{rec.dosing_suggestions if hasattr(rec, 'dosing_suggestions') and rec.dosing_suggestions else 'è¯·æ ¹æ®åŒ»ç”ŸæŒ‡å¯¼ç”¨è¯'}

**â° æ—¶æœºå®‰æ’**:
{rec.timing_instructions if hasattr(rec, 'timing_instructions') and rec.timing_instructions else 'è¯·éµå¾ªå¸¸è§„ç”¨è¯æ—¶é—´'}

**ğŸ“… éšè®¿è®¡åˆ’**:
{rec.follow_up_schedule if hasattr(rec, 'follow_up_schedule') and rec.follow_up_schedule else 'å»ºè®®1-2å‘¨åå¤è¯Šè¯„ä¼°'}

**âœ… æˆåŠŸæ ‡å‡†**:
{rec.success_criteria if hasattr(rec, 'success_criteria') and rec.success_criteria else 'è¡€ç³–æ§åˆ¶è¾¾æ ‡ï¼Œæ— ä¸è‰¯äº‹ä»¶'}

**âš ï¸ æ³¨æ„äº‹é¡¹**:
{', '.join(rec.warning_signs) if hasattr(rec, 'warning_signs') and rec.warning_signs else 'æ³¨æ„ç›‘æµ‹è¡€ç³–å˜åŒ–'}

**ğŸ“Š ç›‘æµ‹è¦ç‚¹**: {', '.join(rec.monitoring_points)}

"""
        
        return report
    
    def _format_specific_actions(self, rec: ClinicalRecommendation) -> str:
        """æ ¼å¼åŒ–å…·ä½“æ‰§è¡Œæªæ–½"""
        if not hasattr(rec, 'specific_actions') or not rec.specific_actions:
            return "è¯·æ ¹æ®åŒ»ç”ŸæŒ‡å¯¼æ‰§è¡Œç›¸å…³æªæ–½"
        
        actions_text = ""
        for i, action in enumerate(rec.specific_actions, 1):
            actions_text += f"  {i}. {action}\n"
        
        return actions_text.rstrip()
    
    def _format_prognosis_assessment(self, 
                                   phenotype: ClinicalPhenotype,
                                   metrics: GlycemicMetrics,
                                   historical_data: List[Dict]) -> str:
        """æ ¼å¼åŒ–é¢„åè¯„ä¼°"""
        
        # åŸºäºè¡¨å‹çš„é¢„åè¯„ä¼°
        prognosis_map = {
            ClinicalPhenotype.STABLE_HYPERGLYCEMIC: "ä¸­ç­‰éš¾åº¦è¾¾æ ‡ï¼Œéœ€è¦ç§¯ææ²»ç–—å¼ºåŒ–",
            ClinicalPhenotype.POSTPRANDIAL_EXCURSION: "é¢„åè‰¯å¥½ï¼Œç²¾å‡†å¹²é¢„å¯è·å¾—æ˜¾è‘—æ”¹å–„",
            ClinicalPhenotype.NEAR_TARGET: "é¢„åä¼˜ç§€ï¼Œå¤§æ¦‚ç‡å®‰å…¨è¾¾æ ‡",
            ClinicalPhenotype.OPTIMAL_CONTROL: "ç»´æŒä¼˜ç§€æ§åˆ¶çŠ¶æ€",
            ClinicalPhenotype.HIGH_VARIABILITY: "éœ€è¦ç³»ç»Ÿæ€§è¯„ä¼°å’Œæ²»ç–—è°ƒæ•´"
        }
        
        treatment_advantages = []
        if metrics.tbr_level1 < 2:
            treatment_advantages.append("ä½è¡€ç³–é£é™©ä½ï¼Œæ²»ç–—è°ƒæ•´å®‰å…¨è¾¹é™…å……åˆ†")
        if metrics.glucose_cv < 30:
            treatment_advantages.append("è¡€ç³–ç¨³å®šæ€§è‰¯å¥½ï¼Œæ²»ç–—ååº”å¯é¢„æµ‹")
        if metrics.tir > 60:
            treatment_advantages.append("å…·å¤‡è‰¯å¥½çš„è¡€ç³–æ§åˆ¶åŸºç¡€")
        
        report = f"""
### ğŸ“ˆ é¢„åè¯„ä¼°ä¸æ²»ç–—ä¼˜åŠ¿

**é¢„åè¯„ä¼°**: {prognosis_map.get(phenotype, 'éœ€è¦ä¸ªæ€§åŒ–è¯„ä¼°')}

**æ²»ç–—ä¼˜åŠ¿**:
"""
        for advantage in treatment_advantages:
            report += f"- {advantage}\n"
        
        if len(historical_data) > 1:
            report += f"\n**å†å²è¡¨ç°**: å·²å»ºç«‹{len(historical_data)}æ¬¡ç›‘æµ‹è®°å½•ï¼Œä¾¿äºè¶‹åŠ¿åˆ†æå’Œç²¾å‡†è°ƒæ•´\n"
        
        report += f"""
**éšè®¿å»ºè®®**:
- æ²»ç–—è°ƒæ•´å1-2å‘¨å†…å¯†åˆ‡ç›‘æµ‹
- æœˆåº¦å…¨é¢è¯„ä¼°æ²»ç–—æ•ˆæœ
- å­£åº¦è¯„ä¼°é•¿æœŸè¶‹åŠ¿å’Œå¹¶å‘ç—‡é£é™©
- å»ºç«‹ä¸ªæ€§åŒ–çš„é•¿æœŸç®¡ç†æ–¹æ¡ˆ

---

**ä¸´åºŠæ€»ç»“**: æ‚£è€…{phenotype.value}ä¸ºç‰¹å¾ï¼Œé€šè¿‡{self._get_treatment_approach(phenotype)}ï¼Œé¢„æœŸå¯è·å¾—è‰¯å¥½çš„è¡€ç³–æ§åˆ¶æ”¹å–„ã€‚
"""
        
        return report
    
    def _get_treatment_approach(self, phenotype: ClinicalPhenotype) -> str:
        """è·å–æ²»ç–—æ–¹æ³•æè¿°"""
        approaches = {
            ClinicalPhenotype.STABLE_HYPERGLYCEMIC: "ç§¯æçš„èƒ°å²›ç´ å¼ºåŒ–æ²»ç–—",
            ClinicalPhenotype.POSTPRANDIAL_EXCURSION: "ç²¾å‡†çš„é¤æ—¶è¡€ç³–ç®¡ç†",
            ClinicalPhenotype.NEAR_TARGET: "ç²¾ç»†åŒ–çš„æ²»ç–—è°ƒæ•´",
            ClinicalPhenotype.OPTIMAL_CONTROL: "ç»´æŒæ€§ç®¡ç†ç­–ç•¥"
        }
        return approaches.get(phenotype, "ä¸ªæ€§åŒ–æ²»ç–—æ–¹æ¡ˆ")

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºAGPAI Agent V2.0åŠŸèƒ½"""
    
    # åˆå§‹åŒ–Agent
    agent = AGPAI_Agent_V2()
    
    print("ğŸ¤– AGPAI Agent V2.0 - é«˜çº§CGMåˆ†æç³»ç»Ÿ")
    print("=" * 60)
    
    # æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
    test_files = [
        ("/Users/williamsun/Documents/gplus/docs/AGPAI/R002 V5.txt", "R002")
    ]
    
    for file_path, patient_id in test_files:
        if os.path.exists(file_path):
            print(f"\nåˆ†ææ‚£è€… {patient_id}...")
            try:
                report = agent.generate_comprehensive_report(
                    patient_id=patient_id,
                    cgm_file_path=file_path,
                    include_historical=True
                )
                print(report)
                print("-" * 60)
            except Exception as e:
                print(f"åˆ†æå¤±è´¥: {str(e)}")
        else:
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

if __name__ == "__main__":
    main()