#!/usr/bin/env python3
"""
å°†å®éªŒå®¤æ£€æµ‹JSONæ–‡ä»¶è½¬æ¢ä¸ºCSVæ ¼å¼ï¼Œå±•ç¤ºæ‰€æœ‰å­—æ®µç»“æ„
"""

import json
import pandas as pd
from typing import Dict, Any, List
import os

def load_json_file(filepath: str) -> Dict[str, Any]:
    """åŠ è½½JSONæ–‡ä»¶"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        print(f"JSONæ ¼å¼é”™è¯¯: {e}")
        return {}

def flatten_dict(d: dict, parent_key: str = '', sep: str = '_') -> dict:
    """æ‰å¹³åŒ–åµŒå¥—å­—å…¸"""
    items = []
    for k, v in d.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.extend(flatten_dict(v, new_key, sep=sep).items())
        elif isinstance(v, list):
            # å¯¹äºåˆ—è¡¨ï¼Œæˆ‘ä»¬å°†å…¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            items.append((new_key, str(v) if v else ''))
        else:
            items.append((new_key, v))
    return dict(items)

def extract_all_tests_to_dataframe(data: Dict[str, Any]) -> pd.DataFrame:
    """æå–æ‰€æœ‰æµ‹è¯•é¡¹ç›®å¹¶è½¬æ¢ä¸ºDataFrame"""
    all_tests = []
    
    # æ£€æŸ¥æ˜¯å¦æœ‰comprehensive_test_panelsç»“æ„
    if 'comprehensive_test_panels' in data:
        data = data['comprehensive_test_panels']
    
    for panel_key, panel_data in data.items():
        if not isinstance(panel_data, dict) or 'tests' not in panel_data:
            continue
        
        panel_info = {
            'panel_id': panel_key,
            'panel_name': panel_data.get('panel_name', ''),
            'domain_code': panel_data.get('domain_code', ''),
            'icd10_codes': str(panel_data.get('icd10_codes', [])),
            'test_count': panel_data.get('test_count', 0)
        }
        
        for test in panel_data['tests']:
            # åˆ›å»ºæµ‹è¯•é¡¹ç›®çš„å®Œæ•´è®°å½•
            test_record = panel_info.copy()
            
            # æ‰å¹³åŒ–æµ‹è¯•æ•°æ®
            flattened_test = flatten_dict(test)
            test_record.update(flattened_test)
            
            all_tests.append(test_record)
    
    return pd.DataFrame(all_tests)

def analyze_json_structure(data: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ†æJSONç»“æ„"""
    analysis = {
        'total_panels': 0,
        'total_tests': 0,
        'panels': [],
        'all_fields': set(),
        'field_frequency': {},
        'sample_test': None
    }
    
    # æ£€æŸ¥æ˜¯å¦æœ‰comprehensive_test_panelsç»“æ„
    if 'comprehensive_test_panels' in data:
        data = data['comprehensive_test_panels']
    
    for panel_key, panel_data in data.items():
        if not isinstance(panel_data, dict) or 'tests' not in panel_data:
            continue
        
        analysis['total_panels'] += 1
        panel_tests = len(panel_data.get('tests', []))
        analysis['total_tests'] += panel_tests
        
        analysis['panels'].append({
            'panel_id': panel_key,
            'panel_name': panel_data.get('panel_name', ''),
            'test_count': panel_tests
        })
        
        # åˆ†æå­—æ®µ
        for test in panel_data['tests']:
            if analysis['sample_test'] is None:
                analysis['sample_test'] = test
            
            flattened = flatten_dict(test)
            for field in flattened.keys():
                analysis['all_fields'].add(field)
                analysis['field_frequency'][field] = analysis['field_frequency'].get(field, 0) + 1
    
    return analysis

def main():
    json_file = '/Users/williamsun/Documents/gplus/docs/CRF_design/Comprehensive_Laboratory_Tests_with_LOINC.json'
    
    if not os.path.exists(json_file):
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return
    
    print("æ­£åœ¨åŠ è½½JSONæ–‡ä»¶...")
    data = load_json_file(json_file)
    
    if not data:
        print("æ— æ³•åŠ è½½JSONæ•°æ®")
        return
    
    print("æ­£åœ¨åˆ†ææ–‡ä»¶ç»“æ„...")
    analysis = analyze_json_structure(data)
    
    print(f"\nğŸ“Š JSONæ–‡ä»¶ç»“æ„åˆ†æ:")
    print(f"æ€»é¢æ¿æ•°: {analysis['total_panels']}")
    print(f"æ€»æµ‹è¯•é¡¹æ•°: {analysis['total_tests']}")
    
    print(f"\nğŸ“‹ æ£€æµ‹é¢æ¿åˆ—è¡¨:")
    for panel in analysis['panels']:
        print(f"  - {panel['panel_id']}: {panel['panel_name']} ({panel['test_count']}é¡¹)")
    
    print(f"\nğŸ·ï¸  æ‰€æœ‰å­—æ®µåˆ—è¡¨ (å…±{len(analysis['all_fields'])}ä¸ª):")
    sorted_fields = sorted(analysis['field_frequency'].items(), key=lambda x: x[1], reverse=True)
    
    for field, count in sorted_fields[:30]:  # æ˜¾ç¤ºå‰30ä¸ªæœ€å¸¸è§å­—æ®µ
        print(f"  - {field}: {count}æ¬¡")
    
    if len(sorted_fields) > 30:
        print(f"  ... è¿˜æœ‰ {len(sorted_fields) - 30} ä¸ªå­—æ®µ")
    
    print(f"\nğŸ“ ç¤ºä¾‹æµ‹è¯•é¡¹ç›®ç»“æ„:")
    if analysis['sample_test']:
        sample_flat = flatten_dict(analysis['sample_test'])
        for key, value in list(sample_flat.items())[:10]:
            print(f"  {key}: {value}")
        if len(sample_flat) > 10:
            print(f"  ... è¿˜æœ‰ {len(sample_flat) - 10} ä¸ªå­—æ®µ")
    
    # è½¬æ¢ä¸ºCSV
    print(f"\nğŸ”„ æ­£åœ¨è½¬æ¢ä¸ºCSVæ ¼å¼...")
    df = extract_all_tests_to_dataframe(data)
    
    # ä¿å­˜CSVæ–‡ä»¶
    csv_file = json_file.replace('.json', '.csv')
    df.to_csv(csv_file, index=False, encoding='utf-8-sig')
    
    print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {csv_file}")
    print(f"ğŸ“Š CSVæ–‡ä»¶ä¿¡æ¯:")
    print(f"  - è¡Œæ•°: {len(df)}")
    print(f"  - åˆ—æ•°: {len(df.columns)}")
    print(f"  - æ–‡ä»¶å¤§å°: {os.path.getsize(csv_file) / 1024 / 1024:.2f} MB")
    
    print(f"\nğŸ“‹ CSVåˆ—å (å‰20ä¸ª):")
    for i, col in enumerate(df.columns[:20]):
        print(f"  {i+1:2d}. {col}")
    
    if len(df.columns) > 20:
        print(f"     ... è¿˜æœ‰ {len(df.columns) - 20} åˆ—")
    
    # ä¿å­˜å­—æ®µåˆ†æåˆ°å•ç‹¬æ–‡ä»¶
    field_analysis_file = json_file.replace('.json', '_field_analysis.txt')
    with open(field_analysis_file, 'w', encoding='utf-8') as f:
        f.write("å®éªŒå®¤æ£€æµ‹JSONå­—æ®µåˆ†ææŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"æ€»é¢æ¿æ•°: {analysis['total_panels']}\n")
        f.write(f"æ€»æµ‹è¯•é¡¹æ•°: {analysis['total_tests']}\n\n")
        
        f.write("æ‰€æœ‰å­—æ®µåŠä½¿ç”¨é¢‘ç‡:\n")
        f.write("-" * 30 + "\n")
        for field, count in sorted_fields:
            f.write(f"{field}: {count}æ¬¡\n")
    
    print(f"ğŸ“„ å­—æ®µåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {field_analysis_file}")

if __name__ == "__main__":
    main()