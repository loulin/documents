#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆECGæ•°æ®åˆ†æå™¨
ç”¨äºåˆ†æPhysioNet WFDBæ ¼å¼çš„ECGæ•°æ®ï¼Œåªä½¿ç”¨åŸºæœ¬Pythonåº“
"""

import struct
import os
import pandas as pd
import numpy as np
import argparse
from pathlib import Path

def parse_header_file(header_path):
    """
    è§£æ.heaå¤´æ–‡ä»¶è·å–è®°å½•ä¿¡æ¯
    """
    info = {}
    leads = []
    
    try:
        with open(header_path, 'r') as f:
            lines = f.readlines()
        
        # ç¬¬ä¸€è¡ŒåŒ…å«åŸºæœ¬ä¿¡æ¯
        first_line = lines[0].strip().split()
        info['record_name'] = first_line[0]
        info['num_leads'] = int(first_line[1])
        info['sampling_rate'] = int(first_line[2])
        info['num_samples'] = int(first_line[3])
        
        # è§£æå¯¼è”ä¿¡æ¯
        for i in range(1, info['num_leads'] + 1):
            lead_line = lines[i].strip().split()
            lead_name = lead_line[-1]  # å¯¼è”åç§°åœ¨æœ€å
            leads.append(lead_name)
        
        info['leads'] = leads
        
        # è§£ææ‚£è€…ä¿¡æ¯
        for line in lines:
            line = line.strip()
            if line.startswith('#Age:'):
                info['age'] = line.split(': ')[1]
            elif line.startswith('#Sex:'):
                info['sex'] = line.split(': ')[1]
            elif line.startswith('#Dx:'):
                info['diagnosis'] = line.split(': ')[1]
        
        return info
        
    except Exception as e:
        print(f"è§£æå¤´æ–‡ä»¶é”™è¯¯: {e}")
        return None

def read_mat_file(mat_path, num_leads, num_samples):
    """
    è¯»å–.matäºŒè¿›åˆ¶æ•°æ®æ–‡ä»¶
    """
    try:
        # WFDBæ ¼å¼é€šå¸¸ä½¿ç”¨16ä½æœ‰ç¬¦å·æ•´æ•°
        with open(mat_path, 'rb') as f:
            data = f.read()
        
        # è§£æä¸º16ä½æ•´æ•°
        num_values = len(data) // 2
        values = struct.unpack(f'<{num_values}h', data)  # å°ç«¯åº16ä½æœ‰ç¬¦å·æ•´æ•°
        
        expected_values = num_leads * num_samples
        
        # å¤„ç†æ•°æ®ç»´åº¦ï¼Œå¯èƒ½æœ‰é¢å¤–çš„å¤´ä¿¡æ¯
        if num_values == expected_values:
            # å®Œå…¨åŒ¹é…
            signal_data = np.array(values).reshape(num_samples, num_leads)
        elif num_values > expected_values:
            # æœ‰é¢å¤–æ•°æ®ï¼Œå¯èƒ½æ˜¯å¤´ä¿¡æ¯ï¼Œè·³è¿‡å¼€å¤´çš„é¢å¤–æ•°æ®
            extra = num_values - expected_values
            print(f"è·³è¿‡ {extra} ä¸ªé¢å¤–å€¼ï¼ˆå¯èƒ½æ˜¯æ–‡ä»¶å¤´ï¼‰")
            signal_values = values[extra:]  # è·³è¿‡å¼€å¤´çš„é¢å¤–æ•°æ®
            if len(signal_values) == expected_values:
                signal_data = np.array(signal_values).reshape(num_samples, num_leads)
            else:
                print(f"è·³è¿‡é¢å¤–æ•°æ®åä»ä¸åŒ¹é…: æœŸæœ› {expected_values}, å®é™… {len(signal_values)}")
                return None
        else:
            print(f"æ•°æ®ä¸è¶³: æœŸæœ› {expected_values}, å®é™… {num_values}")
            return None
        
        return signal_data
        
    except Exception as e:
        print(f"è¯»å–æ•°æ®æ–‡ä»¶é”™è¯¯: {e}")
        return None

def simple_r_peak_detection(ecg_signal, sampling_rate):
    """
    ç®€å•çš„Rå³°æ£€æµ‹ç®—æ³•
    """
    try:
        # ç®€å•çš„é˜ˆå€¼æ£€æµ‹
        signal = np.array(ecg_signal, dtype=float)
        
        # å»é™¤åŸºçº¿æ¼‚ç§»ï¼ˆç§»åŠ¨å¹³å‡ï¼‰
        window_size = int(sampling_rate * 0.2)  # 200msçª—å£
        baseline = np.convolve(signal, np.ones(window_size)/window_size, mode='same')
        signal_filtered = signal - baseline
        
        # æ‰¾åˆ°å³°å€¼
        threshold = np.std(signal_filtered) * 2.0
        peaks = []
        
        min_distance = int(sampling_rate * 0.3)  # æœ€å°é—´è·300ms
        
        for i in range(min_distance, len(signal_filtered) - min_distance):
            if (signal_filtered[i] > threshold and 
                signal_filtered[i] > signal_filtered[i-1] and 
                signal_filtered[i] > signal_filtered[i+1]):
                
                # æ£€æŸ¥æœ€å°é—´è·
                if not peaks or (i - peaks[-1]) >= min_distance:
                    peaks.append(i)
        
        return peaks
        
    except Exception as e:
        print(f"Rå³°æ£€æµ‹é”™è¯¯: {e}")
        return []

def calculate_hrv_metrics(r_peaks, sampling_rate):
    """
    è®¡ç®—åŸºæœ¬HRVæŒ‡æ ‡
    """
    if len(r_peaks) < 3:
        return {}
    
    # è®¡ç®—RRé—´æœŸï¼ˆæ¯«ç§’ï¼‰
    rr_intervals = np.diff(r_peaks) / sampling_rate * 1000
    
    # åŸºæœ¬ç»Ÿè®¡æŒ‡æ ‡
    metrics = {
        'mean_rr': np.mean(rr_intervals),
        'std_rr': np.std(rr_intervals),  # SDNN
        'min_rr': np.min(rr_intervals),
        'max_rr': np.max(rr_intervals),
        'mean_hr': 60000 / np.mean(rr_intervals),
        'std_hr': np.std(60000 / rr_intervals)
    }
    
    # RMSSD (ç›¸é‚»RRé—´æœŸå·®å€¼çš„å‡æ–¹æ ¹)
    if len(rr_intervals) > 1:
        diff_rr = np.diff(rr_intervals)
        metrics['rmssd'] = np.sqrt(np.mean(diff_rr ** 2))
        
        # pNN50 (ç›¸é‚»RRé—´æœŸå·®å€¼>50msçš„æ¯”ä¾‹)
        nn50 = np.sum(np.abs(diff_rr) > 50)
        metrics['pnn50'] = (nn50 / len(diff_rr)) * 100
    
    return metrics

def analyze_single_record(record_name, data_dir):
    """
    åˆ†æå•ä¸ªECGè®°å½•
    """
    print(f"\n=== åˆ†æè®°å½•: {record_name} ===")
    
    header_path = os.path.join(data_dir, f"{record_name}.hea")
    mat_path = os.path.join(data_dir, f"{record_name}.mat")
    
    # è§£æå¤´æ–‡ä»¶
    header_info = parse_header_file(header_path)
    if not header_info:
        return None
    
    print(f"å¯¼è”æ•°: {header_info['num_leads']}")
    print(f"é‡‡æ ·ç‡: {header_info['sampling_rate']} Hz")
    print(f"æ ·æœ¬æ•°: {header_info['num_samples']}")
    print(f"å¯¼è”: {header_info['leads']}")
    
    # è¯»å–æ•°æ®
    signal_data = read_mat_file(mat_path, header_info['num_leads'], header_info['num_samples'])
    if signal_data is None:
        return None
    
    # é€‰æ‹©å¯¼è”IIè¿›è¡Œåˆ†æï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'II' in header_info['leads']:
        lead_idx = header_info['leads'].index('II')
        ecg_signal = signal_data[:, lead_idx]
        analysis_lead = 'II'
    else:
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯¼è”
        ecg_signal = signal_data[:, 0]
        analysis_lead = header_info['leads'][0]
    
    print(f"ä½¿ç”¨å¯¼è” {analysis_lead} è¿›è¡Œåˆ†æ")
    
    # Rå³°æ£€æµ‹
    r_peaks = simple_r_peak_detection(ecg_signal, header_info['sampling_rate'])
    print(f"æ£€æµ‹åˆ° {len(r_peaks)} ä¸ªRå³°")
    
    if len(r_peaks) < 3:
        print("âš ï¸ Rå³°æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå¯é åˆ†æ")
        return None
    
    # è®¡ç®—HRVæŒ‡æ ‡
    hrv_metrics = calculate_hrv_metrics(r_peaks, header_info['sampling_rate'])
    
    # æ•´åˆç»“æœ
    result = {
        'record_name': record_name,
        'num_leads': header_info['num_leads'],
        'sampling_rate': header_info['sampling_rate'],
        'duration_sec': header_info['num_samples'] / header_info['sampling_rate'],
        'analysis_lead': analysis_lead,
        'r_peaks_count': len(r_peaks),
        **hrv_metrics,
        **{k: v for k, v in header_info.items() if k in ['age', 'sex', 'diagnosis']}
    }
    
    print("âœ… åˆ†æå®Œæˆ")
    return result

def analyze_directory(data_dir, output_file=None):
    """
    æ‰¹é‡åˆ†æç›®å½•ä¸­çš„æ‰€æœ‰ECGè®°å½•
    """
    print(f"ğŸ” åˆ†æç›®å½•: {data_dir}")
    
    # è¯»å–RECORDSæ–‡ä»¶
    records_file = os.path.join(data_dir, 'RECORDS')
    if not os.path.exists(records_file):
        print("âŒ æœªæ‰¾åˆ°RECORDSæ–‡ä»¶")
        return None
    
    with open(records_file, 'r') as f:
        record_names = [line.strip() for line in f if line.strip()]
    
    print(f"æ‰¾åˆ° {len(record_names)} ä¸ªè®°å½•")
    
    # åˆ†ææ‰€æœ‰è®°å½•
    results = []
    successful = 0
    
    for i, record_name in enumerate(record_names, 1):
        print(f"\nè¿›åº¦: {i}/{len(record_names)}")
        result = analyze_single_record(record_name, data_dir)
        
        if result:
            results.append(result)
            successful += 1
    
    if results:
        df = pd.DataFrame(results)
        
        if output_file is None:
            output_file = os.path.join(data_dir, 'ecg_analysis_results.csv')
        
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        print(f"âœ… æˆåŠŸåˆ†æ: {successful}/{len(record_names)} ä¸ªè®°å½•")
        
        # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
        print(f"\nğŸ“ˆ åˆ†ææ‘˜è¦:")
        print(f"å¹³å‡å¿ƒç‡: {df['mean_hr'].mean():.1f} Â± {df['mean_hr'].std():.1f} BPM")
        print(f"å¹³å‡SDNN: {df['std_rr'].mean():.1f} Â± {df['std_rr'].std():.1f} ms")
        if 'rmssd' in df.columns:
            print(f"å¹³å‡RMSSD: {df['rmssd'].mean():.1f} Â± {df['rmssd'].std():.1f} ms")
        
        if 'age' in df.columns:
            ages = pd.to_numeric(df['age'], errors='coerce').dropna()
            if len(ages) > 0:
                print(f"å¹´é¾„èŒƒå›´: {ages.min():.0f}-{ages.max():.0f} å²")
        
        if 'sex' in df.columns:
            print(f"æ€§åˆ«åˆ†å¸ƒ: {dict(df['sex'].value_counts())}")
        
        return df
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸåˆ†æçš„è®°å½•")
        return None

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="ç®€åŒ–ç‰ˆECGæ•°æ®åˆ†æå™¨")
    parser.add_argument("data_dir", help="ECGæ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    if not os.path.exists(args.data_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.data_dir}")
        exit(1)
    
    analyze_directory(args.data_dir, args.output)