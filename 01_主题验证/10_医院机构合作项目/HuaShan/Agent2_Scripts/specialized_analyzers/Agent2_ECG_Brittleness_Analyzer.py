#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Agent2_ECG_Brittleness_Analyzer.py

åŸºäºAgent2 v5.0è¡€ç³–è„†æ€§åˆ†ææ¶æ„çš„ECGè„†æ€§åˆ†æç³»ç»Ÿ
é€‚ç”¨äºå¿ƒç”µå›¾ä¿¡å·çš„è„†æ€§è¯„ä¼°ã€æ™ºèƒ½åˆ†æ®µå’Œä¸´åºŠé¢„è­¦

ä½œè€…: AGPAI Team
ç‰ˆæœ¬: v1.0
æ—¥æœŸ: 2025-08-28
"""

import numpy as np
import pandas as pd
from scipy import signal
from scipy.stats import entropy
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class ECGBrittenessAnalyzer:
    """ECGè„†æ€§åˆ†æå™¨ - åŸºäºAgent2æ··æ²ŒåŠ¨åŠ›å­¦æ¶æ„"""
    
    def __init__(self, sampling_rate=500):
        self.sampling_rate = sampling_rate
        self.brittleness_types = {
            1: "Iå‹æ­£å¸¸ç¨³å®šå‹",
            2: "IIå‹è½»åº¦ä¸ç¨³å®šå‹", 
            3: "IIIå‹ä¸­åº¦æ˜“æŸå‹",
            4: "IVå‹é‡åº¦è„†å¼±å‹",
            5: "Vå‹æåº¦å±é™©å‹"
        }
    
    def preprocess_ecg_data(self, raw_ecg):
        """ECGæ•°æ®é¢„å¤„ç†"""
        # å¸¦é€šæ»¤æ³¢ (0.5-40Hz)
        nyquist = self.sampling_rate / 2
        low = 0.5 / nyquist
        high = 40 / nyquist
        b, a = signal.butter(4, [low, high], btype='band')
        filtered_ecg = signal.filtfilt(b, a, raw_ecg)
        
        # åŸºçº¿æ ¡æ­£ (é«˜é€šæ»¤æ³¢å»é™¤åŸºçº¿æ¼‚ç§»)
        b_high, a_high = signal.butter(4, 0.5/nyquist, btype='high')
        baseline_corrected = signal.filtfilt(b_high, a_high, filtered_ecg)
        
        return baseline_corrected
    
    def detect_r_peaks(self, ecg_signal):
        """Ræ³¢æ£€æµ‹"""
        # ä½¿ç”¨Pan-Tompkinsç®—æ³•æ£€æµ‹Ræ³¢
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”ç”¨ä¸­å¯ä½¿ç”¨æ›´ç²¾ç¡®çš„ç®—æ³•
        peaks, _ = signal.find_peaks(ecg_signal, 
                                   height=np.max(ecg_signal) * 0.6,
                                   distance=self.sampling_rate * 0.6)  # æœ€å°é—´éš”0.6ç§’
        return peaks
    
    def calculate_rr_intervals(self, r_peaks):
        """è®¡ç®—RRé—´æœŸ"""
        rr_intervals = np.diff(r_peaks) / self.sampling_rate * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        # å¼‚å¸¸å€¼è¿‡æ»¤ (300-2000ms)
        rr_intervals = rr_intervals[(rr_intervals >= 300) & (rr_intervals <= 2000)]
        return rr_intervals
    
    def calculate_lyapunov_exponent(self, signal_data, embedding_dim=3, delay=1):
        """è®¡ç®—LyapunovæŒ‡æ•° - æ··æ²ŒåŠ¨åŠ›å­¦æ ¸å¿ƒæŒ‡æ ‡"""
        try:
            # ç›¸ç©ºé—´é‡æ„
            N = len(signal_data)
            reconstructed = np.zeros((N - (embedding_dim - 1) * delay, embedding_dim))
            
            for i in range(embedding_dim):
                reconstructed[:, i] = signal_data[i * delay:N - (embedding_dim - 1 - i) * delay]
            
            # è®¡ç®—LyapunovæŒ‡æ•°
            lyapunov_values = []
            for i in range(1, len(reconstructed) - 1):
                if i + 1 < len(reconstructed):
                    distance = np.linalg.norm(reconstructed[i + 1] - reconstructed[i])
                    if distance > 0:
                        lyapunov_values.append(np.log(distance))
            
            if len(lyapunov_values) > 0:
                lyapunov_exponent = np.mean(np.diff(lyapunov_values))
            else:
                lyapunov_exponent = 0
                
            return lyapunov_exponent
        except:
            return 0
    
    def calculate_approximate_entropy(self, signal_data, m=2, r=None):
        """è®¡ç®—è¿‘ä¼¼ç†µ"""
        try:
            N = len(signal_data)
            if r is None:
                r = 0.2 * np.std(signal_data)
            
            def maxdist(xi, xj, N):
                return max([abs(ua - va) for ua, va in zip(xi, xj)])
            
            def phi(m):
                patterns = np.array([signal_data[i:i + m] for i in range(N - m + 1)])
                C = np.zeros(N - m + 1)
                for i in range(N - m + 1):
                    template = patterns[i]
                    matches = sum([1 for j in range(N - m + 1) if maxdist(template, patterns[j], m) <= r])
                    if matches > 0:
                        C[i] = matches / (N - m + 1)
                
                phi = sum([np.log(c) if c > 0 else 0 for c in C]) / (N - m + 1)
                return phi
            
            approximate_entropy = phi(m) - phi(m + 1)
            return approximate_entropy
        except:
            return 0
    
    def calculate_hurst_exponent(self, signal_data):
        """è®¡ç®—HurstæŒ‡æ•°"""
        try:
            N = len(signal_data)
            if N < 100:
                return 0.5
                
            # R/Såˆ†æ
            lags = np.logspace(1, np.log10(N//4), 20).astype(int)
            rs = []
            
            for lag in lags:
                sections = N // lag
                if sections == 0:
                    continue
                    
                section_data = signal_data[:sections*lag].reshape(sections, lag)
                
                rs_values = []
                for section in section_data:
                    mean_val = np.mean(section)
                    deviations = section - mean_val
                    cumsum_dev = np.cumsum(deviations)
                    
                    R = np.max(cumsum_dev) - np.min(cumsum_dev)
                    S = np.std(section)
                    
                    if S > 0:
                        rs_values.append(R / S)
                
                if len(rs_values) > 0:
                    rs.append(np.mean(rs_values))
            
            if len(rs) > 2 and len(lags) > 2:
                # çº¿æ€§æ‹Ÿåˆ
                log_lags = np.log10(lags[:len(rs)])
                log_rs = np.log10(rs)
                
                valid_indices = ~(np.isinf(log_rs) | np.isnan(log_rs))
                if np.sum(valid_indices) > 2:
                    hurst = np.polyfit(log_lags[valid_indices], log_rs[valid_indices], 1)[0]
                    return hurst
            
            return 0.5
        except:
            return 0.5
    
    def calculate_sample_entropy(self, signal_data, m=2, r=None):
        """è®¡ç®—æ ·æœ¬ç†µ"""
        try:
            N = len(signal_data)
            if r is None:
                r = 0.2 * np.std(signal_data)
            
            def chebyshev_distance(a, b):
                return max(abs(a - b))
            
            # è®¡ç®—æ¨¡æ¿åŒ¹é…
            A = 0.0  # m+1é•¿åº¦åŒ¹é…æ•°
            B = 0.0  # mé•¿åº¦åŒ¹é…æ•°
            
            for i in range(N - m):
                template_m = signal_data[i:i + m]
                template_m_plus = signal_data[i:i + m + 1] if i + m + 1 <= N else None
                
                for j in range(i + 1, N - m):
                    if j + m <= N:
                        test_m = signal_data[j:j + m]
                        
                        # mé•¿åº¦åŒ¹é…
                        if max([chebyshev_distance(template_m[k], test_m[k]) for k in range(m)]) <= r:
                            B += 1.0
                            
                            # m+1é•¿åº¦åŒ¹é…
                            if (template_m_plus is not None and 
                                j + m + 1 <= N and 
                                chebyshev_distance(template_m_plus[m], signal_data[j + m]) <= r):
                                A += 1.0
            
            if B > 0:
                sample_entropy = -np.log(A / B)
            else:
                sample_entropy = 0
                
            return sample_entropy
        except:
            return 0
    
    def calculate_hrv_time_domain(self, rr_intervals):
        """è®¡ç®—HRVæ—¶åŸŸæŒ‡æ ‡"""
        if len(rr_intervals) < 2:
            return {'RMSSD': 0, 'pNN50': 0, 'SDNN': 0}
            
        # RMSSD: ç›¸é‚»RRé—´æœŸå·®å€¼çš„å‡æ–¹æ ¹
        rmssd = np.sqrt(np.mean(np.diff(rr_intervals) ** 2))
        
        # pNN50: ç›¸é‚»RRé—´æœŸå·®å€¼>50msçš„ç™¾åˆ†æ¯”
        nn50 = np.sum(np.abs(np.diff(rr_intervals)) > 50)
        pnn50 = nn50 / len(rr_intervals) * 100
        
        # SDNN: RRé—´æœŸçš„æ ‡å‡†å·®
        sdnn = np.std(rr_intervals)
        
        return {
            'RMSSD': rmssd,
            'pNN50': pnn50,
            'SDNN': sdnn
        }
    
    def calculate_qt_variability(self, ecg_signal, r_peaks):
        """è®¡ç®—QTå˜å¼‚æ€§"""
        try:
            qt_intervals = []
            
            for i in range(len(r_peaks) - 1):
                # ç®€åŒ–çš„QTé—´æœŸæ£€æµ‹ (å®é™…åº”ç”¨ä¸­éœ€è¦æ›´ç²¾ç¡®çš„Tæ³¢æ£€æµ‹)
                qrs_start = r_peaks[i]
                next_qrs = r_peaks[i + 1]
                
                # åœ¨RRé—´æœŸçš„å70%åŒºåŸŸå¯»æ‰¾Tæ³¢ç»“æŸç‚¹
                search_start = int(qrs_start + (next_qrs - qrs_start) * 0.3)
                search_end = int(qrs_start + (next_qrs - qrs_start) * 0.8)
                
                if search_end < len(ecg_signal):
                    # å¯»æ‰¾Tæ³¢ç»“æŸç‚¹ (æœ€å°äºŒé˜¶å¯¼æ•°ç‚¹)
                    search_region = ecg_signal[search_start:search_end]
                    second_derivative = np.gradient(np.gradient(search_region))
                    t_end_relative = np.argmin(np.abs(second_derivative))
                    
                    qt_interval = (search_start + t_end_relative - qrs_start) / self.sampling_rate * 1000
                    
                    if 300 <= qt_interval <= 600:  # åˆç†çš„QTé—´æœŸèŒƒå›´
                        qt_intervals.append(qt_interval)
            
            if len(qt_intervals) > 1:
                qt_variability = np.std(qt_intervals)
            else:
                qt_variability = 0
                
            return qt_variability
        except:
            return 0
    
    def classify_ecg_brittleness(self, ecg_data):
        """ECGè„†æ€§åˆ†å‹"""
        try:
            # é¢„å¤„ç†
            clean_ecg = self.preprocess_ecg_data(ecg_data)
            
            # Ræ³¢æ£€æµ‹
            r_peaks = self.detect_r_peaks(clean_ecg)
            rr_intervals = self.calculate_rr_intervals(r_peaks)
            
            # æ··æ²ŒåŠ¨åŠ›å­¦æŒ‡æ ‡
            lyapunov = self.calculate_lyapunov_exponent(rr_intervals)
            approx_entropy = self.calculate_approximate_entropy(rr_intervals)
            hurst_exponent = self.calculate_hurst_exponent(rr_intervals)
            sample_entropy = self.calculate_sample_entropy(rr_intervals)
            
            # HRVæŒ‡æ ‡
            hrv_metrics = self.calculate_hrv_time_domain(rr_intervals)
            
            # QTå˜å¼‚æ€§
            qt_variability = self.calculate_qt_variability(clean_ecg, r_peaks)
            
            # ECGè„†æ€§è¯„åˆ†è®¡ç®—
            brittleness_score = self.calculate_ecg_brittleness_score(
                lyapunov, approx_entropy, hurst_exponent, hrv_metrics, qt_variability
            )
            
            # è„†æ€§åˆ†å‹
            brittleness_type = self.determine_brittleness_type(brittleness_score)
            risk_level = self.assess_risk_level(brittleness_score)
            
            return {
                "è„†æ€§åˆ†å‹": self.brittleness_types[brittleness_type],
                "è„†æ€§è¯„åˆ†": f"{brittleness_score:.1f}/100",
                "é£é™©ç­‰çº§": risk_level,
                "æ··æ²ŒåŠ¨åŠ›å­¦æŒ‡æ ‡": {
                    "LyapunovæŒ‡æ•°": f"{lyapunov:.6f}",
                    "è¿‘ä¼¼ç†µ": f"{approx_entropy:.4f}",
                    "HurstæŒ‡æ•°": f"{hurst_exponent:.4f}",
                    "æ ·æœ¬ç†µ": f"{sample_entropy:.4f}"
                },
                "å¿ƒç‡å˜å¼‚æ€§": hrv_metrics,
                "QTå˜å¼‚æ€§": f"{qt_variability:.2f}ms",
                "ä¸´åºŠè§£è¯»": self.generate_clinical_interpretation(
                    brittleness_type, brittleness_score, hrv_metrics
                )
            }
            
        except Exception as e:
            return {"error": f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"}
    
    def calculate_ecg_brittleness_score(self, lyapunov, approx_entropy, hurst, hrv_metrics, qt_var):
        """ECGè„†æ€§ç»¼åˆè¯„åˆ† (0-100)"""
        
        # æ··æ²ŒåŠ¨åŠ›å­¦è¯„åˆ† (0-40åˆ†)
        chaos_score = 0
        
        # LyapunovæŒ‡æ•°è¯„åˆ†
        if lyapunov > 0.001:
            chaos_score += min(15, abs(lyapunov) * 10000)
        
        # ç†µå€¼è¯„åˆ† 
        if approx_entropy < 0.5:
            chaos_score += 10
        elif approx_entropy > 1.5:
            chaos_score += 5
        
        # HurstæŒ‡æ•°è¯„åˆ†
        if abs(hurst - 0.5) > 0.3:
            chaos_score += 15
        
        # HRVè¯„åˆ† (0-35åˆ†)
        hrv_score = 0
        if hrv_metrics['RMSSD'] < 20:  # ä½HRV
            hrv_score += 15
        if hrv_metrics['pNN50'] < 5:   # ä½å˜å¼‚æ€§
            hrv_score += 10  
        if hrv_metrics['SDNN'] < 30:   # ä½æ€»å˜å¼‚æ€§
            hrv_score += 10
        
        # QTå˜å¼‚æ€§è¯„åˆ† (0-25åˆ†)
        qt_score = 0
        if qt_var > 30:  # é«˜QTå˜å¼‚æ€§
            qt_score += min(25, qt_var * 0.5)
        
        total_score = chaos_score + hrv_score + qt_score
        return min(100, max(0, total_score))
    
    def determine_brittleness_type(self, score):
        """ç¡®å®šè„†æ€§åˆ†å‹"""
        if score <= 20:
            return 1  # Iå‹æ­£å¸¸ç¨³å®šå‹
        elif score <= 40:
            return 2  # IIå‹è½»åº¦ä¸ç¨³å®šå‹
        elif score <= 60:
            return 3  # IIIå‹ä¸­åº¦æ˜“æŸå‹
        elif score <= 80:
            return 4  # IVå‹é‡åº¦è„†å¼±å‹
        else:
            return 5  # Vå‹æåº¦å±é™©å‹
    
    def assess_risk_level(self, score):
        """è¯„ä¼°é£é™©ç­‰çº§"""
        if score <= 20:
            return "ğŸŸ¢ ä½é£é™©"
        elif score <= 40:
            return "ğŸŸ¡ ä¸­ä½é£é™©"
        elif score <= 60:
            return "ğŸŸ  ä¸­ç­‰é£é™©"
        elif score <= 80:
            return "ğŸ”´ é«˜é£é™©"
        else:
            return "ğŸ”´ æé«˜é£é™©"
    
    def generate_clinical_interpretation(self, brittleness_type, score, hrv_metrics):
        """ç”Ÿæˆä¸´åºŠè§£è¯»"""
        interpretations = {
            1: "å¿ƒå¾‹ç¨³å®šï¼Œè‡ªä¸»ç¥ç»åŠŸèƒ½æ­£å¸¸ï¼Œå¿ƒè„ç”µæ´»åŠ¨è§„å¾‹æ€§è‰¯å¥½",
            2: "è½»åº¦å¿ƒå¾‹ä¸ç¨³å®šï¼Œå»ºè®®å®šæœŸç›‘æµ‹ï¼Œæ³¨æ„ç”Ÿæ´»æ–¹å¼è°ƒæ•´",
            3: "ä¸­åº¦å¿ƒç”µä¸ç¨³å®šï¼Œå»ºè®®è¿›ä¸€æ­¥å¿ƒç”µå›¾æ£€æŸ¥ï¼Œè¯„ä¼°æ½œåœ¨å¿ƒå¾‹å¤±å¸¸",
            4: "é‡åº¦å¿ƒç”µè„†æ€§ï¼Œå­˜åœ¨æ¶æ€§å¿ƒå¾‹å¤±å¸¸é£é™©ï¼Œå»ºè®®ç´§æ€¥å¿ƒå†…ç§‘ä¼šè¯Š",
            5: "æåº¦å±é™©å¿ƒç”µçŠ¶æ€ï¼Œå¿ƒè„çŒæ­»é«˜é£é™©ï¼Œéœ€è¦ç«‹å³åŒ»ç–—å¹²é¢„"
        }
        
        return interpretations.get(brittleness_type, "éœ€è¦ä¸“ä¸šåŒ»å¸ˆè¿›ä¸€æ­¥è¯„ä¼°")

def analyze_ecg_brittleness(ecg_data, patient_id="Unknown", sampling_rate=500):
    """ECGè„†æ€§åˆ†æä¸»å‡½æ•°"""
    
    print(f"ğŸ«€ ECGè„†æ€§åˆ†æç³»ç»Ÿå¯åŠ¨ - æ‚£è€…ID: {patient_id}")
    print("="*60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = ECGBrittenessAnalyzer(sampling_rate=sampling_rate)
    
    # æ‰§è¡Œåˆ†æ
    result = analyzer.classify_ecg_brittleness(ecg_data)
    
    # ç”ŸæˆæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report = {
        "æŠ¥å‘Šå¤´ä¿¡æ¯": {
            "æŠ¥å‘Šç±»å‹": "ECGè„†æ€§åˆ†ææŠ¥å‘Š v1.0",
            "æ‚£è€…ID": patient_id,
            "åˆ†ææ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "åˆ†ææ–¹æ³•": "æ··æ²ŒåŠ¨åŠ›å­¦ + HRV + QTå˜å¼‚æ€§åˆ†æ"
        },
        "ECGè„†æ€§è¯„ä¼°": result
    }
    
    # ä¿å­˜æŠ¥å‘Š
    filename = f"ECG_Brittleness_Analysis_{patient_id}_{timestamp}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=str)
    
    print("ğŸ“Š ECGè„†æ€§åˆ†æå®Œæˆ")
    print(f"è„†æ€§åˆ†å‹: {result.get('è„†æ€§åˆ†å‹', 'N/A')}")
    print(f"è„†æ€§è¯„åˆ†: {result.get('è„†æ€§è¯„åˆ†', 'N/A')}")
    print(f"é£é™©ç­‰çº§: {result.get('é£é™©ç­‰çº§', 'N/A')}")
    print(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {filename}")
    
    return report

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # ç”Ÿæˆç¤ºä¾‹ECGæ•°æ® (å®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®æ•°æ®)
    import matplotlib.pyplot as plt
    
    # æ¨¡æ‹ŸECGä¿¡å· (çª¦æ€§å¿ƒå¾‹ + å™ªå£°)
    duration = 30  # 30ç§’
    sampling_rate = 500
    t = np.linspace(0, duration, duration * sampling_rate)
    
    # åŸºç¡€çª¦æ€§å¿ƒå¾‹ (å¿ƒç‡çº¦70bpm)
    heart_rate = 70
    ecg_signal = np.zeros_like(t)
    
    # æ·»åŠ QRSæ³¢ç¾¤
    rr_interval = 60 / heart_rate
    for beat_time in np.arange(0, duration, rr_interval):
        beat_idx = int(beat_time * sampling_rate)
        if beat_idx < len(ecg_signal) - 100:
            # ç®€åŒ–çš„QRSæ³¢å½¢
            qrs_duration = int(0.1 * sampling_rate)  # 100ms
            qrs_wave = signal.gaussian(qrs_duration, std=qrs_duration//8)
            end_idx = min(beat_idx + qrs_duration, len(ecg_signal))
            ecg_signal[beat_idx:end_idx] += qrs_wave[:end_idx-beat_idx]
    
    # æ·»åŠ å™ªå£°å’Œå˜å¼‚æ€§
    noise = np.random.normal(0, 0.1, len(ecg_signal))
    ecg_signal += noise
    
    # æ‰§è¡Œåˆ†æ
    result = analyze_ecg_brittleness(ecg_signal, "Demo_Patient_001", sampling_rate)
    
    print("\nğŸ¯ æ¼”ç¤ºåˆ†æå®Œæˆï¼")