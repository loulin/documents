#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CRFæ•°æ®æŒ–æ˜Agentå®Œæ•´æµ‹è¯•è„šæœ¬
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print("ğŸ“Š æ­£åœ¨åˆ›å»ºæµ‹è¯•æ•°æ®...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
    test_data_dir = os.path.join(os.path.dirname(__file__), 'test_data')
    os.makedirs(test_data_dir, exist_ok=True)
    
    np.random.seed(42)
    n_patients = 300  # å¢åŠ æ ·æœ¬é‡åˆ°300
    
    # æ‚£è€…åŸºæœ¬ä¿¡æ¯ - å¼•å…¥æ›´å¤šä¸´åºŠç›¸å…³çš„å…³è”æ€§
    demographics_data = {
        'patient_id': [f'P{i:03d}' for i in range(1, n_patients + 1)],
        'age': np.random.normal(58, 15, n_patients).astype(int),  # å¹´é¾„èŒƒå›´æ›´å¹¿
        'gender': np.random.choice(['male', 'female'], n_patients, p=[0.55, 0.45]),
        'diabetes_type': np.random.choice(['type1', 'type2'], n_patients, p=[0.12, 0.88]),  # æ›´ç°å®çš„æ¯”ä¾‹
        'duration': np.random.exponential(10, n_patients).astype(int),  # ç—…ç¨‹æ›´é•¿
        'bmi': np.random.normal(28, 5, n_patients),  # BMIæ›´é«˜ï¼Œæ›´ç¬¦åˆç³–å°¿ç—…æ‚£è€…ç‰¹å¾
        'education_level': np.random.choice(['primary', 'middle', 'high_school', 'college', 'graduate'], 
                                          n_patients, p=[0.1, 0.2, 0.35, 0.3, 0.05])
    }
    
    demographics_df = pd.DataFrame(demographics_data)
    demographics_df['age'] = np.clip(demographics_df['age'], 18, 85)
    demographics_path = os.path.join(test_data_dir, 'patient_demographics.csv')
    demographics_df.to_csv(demographics_path, index=False)
    
    # ä¸´åºŠæ•°æ® - å¼•å…¥æ›´å¼ºçš„ç›¸å…³æ€§å’Œä¸´åºŠæ„ä¹‰
    clinical_data = {
        'patient_id': demographics_df['patient_id'],
        'hba1c': np.random.normal(8.5, 2.0, n_patients),  # æ›´å¤§çš„å˜å¼‚æ€§
        'fbg': np.random.normal(10.2, 3.2, n_patients),
        'creatinine': np.random.normal(90, 25, n_patients),
        'total_cholesterol': np.random.normal(5.2, 1.1, n_patients),
        'triglycerides': np.random.normal(2.8, 1.8, n_patients),  # æ›´é«˜çš„åŸºçº¿å€¼
        'systolic_bp': np.random.normal(142, 22, n_patients),  # æ›´é«˜çš„è¡€å‹
        'diastolic_bp': np.random.normal(88, 15, n_patients)
    }
    
    clinical_df = pd.DataFrame(clinical_data)
    
    # åŠ å…¥å¼ºçƒˆçš„ä¸´åºŠå…³è”æ€§
    # å¹´é¾„ä¸HbA1cçš„å…³è” - è€å¹´æ‚£è€…è¡€ç³–æ§åˆ¶æ›´å·®
    age_effect_hba1c = np.where(demographics_df['age'] > 65, 
                                np.random.normal(1.2, 0.5, n_patients), 0)
    clinical_df['hba1c'] += age_effect_hba1c
    
    # ç—…ç¨‹ä¸å¹¶å‘ç—‡é£é™©çš„å…³è”
    duration_effect = np.where(demographics_df['duration'] > 10,
                              np.random.normal(0.8, 0.3, n_patients), 0)
    clinical_df['hba1c'] += duration_effect
    clinical_df['creatinine'] += duration_effect * 15  # è‚¾åŠŸèƒ½æ¶åŒ–
    
    # BMIä¸ä»£è°¢æŒ‡æ ‡çš„å¼ºå…³è”
    bmi_effect = (demographics_df['bmi'] - 25) * 0.15
    clinical_df['hba1c'] += np.maximum(bmi_effect, 0)  # åªæœ‰æ­£å‘æ•ˆåº”
    clinical_df['systolic_bp'] += bmi_effect * 2
    clinical_df['triglycerides'] += bmi_effect * 0.3
    
    clinical_df['hba1c'] = np.clip(clinical_df['hba1c'], 5.5, 15.0)
    clinical_path = os.path.join(test_data_dir, 'clinical_data.csv')
    clinical_df.to_csv(clinical_path, index=False)
    
    # PHQ-9æ•°æ® (åŠ å…¥ä¸HbA1cçš„å…³è”æ€§å’Œä¸€äº›æ•°æ®è´¨é‡é—®é¢˜)
    base_depression = np.random.poisson(4, n_patients)  # åŸºç¡€æŠ‘éƒè¯„åˆ†
    
    # å¼ºåŒ–HbA1cä¸æŠ‘éƒçš„å…³è”
    hba1c_effect = np.where(clinical_df['hba1c'] > 9.0, 
                           np.random.poisson(6, n_patients), 
                           np.random.poisson(1, n_patients))
    
    # æ€§åˆ«æ•ˆåº” - å¥³æ€§æŠ‘éƒç—‡çŠ¶æ›´ä¸¥é‡
    gender_effect = np.where(demographics_df['gender'] == 'female',
                            np.random.poisson(2, n_patients), 0)
    
    phq9_data = {
        'patient_id': demographics_df['patient_id'],
        'total_score': base_depression + hba1c_effect + gender_effect
    }
    phq9_df = pd.DataFrame(phq9_data)
    phq9_df['total_score'] = np.clip(phq9_df['total_score'], 0, 27)
    
    # æ•…æ„æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼æ¥æµ‹è¯•æ•°æ®è´¨é‡æ£€éªŒ
    missing_indices = np.random.choice(n_patients, size=int(n_patients * 0.05), replace=False)
    phq9_df.loc[missing_indices, 'total_score'] = np.nan
    
    # æ·»åŠ ä¸€äº›å¼‚å¸¸é«˜å€¼ä½œä¸ºå¼‚å¸¸å€¼æµ‹è¯•
    extreme_indices = np.random.choice(n_patients, size=int(n_patients * 0.02), replace=False)
    phq9_df.loc[extreme_indices, 'total_score'] = 25  # å¼‚å¸¸é«˜çš„æŠ‘éƒè¯„åˆ†
    
    phq9_path = os.path.join(test_data_dir, 'phq9.csv')
    phq9_df.to_csv(phq9_path, index=False)
    
    # GAD-7æ•°æ® (ä¸PHQ-9æœ‰å¼ºçƒˆå…±ç—…å…³ç³»)
    base_anxiety = np.random.poisson(3, n_patients)
    
    # æŠ‘éƒ-ç„¦è™‘å…±ç—…æ•ˆåº” - åŸºäºçœŸå®PHQ-9è¯„åˆ†
    phq9_scores = phq9_df['total_score'].fillna(0)  # å¤„ç†ç¼ºå¤±å€¼
    depression_effect = np.where(phq9_scores > 10, 
                                np.random.poisson(5, n_patients), 
                                np.random.poisson(1, n_patients))
    
    # å¹´é¾„æ•ˆåº” - å¹´è½»äººç„¦è™‘æ›´ä¸¥é‡
    age_effect = np.where(demographics_df['age'] < 40,
                         np.random.poisson(2, n_patients), 0)
    
    gad7_data = {
        'patient_id': demographics_df['patient_id'],
        'total_score': base_anxiety + depression_effect + age_effect
    }
    gad7_df = pd.DataFrame(gad7_data)
    gad7_df['total_score'] = np.clip(gad7_df['total_score'], 0, 21)
    
    # æ·»åŠ ä¸€äº›é‡å¤è®°å½•æ¥æµ‹è¯•é‡å¤æ£€æµ‹
    duplicate_indices = np.random.choice(n_patients, size=int(n_patients * 0.03), replace=False)
    duplicate_rows = gad7_df.iloc[duplicate_indices].copy()
    gad7_df = pd.concat([gad7_df, duplicate_rows], ignore_index=True)
    
    gad7_path = os.path.join(test_data_dir, 'gad7.csv')
    gad7_df.to_csv(gad7_path, index=False)
    
    # MMAS-8æ•°æ® (è¯ç‰©ä¾ä»æ€§ä¸å¤šå› ç´ å…³è”)
    base_adherence = np.random.binomial(8, 0.6, n_patients)  # åŸºç¡€ä¾ä»æ€§è¾ƒä½
    
    # æ•™è‚²æ°´å¹³å¯¹ä¾ä»æ€§çš„å½±å“
    education_effect = np.where(demographics_df['education_level'].isin(['college', 'graduate']),
                               np.random.binomial(2, 0.8, n_patients), 0)
    
    # å¹´é¾„å¯¹ä¾ä»æ€§çš„å½±å“ - è€å¹´äººä¾ä»æ€§å¯èƒ½æ›´å¥½æˆ–æ›´å·®
    age_effect = np.where(demographics_df['age'] > 70,
                         np.random.choice([-1, 1], n_patients) * np.random.binomial(1, 0.3, n_patients), 0)
    
    # æŠ‘éƒå¯¹ä¾ä»æ€§çš„è´Ÿé¢å½±å“
    depression_effect = np.where(phq9_scores > 15,
                                -np.random.binomial(2, 0.7, n_patients), 0)
    
    mmas8_data = {
        'patient_id': demographics_df['patient_id'],
        'total_score': base_adherence + education_effect + age_effect + depression_effect
    }
    mmas8_df = pd.DataFrame(mmas8_data)
    mmas8_df['total_score'] = np.clip(mmas8_df['total_score'], 0, 8)
    
    # æ·»åŠ ä¸€äº›ä¸´åºŠä¸åˆç†å€¼è¿›è¡Œæµ‹è¯•
    invalid_indices = np.random.choice(n_patients, size=int(n_patients * 0.01), replace=False)
    mmas8_df.loc[invalid_indices, 'total_score'] = -1  # ä¸åˆç†çš„è´Ÿå€¼
    
    mmas8_path = os.path.join(test_data_dir, 'mmas8.csv')
    mmas8_df.to_csv(mmas8_path, index=False)
    
    print(f"âœ… æµ‹è¯•æ•°æ®å·²åˆ›å»ºåœ¨ {test_data_dir}")
    
    return {
        'patient_demographics': demographics_path,
        'clinical_data': clinical_path,
        'phq9': phq9_path,
        'gad7': gad7_path,
        'mmas8': mmas8_path
    }

def test_agent():
    """æµ‹è¯•AgentåŠŸèƒ½"""
    print("ğŸš€ CRFæ•°æ®æŒ–æ˜æ™ºèƒ½åˆ†æAgent - å®Œæ•´æµ‹è¯•")
    print("=" * 60)
    
    try:
        # 1. å¯¼å…¥Agent
        from CRF_Research_Mining_Agent import CRFResearchMiningAgent
        print("âœ… Agentå¯¼å…¥æˆåŠŸ")
        
        # 2. åˆå§‹åŒ–Agent
        agent = CRFResearchMiningAgent()
        print("âœ… Agentåˆå§‹åŒ–æˆåŠŸ")
        
        # 3. åˆ›å»ºæµ‹è¯•æ•°æ®
        data_sources = create_test_data()
        
        # 4. åŠ è½½æ•°æ®
        print("\nğŸ“Š æ­£åœ¨åŠ è½½æ•°æ®...")
        datasets = agent.load_crf_data(data_sources)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(datasets)} ä¸ªæ•°æ®é›†")
        
        # 5. æ•°æ®è´¨é‡è¯„ä¼°
        print("\nğŸ” æ­£åœ¨è¯„ä¼°æ•°æ®è´¨é‡...")
        quality_report = agent.assess_data_quality()
        
        print("æ•°æ®è´¨é‡æŠ¥å‘Š:")
        for dataset_name, metrics in quality_report.items():
            print(f"\nğŸ“Š {dataset_name}:")
            print(f"  - è®°å½•æ•°: {metrics['total_records']}")
            print(f"  - ç‰¹å¾æ•°: {metrics['total_features']}")
            print(f"  - ç¼ºå¤±ç‡: {metrics['missing_rate']:.1%}")
            print(f"  - é‡å¤ç‡: {metrics['duplicate_rate']:.1%}")
            print(f"  - è´¨é‡ç­‰çº§: {metrics['overall_grade']}")
            
            # æ˜¾ç¤ºå¼‚å¸¸å€¼ä¿¡æ¯
            if 'outlier_rates' in metrics:
                high_outlier_cols = [col for col, rate in metrics['outlier_rates'].items() if rate > 0.05]
                if high_outlier_cols:
                    print(f"  - å¼‚å¸¸å€¼è¾ƒå¤šå­—æ®µ: {', '.join(high_outlier_cols)}")
            
            # æ˜¾ç¤ºè´¨é‡é—®é¢˜
            if 'quality_issues' in metrics and metrics['quality_issues']:
                print(f"  - ä¸»è¦é—®é¢˜: {'; '.join(metrics['quality_issues'][:2])}")
            
            # æ˜¾ç¤ºæ¸…ç†å»ºè®®
            if 'cleaning_recommendations' in metrics and metrics['cleaning_recommendations']:
                print(f"  - æ¸…ç†å»ºè®®: {metrics['cleaning_recommendations'][0]}")
        
        # 6. å‘ç°ç ”ç©¶æœºä¼š
        print("\nğŸ’¡ æ­£åœ¨å‘ç°ç ”ç©¶æœºä¼š...")
        insights = agent.discover_research_opportunities()
        print(f"âœ… å‘ç° {len(insights)} ä¸ªç ”ç©¶æœºä¼š")
        
        # æ˜¾ç¤ºå‰3ä¸ªç ”ç©¶æœºä¼š
        if insights:
            print("\nğŸ¯ TOP 3 ç ”ç©¶æœºä¼š:")
            for i, insight in enumerate(insights[:3], 1):
                print(f"{i}. {insight.title}")
                print(f"   - ç ”ç©¶ä»·å€¼: {insight.value_level.value}")
                print(f"   - ç»Ÿè®¡åŠŸæ•ˆ: {insight.statistical_power:.2f}")
                print(f"   - æ ·æœ¬é‡: {insight.sample_size}")
                print(f"   - æœŸåˆŠæ¡£æ¬¡: {insight.expected_impact_factor}")
        
        # 7. ç”Ÿæˆä¼˜å…ˆçº§çŸ©é˜µ
        print("\nğŸ“ˆ æ­£åœ¨ç”Ÿæˆä¼˜å…ˆçº§çŸ©é˜µ...")
        priority_matrix = agent.generate_research_priority_matrix()
        if not priority_matrix.empty:
            print("ä¼˜å…ˆçº§æœ€é«˜çš„3ä¸ªç ”ç©¶:")
            for i, row in priority_matrix.head(3).iterrows():
                print(f"- {row['research_topic']} (ä¼˜å…ˆçº§: {row['priority_score']:.2f})")
        
        # 8. ç”Ÿæˆå‘è¡¨è·¯çº¿å›¾
        print("\nğŸ“… æ­£åœ¨ç”Ÿæˆå‘è¡¨è·¯çº¿å›¾...")
        roadmap = agent.generate_publication_roadmap()
        
        print("å‘è¡¨è·¯çº¿å›¾:")
        for timeframe, projects in roadmap.items():
            print(f"- {timeframe}: {len(projects)}ä¸ªé¡¹ç›®")
        
        # 9. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        print("\nğŸ“ æ­£åœ¨ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
        output_path = os.path.join(os.path.dirname(__file__), 'CRF_Test_Analysis_Report.md')
        report = agent.generate_comprehensive_report(output_path)
        
        print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        
        # 10. æ˜¾ç¤ºæ€»ç»“
        print("\n" + "=" * 60)
        print("âœ… æµ‹è¯•å®Œæˆï¼AgentåŠŸèƒ½æ­£å¸¸")
        print(f"ğŸ“Š å¤„ç†æ•°æ®: {sum(len(df) for df in datasets.values())}æ¡è®°å½•")
        print(f"ğŸ” å‘ç°ç ”ç©¶æœºä¼š: {len(insights)}ä¸ª")
        print(f"ğŸ“„ ç”ŸæˆæŠ¥å‘Š: {len(report)}å­—ç¬¦")
        print("ğŸ¯ æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å·¥ä½œæ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    test_agent()

if __name__ == "__main__":
    main()