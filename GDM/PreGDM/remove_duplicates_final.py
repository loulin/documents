#!/usr/bin/env python3
"""
æ¸…ç†è¯ç‰©æ•°æ®åº“ä¸­çš„é‡å¤å†…å®¹
"""

import csv

def remove_content_duplicates(input_file, output_file):
    """æ¸…ç†å†…å®¹é‡å¤çš„è¯ç‰©æ¡ç›®"""
    
    removed_drugs = []
    total_drugs = 0
    
    print("ğŸ§¹ å¼€å§‹æ¸…ç†é‡å¤å†…å®¹...")
    
    # è¯»å–æ‰€æœ‰æ•°æ®
    with open(input_file, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        all_rows = list(reader)
    
    # å­˜å‚¨è¦ä¿ç•™çš„è¡Œ
    filtered_rows = []
    
    # è¦ç§»é™¤çš„é‡å¤è¯ç‰©ID (ä¿ç•™ç¬¬ä¸€ä¸ªï¼Œç§»é™¤åé¢çš„)
    duplicates_to_remove = [
        'D047',  # åˆ©æ‹‰é²è‚½é‡å¤é¡¹ (ä¿ç•™D013)
        'D079'   # å¡æ ¼åˆ—é…®é‡å¤é¡¹ (ä¿ç•™D096)
    ]
    
    for row_num, row in enumerate(all_rows):
        # éè¯ç‰©è¡Œç›´æ¥ä¿ç•™
        if not row or not row[0].startswith('D') or not row[0][1:].isdigit():
            filtered_rows.append(row)
            continue
            
        total_drugs += 1
        drug_id = row[0]
        
        if drug_id in duplicates_to_remove:
            removed_drugs.append(drug_id)
            print(f"âŒ ç§»é™¤é‡å¤è¯ç‰©: {drug_id} - {row[4]} (è¡Œ {row_num + 1})")
            continue
        
        filtered_rows.append(row)
    
    # å†™å…¥æ¸…ç†åçš„æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        writer.writerows(filtered_rows)
    
    # ç»Ÿè®¡ç»“æœ
    remaining_drugs = total_drugs - len(removed_drugs)
    
    print(f"\nğŸ“Š æ¸…ç†å®Œæˆç»Ÿè®¡:")
    print(f"   ğŸ“ åŸè¯ç‰©æ€»æ•°: {total_drugs}")
    print(f"   âŒ ç§»é™¤é‡å¤è¯ç‰©: {len(removed_drugs)} ä¸ª")
    print(f"   âœ… å‰©ä½™è¯ç‰©æ•°é‡: {remaining_drugs}")
    print(f"   ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    if removed_drugs:
        print(f"\nğŸ—‘ï¸  å·²ç§»é™¤çš„é‡å¤è¯ç‰©:")
        for drug_id in removed_drugs:
            print(f"   â€¢ {drug_id}")
    
    return {
        'original_count': total_drugs,
        'removed_count': len(removed_drugs),
        'final_count': remaining_drugs,
        'removed_drugs': removed_drugs
    }

def final_verification(file_path):
    """æœ€ç»ˆéªŒè¯æ•°æ®åº“å®Œæ•´æ€§"""
    
    print(f"\nğŸ” æœ€ç»ˆå®Œæ•´æ€§éªŒè¯...")
    
    drug_ids = set()
    drug_contents = {}
    field_errors = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        
        # æ‰¾è¡¨å¤´
        header_found = False
        expected_fields = 0
        
        for row_num, row in enumerate(reader, 1):
            if row and row[0] == 'drug_id':
                expected_fields = len(row)
                header_found = True
                continue
                
            if not header_found or not row or not row[0].startswith('D') or not row[0][1:].isdigit():
                continue
                
            drug_id = row[0]
            
            # æ£€æŸ¥é‡å¤ID
            if drug_id in drug_ids:
                print(f"âŒ å‘ç°é‡å¤ID: {drug_id}")
            else:
                drug_ids.add(drug_id)
            
            # æ£€æŸ¥å­—æ®µæ•°é‡
            if len(row) != expected_fields:
                field_errors.append((drug_id, len(row)))
            
            # æ£€æŸ¥å†…å®¹é‡å¤
            if len(row) >= 5:
                content_key = (row[2].strip().lower(), row[4].strip())
                if content_key in drug_contents:
                    print(f"âŒ å‘ç°å†…å®¹é‡å¤: {row[2]} / {row[4]} - {drug_id} å’Œ {drug_contents[content_key]}")
                else:
                    drug_contents[content_key] = drug_id
    
    print(f"   ğŸ“ å”¯ä¸€è¯ç‰©æ•°é‡: {len(drug_ids)}")
    print(f"   ğŸ”„ å†…å®¹é‡å¤æ£€æŸ¥: {'âŒ æœ‰é‡å¤' if len(drug_contents) < len(drug_ids) else 'âœ… æ— é‡å¤'}")
    print(f"   ğŸ“ å­—æ®µå®Œæ•´æ€§: {'âŒ æœ‰ç¼ºå¤±' if field_errors else 'âœ… å®Œæ•´'}")
    
    if field_errors:
        print(f"   å­—æ®µé—®é¢˜è¯¦æƒ…: {field_errors[:3]}...")  # åªæ˜¾ç¤ºå‰3ä¸ª
    
    return len(drug_ids), len(field_errors) == 0

if __name__ == "__main__":
    input_file = "/Users/williamsun/Documents/gplus/docs/Medicines/medication_database.csv"
    output_file = input_file
    
    # ç¬¬ä¸€æ­¥ï¼šç§»é™¤é‡å¤å†…å®¹
    result = remove_content_duplicates(input_file, output_file)
    
    # ç¬¬äºŒæ­¥ï¼šæœ€ç»ˆéªŒè¯
    final_count, is_clean = final_verification(output_file)
    
    if is_clean:
        print(f"\nğŸ‰ æ•°æ®åº“æ¸…ç†å®Œæˆï¼æœ€ç»ˆåŒ…å« {final_count} ä¸ªå”¯ä¸€è¯ç‰©ï¼Œæ— é‡å¤å’Œé”™è¯¯ã€‚")
    else:
        print(f"\nâš ï¸  æ•°æ®åº“ä»æœ‰é—®é¢˜éœ€è¦æ‰‹åŠ¨å¤„ç†ã€‚")